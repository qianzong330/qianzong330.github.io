<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-Dubbo面试题" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/02/Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98/" class="article-date">
  <time class="dt-published" datetime="2022-06-02T07:38:23.961Z" itemprop="datePublished">2022-06-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-Dubbo是什么？"><a href="#1-Dubbo是什么？" class="headerlink" title="1.Dubbo是什么？"></a>1.Dubbo是什么？</h2><p>Dubbo是阿里巴巴开源的基于 Java 的高性能 RPC 分布式服务框架，现已成为 Apache 基金会孵化项目。</p>
<p>其核心部分包含：</p>
<ul>
<li>集群容错：提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。</li>
<li>远程通讯：提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。</li>
<li>自动发现：基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。</li>
</ul>
<h2 id="2-Dubbo和-Spring-Cloud-有什么区别？"><a href="#2-Dubbo和-Spring-Cloud-有什么区别？" class="headerlink" title="2. Dubbo和 Spring Cloud 有什么区别？"></a>2. Dubbo和 Spring Cloud 有什么区别？</h2><p>最大的区别：</p>
<ul>
<li>Dubbo底层是使用Netty这样的NIO框架，是基于TCP协议传输的，配合以Hession序列化完成RPC通信;</li>
<li>而SpringCloud是基于Http协议+rest接口调用远程过程的通信，相对来说，Http请求会有更大的报文，占的带宽也会更多。但是REST相比RPC更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下，显得更为合适，至于注重通信速度还是方便灵活性，具体情况具体考虑。</li>
</ul>
<p>模块区别：</p>
<ul>
<li><p>Dubbo主要分为服务注册中心，服务提供者，服务消费者，还有管控中心；</p>
</li>
<li><p>相比起Dubbo简单的四个模块，SpringCloud则是一个完整的分布式一站式框架，他有着一样的服务注册中心，服务提供者，服务消费者，管控台，断路器，分布式配置服务，消息总线，以及服务追踪等；</p>
</li>
</ul>
<h2 id="3-Dubbo核心组件有哪些？"><a href="#3-Dubbo核心组件有哪些？" class="headerlink" title="3. Dubbo核心组件有哪些？"></a>3. Dubbo核心组件有哪些？</h2><p><img src="http://blog-img.coolsen.cn/img/image-20210829190835070.png" alt="image-20210829190835070"></p>
<ul>
<li>Provider：暴露服务的服务提供方</li>
<li>Consumer：调用远程服务消费方</li>
<li>Registry：服务注册与发现注册中心</li>
<li>Monitor：监控中心和访问调用统计</li>
<li>Container：服务运行容器</li>
</ul>
<h2 id="4-Dubbo都支持什么协议，推荐用哪种？"><a href="#4-Dubbo都支持什么协议，推荐用哪种？" class="headerlink" title="4. Dubbo都支持什么协议，推荐用哪种？"></a>4. Dubbo都支持什么协议，推荐用哪种？</h2><p>1、 Dubbo协议：Dubbo默认使用Dubbo协议。</p>
<ul>
<li>适合大并发小数据量的服务调用，以及服务消费者远大于提供者的情况</li>
<li>Hessian二进制序列化。</li>
<li>缺点是不适合传送大数据包的服务。</li>
</ul>
<p>2、rmi协议：采用JDK标准的rmi协议实现，传输参数和返回参数对象需要实现Serializable接口。使用java标准序列化机制，使用阻塞式短连接，传输数据包不限，消费者和提供者个数相当。</p>
<ul>
<li>多个短连接，TCP协议传输，同步传输，适用常规的远程服务调用和rmi互操作</li>
<li>缺点：在依赖低版本的Common-Collections包，java反序列化存在安全漏洞，需升级commons-collections3 到3.2.2版本或commons-collections4到4.1版本。</li>
</ul>
<p>3、 webservice协议：基于WebService的远程调用协议(Apache CXF的frontend-simple和transports-http)实现，提供和原生WebService的互操作多个短连接，基于HTTP传输，同步传输，适用系统集成和跨语言调用。</p>
<p>4、http协议：基于Http表单提交的远程调用协议，使用Spring的HttpInvoke实现。对传输数据包不限，传入参数大小混合，提供者个数多于消费者</p>
<ul>
<li>缺点是不支持传文件，只适用于同时给应用程序和浏览器JS调用</li>
</ul>
<p>5、hessian：集成Hessian服务，基于底层Http通讯，采用Servlet暴露服务，Dubbo内嵌Jetty作为服务器实现,可与Hession服务互操作<br>通讯效率高于WebService和Java自带的序列化</p>
<ul>
<li><p>适用于传输大数据包(可传文件)，提供者比消费者个数多，提供者压力较大</p>
</li>
<li><p>缺点是参数及返回值需实现Serializable接口，自定义实现List、Map、Number、Date、Calendar等接口</p>
</li>
</ul>
<p>6、thrift协议：对thrift原生协议的扩展添加了额外的头信息。使用较少，不支持传null值</p>
<p>7、memcache：基于memcached实现的RPC协议</p>
<p>8、redis：基于redis实现的RPC协议</p>
<h2 id="5-Dubbo服务器注册与发现的流程？"><a href="#5-Dubbo服务器注册与发现的流程？" class="headerlink" title="5. Dubbo服务器注册与发现的流程？"></a>5. Dubbo服务器注册与发现的流程？</h2><ul>
<li>服务容器Container负责启动，加载，运行服务提供者。</li>
<li>服务提供者Provider在启动时，向注册中心注册自己提供的服务。</li>
<li>服务消费者Consumer在启动时，向注册中心订阅自己所需的服务。</li>
<li>注册中心Registry返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li>
<li>服务消费者Consumer，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</li>
<li>服务消费者Consumer和提供者Provider，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心Monitor。</li>
</ul>
<h2 id="6-Dubbo内置了哪几种服务容器？"><a href="#6-Dubbo内置了哪几种服务容器？" class="headerlink" title="6. Dubbo内置了哪几种服务容器？"></a>6. Dubbo内置了哪几种服务容器？</h2><p>三种服务容器：</p>
<ul>
<li>Spring Container</li>
<li>Jetty Container</li>
<li>Log4j Container</li>
</ul>
<p>Dubbo的服务容器只是一个简单的 Main 方法，并加载一个简单的 Spring 容器，用于暴露服务。</p>
<h2 id="7-Dubbo负载均衡的作用？"><a href="#7-Dubbo负载均衡的作用？" class="headerlink" title="7. Dubbo负载均衡的作用？"></a>7. Dubbo负载均衡的作用？</h2><p>　将负载均衡功能实现在rpc客户端侧，以便能够随时适应外部的环境变化，更好地发挥硬件作用。而且客户端的负载均衡天然地就避免了单点问题。定制化的自有定制化的优势和劣势。</p>
<p>它可以从配置文件中指定，也可以在管理后台进行配置修改。</p>
<p>事实上，它支持 服务端服务&#x2F;方法级别、客户端服务&#x2F;方法级别 的负载均衡配置。</p>
<h2 id="8-Dubbo有哪几种负载均衡策略，默认是哪种？"><a href="#8-Dubbo有哪几种负载均衡策略，默认是哪种？" class="headerlink" title="8. Dubbo有哪几种负载均衡策略，默认是哪种？"></a>8. Dubbo有哪几种负载均衡策略，默认是哪种？</h2><p>Dubbo提供了4种负载均衡实现：</p>
<ol>
<li>RandomLoadBalance:随机负载均衡。随机的选择一个。是Dubbo的默认负载均衡策略。</li>
<li>RoundRobinLoadBalance:轮询负载均衡。轮询选择一个。</li>
<li>LeastActiveLoadBalance:最少活跃调用数，相同活跃数的随机。活跃数指调用前后计数差。使慢的 Provider 收到更少请求，因为越慢的 Provider 的调用前后计数差会越大。</li>
<li>ConsistentHashLoadBalance:一致性哈希负载均衡。相同参数的请求总是落在同一台机器上。</li>
</ol>
<h2 id="9-Dubbo服务之间的调用是阻塞的吗？"><a href="#9-Dubbo服务之间的调用是阻塞的吗？" class="headerlink" title="9. Dubbo服务之间的调用是阻塞的吗？"></a>9. Dubbo服务之间的调用是阻塞的吗？</h2><p>默认是同步等待结果阻塞的，支持异步调用。</p>
<p>Dubbo是基于 NIO 的非阻塞实现并行调用，客户端不需要启动多线程即可完成并行调用多个远程服务，相对多线程开销较小，异步调用会返回一个 Future 对象。</p>
<h2 id="10-DubboMonitor-实现原理？"><a href="#10-DubboMonitor-实现原理？" class="headerlink" title="10. DubboMonitor 实现原理？"></a>10. DubboMonitor 实现原理？</h2><p>Consumer 端在发起调用之前会先走 filter 链；provider 端在接收到请求时也是先走 filter 链，然后才进行真正的业务逻辑处理。默认情况下，在 consumer 和 provider 的 filter 链中都会有 Monitorfilter。</p>
<ol>
<li>MonitorFilter 向 DubboMonitor 发送数据</li>
<li>DubboMonitor 将数据进行聚合后（默认聚合 1min 中的统计数据）暂存到ConcurrentMap&lt;Statistics, AtomicReference&gt; statisticsMap，然后使用一个含有 3 个线程（线程名字：DubboMonitorSendTimer）的线程池每隔 1min 钟，调用 SimpleMonitorService 遍历发送 statisticsMap 中的统计数据，每发送完毕一个，就重置当前的 Statistics 的 AtomicReference</li>
<li>SimpleMonitorService 将这些聚合数据塞入 BlockingQueue queue 中（队列大写为 100000）</li>
<li>SimpleMonitorService 使用一个后台线程（线程名为：DubboMonitorAsyncWriteLogThread）将 queue 中的数据写入文件（该线程以死循环的形式来写）</li>
<li>SimpleMonitorService 还会使用一个含有 1 个线程（线程名字：DubboMonitorTimer）的线程池每隔 5min 钟，将文件中的统计数据画成图表</li>
</ol>
<h2 id="11-Dubbo有哪些注册中心？"><a href="#11-Dubbo有哪些注册中心？" class="headerlink" title="11. Dubbo有哪些注册中心？"></a>11. Dubbo有哪些注册中心？</h2><ul>
<li>Multicast 注册中心：Multicast 注册中心不需要任何中心节点，只要广播地址，就能进行服务注册和发现,基于网络中组播传输实现。</li>
<li>Zookeeper 注册中心：基于分布式协调系统 Zookeeper 实现，采用 Zookeeper 的 watch 机制实现数据变更。</li>
<li>Redis 注册中心：基于 Redis 实现，采用 key&#x2F;map 存储，key 存储服务名和类型，map 中 key 存储服务 url，value 服务过期时间。基于 Redis 的发布&#x2F;订阅模式通知数据变更。</li>
<li>Simple 注册中心。</li>
<li>推荐使用 Zookeeper 作为注册中心</li>
</ul>
<h2 id="12-Dubbo的集群容错方案有哪些？"><a href="#12-Dubbo的集群容错方案有哪些？" class="headerlink" title="12. Dubbo的集群容错方案有哪些？"></a>12. Dubbo的集群容错方案有哪些？</h2><ul>
<li>Failover Cluster：失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。</li>
<li>Failfast Cluster：快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。</li>
<li>Failsafe Cluster：失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。</li>
<li>Failback Cluster：失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。</li>
<li>Forking Cluster：并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks&#x3D;”2″ 来设置最大并行数。</li>
<li>Broadcast Cluster：广播调用所有提供者，逐个调用，任意一台报错则报错 。通常用于通知所有提供者更新缓存或日志等本地资源信息。</li>
</ul>
<h2 id="13-Dubbo超时设置有哪些方式？"><a href="#13-Dubbo超时设置有哪些方式？" class="headerlink" title="13. Dubbo超时设置有哪些方式？"></a>13. Dubbo超时设置有哪些方式？</h2><p>Dubbo超时设置有两种方式：</p>
<ul>
<li>服务提供者端设置超时时间，在Dubbo的用户文档中，推荐如果能在服务端多配置就尽量多配置，因为服务提供者比消费者更清楚自己提供的服务特性。</li>
<li>服务消费者端设置超时时间，如果在消费者端设置了超时时间，以消费者端为主，即优先级更高。因为服务调用方设置超时时间控制性更灵活。如果消费方超时，服务端线程不会定制，会产生警告。</li>
</ul>
<h2 id="14-Dubbo用到哪些设计模式？"><a href="#14-Dubbo用到哪些设计模式？" class="headerlink" title="14. Dubbo用到哪些设计模式？"></a>14. Dubbo用到哪些设计模式？</h2><p>1、<strong>工厂模式</strong></p>
<p>Provider 在 export 服务时，会调用 ServiceConfig 的 export 方法。ServiceConfig中有个字段：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">private static final Protocol protocol =</span><br><span class="line">ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtensi</span><br><span class="line">on();</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure>

<p>Dubbo里有很多这种代码。这也是一种工厂模式，只是实现类的获取采用了 JDKSPI 的机制。这么实现的优点是可扩展性强，想要扩展实现，只需要在 classpath下增加个文件就可以了，代码零侵入。另外，像上面的 Adaptive 实现，可以做到调用时动态决定调用哪个实现，但是由于这种实现采用了动态代理，会造成代码调试比较麻烦，需要分析出实际调用的实现类。</p>
<p>2、<strong>装饰器模式</strong></p>
<p>Dubbo在启动和调用阶段都大量使用了装饰器模式。以 Provider 提供的调用链为例，具体的调用链代码是在 ProtocolFilterWrapper 的 buildInvokerChain 完成的，具体是将注解中含有 group&#x3D;provider 的 Filter 实现，按照 order 排序，最后的调用顺序是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">EchoFilter -&gt; ClassLoaderFilter -&gt; GenericFilter -&gt; ContextFilter -&gt;</span><br><span class="line">ExecuteLimitFilter -&gt; TraceFilter -&gt; TimeoutFilter -&gt; MonitorFilter -&gt;</span><br><span class="line">ExceptionFilter</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure>

<p>更确切地说，这里是装饰器和责任链模式的混合使用。例如，EchoFilter 的作用是判断是否是回声测试请求，是的话直接返回内容，这是一种责任链的体现。而像ClassLoaderFilter 则只是在主功能上添加了功能，更改当前线程的 ClassLoader，这是典型的装饰器模式。</p>
<p>3、<strong>观察者模式</strong></p>
<p>Dubbo的 Provider 启动时，需要与注册中心交互，先注册自己的服务，再订阅自己的服务，订阅时，采用了观察者模式，开启一个 listener。注册中心会每 5 秒定时检查是否有服务更新，如果有更新，向该服务的提供者发送一个 notify 消息，provider 接受到 notify 消息后，运行 NotifyListener 的 notify 方法，执行监听器方法。</p>
<p>4、<strong>动态代理模式</strong></p>
<p>Dubbo扩展 JDK SPI 的类 ExtensionLoader 的 Adaptive 实现是典型的动态代理实现。Dubbo需要灵活地控制实现类，即在调用阶段动态地根据参数决定调用哪个实现类，所以采用先生成代理类的方法，能够做到灵活的调用。生成代理类的代码是 ExtensionLoader 的 createAdaptiveExtensionClassCode 方法。代理类主要逻辑是，获取 URL 参数中指定参数的值作为获取实现类的 key。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/02/Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98/" data-id="cl3wpioek0001o0r44zz45xqm" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-计算机网络下" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8B/" class="article-date">
  <time class="dt-published" datetime="2022-06-02T07:38:17.430Z" itemprop="datePublished">2022-06-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>计算机网络面试题第二期来了，话不多说，先收藏再看吧~</p>
<p>看下本期的目录：</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210525175906351.png" alt="目录"></p>
<h2 id="1-HTTP常见的状态码有哪些？"><a href="#1-HTTP常见的状态码有哪些？" class="headerlink" title="1. HTTP常见的状态码有哪些？"></a>1. HTTP常见的状态码有哪些？</h2><p>常见状态码：</p>
<ul>
<li>200：服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。</li>
<li>301 ： (永久移动) 请求的网页已永久移动到新位置。 服务器返回此响应(对 GET 或 HEAD 请求的响应)时，会自动将请求者转到新位置。</li>
<li>302：(临时移动) 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。</li>
<li>400 ：客户端请求有语法错误，不能被服务器所理解。</li>
<li>403 ：服务器收到请求，但是拒绝提供服务。</li>
<li>404 ：(未找到) 服务器找不到请求的网页。</li>
<li>500： (服务器内部错误) 服务器遇到错误，无法完成请求。</li>
</ul>
<p>状态码开头代表类型：</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210525114439748.png"></p>
<h2 id="2-状态码301和302的区别是什么？"><a href="#2-状态码301和302的区别是什么？" class="headerlink" title="2. 状态码301和302的区别是什么？"></a>2. 状态码301和302的区别是什么？</h2><p><strong>共同点</strong>：301和302状态码都表示重定向，就是说浏览器在拿到服务器返回的这个状态码后会自动跳转到一个新的URL地址，这个地址可以从响应的Location首部中获取（<strong>用户看到的效果就是他输入的地址A瞬间变成了另一个地址B</strong>）。<br><strong>不同点</strong>：301表示旧地址A的资源已经被永久地移除了(这个资源不可访问了)，搜索引擎在抓取新内容的同时也将旧的网址交换为重定向之后的网址；302表示旧地址A的资源还在（仍然可以访问），这个重定向只是临时地从旧地址A跳转到地址B，搜索引擎会抓取新的内容而保存旧的网址。 SEO中302好于301。</p>
<p><strong>补充，重定向原因</strong>：</p>
<ol>
<li>网站调整（如改变网页目录结构）；</li>
<li>网页被移到一个新地址；</li>
<li>网页扩展名改变(如应用需要把.php改成.Html或.shtml)。</li>
</ol>
<h2 id="3-HTTP-常用的请求方式？"><a href="#3-HTTP-常用的请求方式？" class="headerlink" title="3. HTTP 常用的请求方式？"></a>3. HTTP 常用的请求方式？</h2><table>
<thead>
<tr>
<th>方法</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>GET</td>
<td>获取资源</td>
</tr>
<tr>
<td>POST</td>
<td>传输实体主体</td>
</tr>
<tr>
<td>PUT</td>
<td>上传文件</td>
</tr>
<tr>
<td>DELETE</td>
<td>删除文件</td>
</tr>
<tr>
<td>HEAD</td>
<td>和GET方法类似，但只返回报文首部，不返回报文实体主体部分</td>
</tr>
<tr>
<td>PATCH</td>
<td>对资源进行部分修改</td>
</tr>
<tr>
<td>OPTIONS</td>
<td>查询指定的URL支持的方法</td>
</tr>
<tr>
<td>CONNECT</td>
<td>要求用隧道协议连接代理</td>
</tr>
<tr>
<td>TRACE</td>
<td>服务器会将通信路径返回给客户端</td>
</tr>
</tbody></table>
<p>为了方便记忆，可以将PUT、DELETE、POST、GET理解为客户端对服务端的增删改查。</p>
<ul>
<li>PUT：上传文件，向服务器添加数据，可以看作增</li>
<li>DELETE：删除文件</li>
<li>POST：传输数据，向服务器提交数据，对服务器数据进行更新。</li>
<li>GET：获取资源，查询服务器资源</li>
</ul>
<h2 id="4-GET请求和POST请求的区别？"><a href="#4-GET请求和POST请求的区别？" class="headerlink" title="4. GET请求和POST请求的区别？"></a>4. GET请求和POST请求的区别？</h2><p><strong>使用上的区别</strong>：</p>
<ul>
<li><p>GET使用URL或Cookie传参，而POST将数据放在BODY中”，这个是因为HTTP协议用法的约定。</p>
</li>
<li><p>GET方式提交的数据有长度限制，则POST的数据则可以非常大”，这个是因为它们使用的操作系统和浏览器设置的不同引起的区别。</p>
</li>
<li><p>POST比GET安全，因为数据在地址栏上不可见”，这个说法没毛病，但依然不是GET和POST本身的区别。</p>
</li>
</ul>
<p><strong>本质区别</strong></p>
<p>GET和POST最大的区别主要是GET请求是幂等性的，POST请求不是。这个是它们本质区别。</p>
<p>幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。</p>
<h2 id="5-解释一下HTTP长连接和短连接？"><a href="#5-解释一下HTTP长连接和短连接？" class="headerlink" title="5. 解释一下HTTP长连接和短连接？"></a>5. 解释一下HTTP长连接和短连接？</h2><p><strong>在HTTP&#x2F;1.0中，默认使用的是短连接</strong>。也就是说，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。如果客户端浏览器访问的某个HTML或其他类型的 Web页中包含有其他的Web资源，如JavaScript文件、图像文件、CSS文件等；当浏览器每遇到这样一个Web资源，就会建立一个HTTP会话。</p>
<p>但从 <strong>HTTP&#x2F;1.1起，默认使用长连接</strong>，用以保持连接特性。使用长连接的HTTP协议，会在响应头有加入这行代码：<code>Connection:keep-alive</code></p>
<p>在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的 TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接要客户端和服务端都支持长连接。</p>
<p><strong>HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。</strong></p>
<h2 id="6-HTTP请求报文和响应报文的格式？"><a href="#6-HTTP请求报文和响应报文的格式？" class="headerlink" title="6. HTTP请求报文和响应报文的格式？"></a>6. HTTP请求报文和响应报文的格式？</h2><p><strong>请求报文格式</strong>：</p>
<ol>
<li>请求行（请求方法+URI协议+版本）</li>
<li>请求头部</li>
<li>空行</li>
<li>请求主体</li>
</ol>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">GET/sample.jspHTTP/1.1 请求行</span><br><span class="line">Accept:image/gif.image/jpeg, 请求头部</span><br><span class="line">Accept-Language:zh-cn</span><br><span class="line">Connection:Keep-Alive</span><br><span class="line">Host:localhost</span><br><span class="line">User-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0)</span><br><span class="line">Accept-Encoding:gzip,deflate</span><br><span class="line"></span><br><span class="line">username=jinqiao&amp;password=1234 请求主体</span><br></pre></td></tr></table></figure>

<p><strong>响应报文</strong>：</p>
<ol>
<li>状态行（版本+状态码+原因短语）</li>
<li>响应首部</li>
<li>空行</li>
<li>响应主体</li>
</ol>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server:Apache Tomcat/5.0.12</span><br><span class="line">Date:Mon,6Oct2003 13:23:42 GMT</span><br><span class="line">Content-Length:112</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>HTTP响应示例<span class="tag">&lt;<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        Hello HTTP!</span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="7-HTTP1-0和HTTP1-1的区别"><a href="#7-HTTP1-0和HTTP1-1的区别" class="headerlink" title="7. HTTP1.0和HTTP1.1的区别?"></a>7. HTTP1.0和HTTP1.1的区别?</h2><ul>
<li><p><strong>长连接</strong>：HTTP 1.1支持长连接（Persistent Connection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启<code>Connection： keep-alive</code>，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。</p>
</li>
<li><p><strong>缓存处理</strong>：在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略，可供选择的缓存头来控制缓存策略。</p>
</li>
<li><p><strong>带宽优化及网络连接的使用</strong>：HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。</p>
</li>
<li><p><strong>错误通知的管理</strong>：在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。</p>
</li>
<li><p><strong>Host头处理</strong>：在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。</p>
</li>
</ul>
<h2 id="8-HTTP1-1和-HTTP2-0的区别？"><a href="#8-HTTP1-1和-HTTP2-0的区别？" class="headerlink" title="8. HTTP1.1和 HTTP2.0的区别？"></a>8. HTTP1.1和 HTTP2.0的区别？</h2><p>HTTP2.0相比HTTP1.1支持的特性：</p>
<ul>
<li><p><strong>新的二进制格式</strong>：HTTP1.1的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。</p>
</li>
<li><p><strong>多路复用</strong>，即连接共享，即每一个request都是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。</p>
</li>
<li><p><strong>头部压缩</strong>，HTTP1.1的头部（header）带有大量信息，而且每次都要重复发送；HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。</p>
</li>
<li><p><strong>服务端推送</strong>：服务器除了对最初请求的响应外，服务器还可以额外的向客户端推送资源，而无需客户端明确的请求。</p>
</li>
</ul>
<h2 id="9-HTTP-与-HTTPS-的区别？"><a href="#9-HTTP-与-HTTPS-的区别？" class="headerlink" title="9. HTTP 与 HTTPS 的区别？"></a>9. HTTP 与 HTTPS 的区别？</h2><table>
<thead>
<tr>
<th align="center"></th>
<th align="center">HTTP</th>
<th>HTTPS</th>
</tr>
</thead>
<tbody><tr>
<td align="center">端口</td>
<td align="center">80</td>
<td>443</td>
</tr>
<tr>
<td align="center">安全性</td>
<td align="center">无加密，安全性较差</td>
<td>有加密机制，安全性较高</td>
</tr>
<tr>
<td align="center">资源消耗</td>
<td align="center">较少</td>
<td>由于加密处理，资源消耗更多</td>
</tr>
<tr>
<td align="center">是否需要证书</td>
<td align="center">不需要</td>
<td>需要</td>
</tr>
<tr>
<td align="center">协议</td>
<td align="center">运行在TCP协议之上</td>
<td>运行在SSL协议之上，SSL运行在TCP协议之上</td>
</tr>
</tbody></table>
<h2 id="10-HTTPS-的优缺点"><a href="#10-HTTPS-的优缺点" class="headerlink" title="10. HTTPS 的优缺点?"></a>10. HTTPS 的优缺点?</h2><p><strong>优点</strong>：</p>
<ul>
<li><p>安全性：</p>
<ul>
<li><p>使用HTTPS协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；</p>
</li>
<li><p>HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性。</p>
</li>
<li><p>HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。</p>
</li>
</ul>
</li>
<li><p>SEO方面：谷歌曾在2014年8月份调整搜索引擎算法，并称“比起同等HTTP网站，采用HTTPS加密的网站在搜索结果中的排名将会更高”。</p>
</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>在相同网络环境中，HTTPS 相比 HTTP 无论是响应时间还是耗电量都有大幅度上升。</li>
<li>HTTPS 的安全是有范围的，在黑客攻击、服务器劫持等情况下几乎起不到作用。</li>
<li>在现有的证书机制下，中间人攻击依然有可能发生。</li>
<li>HTTPS 需要更多的服务器资源，也会导致成本的升高。</li>
</ul>
<h2 id="11-讲一讲HTTPS-的原理？"><a href="#11-讲一讲HTTPS-的原理？" class="headerlink" title="11. 讲一讲HTTPS 的原理？"></a>11. 讲一讲HTTPS 的原理？</h2><p><img src="http://blog-img.coolsen.cn/img/image-20210525160006424.png"></p>
<blockquote>
<p>图片来源：<a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000021494676">https://segmentfault.com/a/1190000021494676</a></p>
</blockquote>
<p>加密流程按图中的序号分为：</p>
<ol>
<li><p>客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，类似于 HTTP 的80端口)。</p>
</li>
<li><p>采用 HTTPS 协议的服务器必须要有一套数字 CA (Certification Authority)证书。颁发证书的同时会产生一个私钥和公钥。私钥由服务端自己保存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。</p>
</li>
<li><p>服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，比如证书颁发机构信息，公司信息和证书有效期等。</p>
</li>
<li><p>客户端解析证书并对其进行验证。如果证书不是可信机构颁布，或者证书中的域名与实际域名不一致，或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。</p>
<p>如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥A。然后客户端还会生成一个随机码 KEY，并使用公钥A将其加密。</p>
</li>
<li><p>客户端把加密后的随机码 KEY 发送给服务器，作为后面对称加密的密钥。</p>
</li>
<li><p>服务器在收到随机码 KEY 之后会使用私钥B将其解密。经过以上这些步骤，客户端和服务器终于建立了安全连接，完美解决了对称加密的密钥泄露问题，接下来就可以用对称加密愉快地进行通信了。</p>
</li>
<li><p>服务器使用密钥 (随机码 KEY)对数据进行对称加密并发送给客户端，客户端使用相同的密钥 (随机码 KEY)解密数据。</p>
</li>
<li><p>双方使用对称加密愉快地传输所有数据。</p>
</li>
</ol>
<h2 id="12-在浏览器中输入www-baidu-com后执行的全部过程？"><a href="#12-在浏览器中输入www-baidu-com后执行的全部过程？" class="headerlink" title="12. 在浏览器中输入www.baidu.com后执行的全部过程？"></a>12. 在浏览器中输入<a href="http://www.baidu.com后执行的全部过程？">www.baidu.com后执行的全部过程？</a></h2><ol>
<li><p>域名解析（域名 <a target="_blank" rel="noopener" href="http://www.baidu.com/">www.baidu.com </a>变为 ip 地址）。</p>
<p><strong>浏览器搜索自己的DNS缓存</strong>（维护一张域名与IP的对应表）；若没有，则搜索<strong>操作系统的DNS缓存</strong>（维护一张域名与IP的对应表）；若没有，则搜索操作系统的<strong>hosts文件</strong>（维护一张域名与IP的对应表）。</p>
<p>若都没有，则找 tcp&#x2F;ip 参数中设置的首选 dns 服务器，即<strong>本地 dns 服务器</strong>（递归查询），<strong>本地域名服务器查询自己的dns缓存</strong>，如果没有，则进行迭代查询。将本地dns服务器将IP返回给操作系统，同时缓存IP。</p>
</li>
<li><p>发起 tcp 的三次握手，建立 tcp 连接。浏览器会以一个随机端口（1024-65535）向服务端的 web 程序 <strong>80</strong> 端口发起 tcp 的连接。</p>
</li>
<li><p>建立 tcp 连接后发起 http 请求。</p>
</li>
<li><p>服务器响应 http 请求，客户端得到 html 代码。服务器 web 应用程序收到 http 请求后，就开始处理请求，处理之后就返回给浏览器 html 文件。</p>
</li>
<li><p>浏览器解析 html 代码，并请求 html 中的资源。</p>
</li>
<li><p>浏览器对页面进行渲染，并呈现给用户。</p>
</li>
</ol>
<p>附一张形象的图片：<img src="http://blog-img.coolsen.cn/img/image-20210525172545204.png"></p>
<h2 id="13-什么是-Cookie-和-Session"><a href="#13-什么是-Cookie-和-Session" class="headerlink" title="13. 什么是 Cookie 和 Session ?"></a>13. 什么是 Cookie 和 Session ?</h2><p><strong>什么是 Cookie</strong></p>
<p>HTTP Cookie（也叫 Web Cookie或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能。</p>
<p>Cookie 主要用于以下三个方面：</p>
<ul>
<li>会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）</li>
<li>个性化设置（如用户自定义设置、主题等）</li>
<li>浏览器行为跟踪（如跟踪分析用户行为等）</li>
</ul>
<p><strong>什么是 Session</strong></p>
<p>Session 代表着服务器和客户端一次会话的过程。Session 对象存储特定用户会话所需的属性及配置信息。这样，当用户在应用程序的 Web 页之间跳转时，存储在 Session 对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当客户端关闭会话，或者 Session 超时失效时会话结束。</p>
<h2 id="14-Cookie-和-Session-是如何配合的呢？"><a href="#14-Cookie-和-Session-是如何配合的呢？" class="headerlink" title="14. Cookie 和 Session 是如何配合的呢？"></a>14. Cookie 和 Session 是如何配合的呢？</h2><p>用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 Session ，请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器，浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名。</p>
<p>当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。</p>
<p>根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分系统也是根据此原理来验证用户登录状态。</p>
<h2 id="15-Cookie和Session的区别？"><a href="#15-Cookie和Session的区别？" class="headerlink" title="15. Cookie和Session的区别？"></a>15. Cookie和Session的区别？</h2><ul>
<li>作用范围不同，Cookie 保存在客户端（浏览器），Session 保存在服务器端。</li>
<li>存取方式的不同，Cookie 只能保存 ASCII，Session 可以存任意数据类型，一般情况下我们可以在 Session 中保持一些常用变量信息，比如说 UserId 等。</li>
<li>有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。</li>
<li>隐私策略不同，Cookie 存储在客户端，比较容易遭到不法获取，早期有人将用户的登录名和密码存储在 Cookie 中导致信息被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。</li>
<li>存储大小不同， 单个 Cookie 保存的数据不能超过 4K，Session 可存储数据远高于 Cookie。</li>
</ul>
<h2 id="16-如何考虑分布式-Session-问题？"><a href="#16-如何考虑分布式-Session-问题？" class="headerlink" title="16. 如何考虑分布式 Session 问题？"></a>16. 如何考虑分布式 Session 问题？</h2><p>在互联网公司为了可以支撑更大的流量，后端往往需要多台服务器共同来支撑前端用户请求，那如果用户在 A 服务器登录了，第二次请求跑到服务 B 就会出现登录失效问题。</p>
<p>分布式 Session 一般会有以下几种解决方案：</p>
<ul>
<li><strong>客户端存储</strong>：直接将信息存储在cookie中，cookie是存储在客户端上的一小段数据，客户端通过http协议和服务器进行cookie交互，通常用来存储一些不敏感信息</li>
</ul>
<ul>
<li><strong>Nginx ip_hash 策略</strong>：服务端使用 Nginx 代理，每个请求按访问 IP 的 hash 分配，这样来自同一 IP 固定访问一个后台服务器，避免了在服务器 A 创建 Session，第二次分发到服务器 B 的现象。</li>
<li><strong>Session 复制</strong>：任何一个服务器上的 Session 发生改变（增删改），该节点会把这个 Session 的所有内容序列化，然后广播给所有其它节点。</li>
<li><strong>共享 Session</strong>：服务端无状态话，将用户的 Session 等信息使用缓存中间件（如Redis）来统一管理，保障分发到每一个服务器的响应结果都一致。</li>
</ul>
<p>建议采用共享 Session的方案。</p>
<h2 id="17-什么是DDos攻击？"><a href="#17-什么是DDos攻击？" class="headerlink" title="17. 什么是DDos攻击？"></a>17. 什么是DDos攻击？</h2><p>DDos全称Distributed Denial of Service，分布式拒绝服务攻击。最基本的DOS攻击过程如下：</p>
<ol>
<li>客户端向服务端发送请求链接数据包。</li>
<li>服务端向客户端发送确认数据包。</li>
<li>客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认</li>
</ol>
<p>DDoS则是采用分布式的方法，通过在网络上占领多台“肉鸡”，用多台计算机发起攻击。</p>
<p>DOS攻击现在基本没啥作用了，因为服务器的性能都很好，而且是多台服务器共同作用，1V1的模式黑客无法占上风。对于DDOS攻击，预防方法有：</p>
<ul>
<li><strong>减少SYN timeout时间</strong>。在握手的第三步，服务器会等待30秒-120秒的时间，减少这个等待时间就能释放更多的资源。</li>
<li><strong>限制同时打开的SYN半连接数目。</strong></li>
</ul>
<h2 id="18-什么是XSS攻击？"><a href="#18-什么是XSS攻击？" class="headerlink" title="18. 什么是XSS攻击？"></a>18. 什么是XSS攻击？</h2><p>XSS也称 cross-site scripting，<strong>跨站脚本</strong>。这种攻击是<strong>由于服务器将攻击者存储的数据原原本本地显示给其他用户所致的</strong>。比如一个存在XSS漏洞的论坛，用户发帖时就可以引入<strong>带有＜script＞标签的代码</strong>，导致恶意代码的执行。</p>
<p>预防措施有：</p>
<ul>
<li>前端：过滤。</li>
<li>后端：转义，比如go自带的处理器就具有转义功能。</li>
</ul>
<h2 id="19-SQL注入是什么，如何避免SQL注入？"><a href="#19-SQL注入是什么，如何避免SQL注入？" class="headerlink" title="19. SQL注入是什么，如何避免SQL注入？"></a>19. SQL注入是什么，如何避免SQL注入？</h2><p>SQL 注入就是在用户输入的字符串中加入 SQL 语句，如果在设计不良的程序中忽略了检查，那么这些注入进去的 SQL 语句就会被数据库服务器误认为是正常的 SQL 语句而运行，攻击者就可以执行计划外的命令或访问未被授权的数据。</p>
<p><strong>SQL注入的原理主要有以下 4 点</strong></p>
<ul>
<li>恶意拼接查询</li>
<li>利用注释执行非法命令</li>
<li>传入非法参数</li>
<li>添加额外条件</li>
</ul>
<p><strong>避免SQL注入的一些方法</strong>：</p>
<ul>
<li>限制数据库权限，给用户提供仅仅能够满足其工作的最低权限。</li>
<li>对进入数据库的特殊字符（’”\尖括号&amp;*;等）转义处理。</li>
<li>提供参数化查询接口，不要直接使用原生SQL。</li>
</ul>
<h2 id="20-负载均衡算法有哪些？"><a href="#20-负载均衡算法有哪些？" class="headerlink" title="20. 负载均衡算法有哪些？"></a>20. 负载均衡算法有哪些？</h2><p>多台服务器以对称的方式组成一个服务器集合，每台服务器都具有等价的地位，能互相分担负载。</p>
<ul>
<li>轮询法：将请求按照顺序轮流的分配到服务器上。大锅饭，不能发挥某些高性能服务器的优势。</li>
<li>随机法：随机获取一台，和轮询类似。</li>
<li>哈希法：通过ip地址哈希化来确定要选择的服务器编号。好处是,每次客户端访问的服务器都是同一个服务器，能很好地利用session或者cookie。</li>
<li>加权轮询：根据服务器性能不同加权。</li>
</ul>
<h2 id="End"><a href="#End" class="headerlink" title="End"></a>End</h2><p>更文不易，点赞鼓励下呗~我将持续输出干货，与你共同成长～</p>
<p>还有，秋招求职交流群持续开放，扫码加我，备注秋招，拉你进群。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210508163936952.png"></p>
<h2 id="巨人的肩膀"><a href="#巨人的肩膀" class="headerlink" title="巨人的肩膀"></a>巨人的肩膀</h2><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844903890840715271">https://juejin.cn/post/6844903890840715271</a></p>
<p><a target="_blank" rel="noopener" href="https://www.justdojava.com/2019/11/03/Network_interview_question/">https://www.justdojava.com/2019/11/03/Network_interview_question/</a></p>
<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844903489596833800">https://juejin.cn/post/6844903489596833800</a></p>
<p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000021494676">https://segmentfault.com/a/1190000021494676</a></p>
<p><a target="_blank" rel="noopener" href="https://jiangren.work/2020/02/16/">https://jiangren.work/2020/02/16/</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/ityouknow/p/10856177.html">https://www.cnblogs.com/ityouknow/p/10856177.html</a></p>
<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844903575684907016">https://juejin.cn/post/6844903575684907016</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8B/" data-id="cl3wpiog0000jo0r4ghvc9fk5" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-计算机网络上" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8A/" class="article-date">
  <time class="dt-published" datetime="2022-06-02T07:38:17.422Z" itemprop="datePublished">2022-06-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>因公众号开通较晚，无留言功能，想要交流的小伙伴可加我个人微信：coolsen666</p>
<p>互联网公司的面试中，计算机网络可以说是必考题目。计算机网络知识点也非常多，库森特将面试题分为多期，今天先来看下第一期。</p>
<p>老规矩，先收藏再看~</p>
<p>看下本期的目录吧</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210520220202590.png"></p>
<h2 id="1-计算机网络的各层协议及作用？"><a href="#1-计算机网络的各层协议及作用？" class="headerlink" title="1. 计算机网络的各层协议及作用？"></a>1. 计算机网络的各层协议及作用？</h2><p>计算机网络体系可以大致分为一下三种，OSI七层模型、TCP&#x2F;IP四层模型和五层模型。</p>
<ul>
<li>OSI七层模型：大而全，但是比较复杂、而且是先有了理论模型，没有实际应用。</li>
<li>TCP&#x2F;IP四层模型：是由实际应用发展总结出来的，从实质上讲，TCP&#x2F;IP只有最上面三层，最下面一层没有什么具体内容，TCP&#x2F;IP参考模型没有真正描述这一层的实现。</li>
<li>五层模型：五层模型只出现在计算机网络教学过程中，这是对七层模型和四层模型的一个折中，既简洁又能将概念阐述清楚。</li>
</ul>
<p><img src="http://blog-img.coolsen.cn/img/image-20210519165421341.png" alt="计算机网络体系结构"></p>
<p>七层网络体系结构各层的主要功能：</p>
<ul>
<li><p>应用层：为应用程序提供交互服务。在互联网中的应用层协议很多，如域名系统DNS，支持万维网应用的HTTP协议，支持电子邮件的SMTP协议等。</p>
</li>
<li><p>表示层：主要负责数据格式的转换，如加密解密、转换翻译、压缩解压缩等。</p>
</li>
<li><p>会话层：负责在网络中的两节点之间建立、维持和终止通信，如服务器验证用户登录便是由会话层完成的。</p>
</li>
<li><p>运输层：有时也译为传输层，向主机进程提供通用的数据传输服务。该层主要有以下两种协议：</p>
<ul>
<li>TCP：提供面向连接的、可靠的数据传输服务；</li>
<li>UDP：提供无连接的、尽最大努力的数据传输服务，但不保证数据传输的可靠性。</li>
</ul>
</li>
<li><p>网络层：选择合适的路由和交换结点，确保数据及时传送。主要包括IP协议。</p>
</li>
<li><p>数据链路层：数据链路层通常简称为链路层。将网络层传下来的IP数据包组装成帧，并再相邻节点的链路上传送帧。</p>
</li>
<li><p><code>物理层</code>：实现相邻节点间比特流的透明传输，尽可能屏蔽传输介质和通信手段的差异。</p>
</li>
</ul>
<h2 id="2-TCP和UDP的区别？"><a href="#2-TCP和UDP的区别？" class="headerlink" title="2. TCP和UDP的区别？"></a>2. TCP和UDP的区别？</h2><p><strong>对比如下</strong>：</p>
<table>
<thead>
<tr>
<th align="left"></th>
<th align="left">UDP</th>
<th align="left">TCP</th>
</tr>
</thead>
<tbody><tr>
<td align="left">是否连接</td>
<td align="left">无连接</td>
<td align="left">面向连接</td>
</tr>
<tr>
<td align="left">是否可靠</td>
<td align="left">不可靠传输，不使用流量控制和拥塞控制</td>
<td align="left">可靠传输，使用流量控制和拥塞控制</td>
</tr>
<tr>
<td align="left">是否有序</td>
<td align="left">无序</td>
<td align="left">有序，消息在传输过程中可能会乱序，TCP 会重新排序</td>
</tr>
<tr>
<td align="left">传输速度</td>
<td align="left">快</td>
<td align="left">慢</td>
</tr>
<tr>
<td align="left">连接对象个数</td>
<td align="left">支持一对一，一对多，多对一和多对多交互通信</td>
<td align="left">只能是一对一通信</td>
</tr>
<tr>
<td align="left">传输方式</td>
<td align="left">面向报文</td>
<td align="left">面向字节流</td>
</tr>
<tr>
<td align="left">首部开销</td>
<td align="left">首部开销小，仅8字节</td>
<td align="left">首部最小20字节，最大60字节</td>
</tr>
<tr>
<td align="left">适用场景</td>
<td align="left">适用于实时应用（IP电话、视频会议、直播等）</td>
<td align="left">适用于要求可靠传输的应用，例如文件传输</td>
</tr>
</tbody></table>
<p><strong>总结</strong>：</p>
<p>TCP 用于在传输层有必要实现可靠传输的情况，UDP 用于对高速传输和实时性有较高要求的通信。TCP 和 UDP 应该根据应用目的按需使用。</p>
<h2 id="3-UDP-和-TCP-对应的应用场景是什么？"><a href="#3-UDP-和-TCP-对应的应用场景是什么？" class="headerlink" title="3. UDP 和 TCP 对应的应用场景是什么？"></a>3. UDP 和 TCP 对应的应用场景是什么？</h2><p> TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：</p>
<ul>
<li>FTP文件传输</li>
<li>HTTP &#x2F; HTTPS</li>
</ul>
<p>UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：</p>
<ul>
<li>包总量较少的通信，如 DNS 、SNMP等</li>
<li>视频、音频等多媒体通信</li>
<li>广播通信</li>
</ul>
<p><img src="http://blog-img.coolsen.cn/img/image-20210519180008296.png" alt="image-20210519180008296"></p>
<h2 id="4-详细介绍一下-TCP-的三次握手机制？"><a href="#4-详细介绍一下-TCP-的三次握手机制？" class="headerlink" title="4. 详细介绍一下 TCP 的三次握手机制？"></a>4. 详细介绍一下 TCP 的三次握手机制？</h2><p><img src="http://blog-img.coolsen.cn/img/image-20210520161056918.png"></p>
<blockquote>
<p>图片来自：<a target="_blank" rel="noopener" href="https://juejin.cn/post/6844904005315854343">https://juejin.cn/post/6844904005315854343</a></p>
</blockquote>
<p>三次握手机制：</p>
<ul>
<li><p>第一次握手：客户端请求建立连接，向服务端发送一个<strong>同步报文</strong>（SYN&#x3D;1），同时选择一个随机数 seq &#x3D; x 作为<strong>初始序列号</strong>，并进入SYN_SENT状态，等待服务器确认。</p>
</li>
<li><p>第二次握手：：服务端收到连接请求报文后，如果同意建立连接，则向客户端发送<strong>同步确认报文</strong>（SYN&#x3D;1，ACK&#x3D;1），确认号为 ack &#x3D; x + 1，同时选择一个随机数 seq &#x3D; y 作为初始序列号，此时服务器进入SYN_RECV状态。</p>
</li>
<li><p>第三次握手：客户端收到服务端的确认后，向服务端发送一个<strong>确认报文</strong>（ACK&#x3D;1），确认号为 ack &#x3D; y + 1，序列号为 seq &#x3D; x + 1，客户端和服务器进入ESTABLISHED状态，完成三次握手。</p>
</li>
</ul>
<p>理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。</p>
<h2 id="5-为什么需要三次握手，而不是两次？"><a href="#5-为什么需要三次握手，而不是两次？" class="headerlink" title="5. 为什么需要三次握手，而不是两次？"></a>5. 为什么需要三次握手，而不是两次？</h2><p>主要有三个原因：</p>
<ol>
<li><p>防止已过期的连接请求报文突然又传送到服务器，因而产生错误和资源浪费。</p>
<p>在双方两次握手即可建立连接的情况下，假设客户端发送 A 报文段请求建立连接，由于网络原因造成 A 暂时无法到达服务器，服务器接收不到请求报文段就不会返回确认报文段。</p>
<p>客户端在长时间得不到应答的情况下重新发送请求报文段 B，这次 B 顺利到达服务器，服务器随即返回确认报文并进入 ESTABLISHED 状态，客户端在收到 确认报文后也进入 ESTABLISHED 状态，双方建立连接并传输数据，之后正常断开连接。</p>
<p>此时姗姗来迟的 A 报文段才到达服务器，服务器随即返回确认报文并进入 ESTABLISHED 状态，但是已经进入 CLOSED 状态的客户端无法再接受确认报文段，更无法进入 ESTABLISHED 状态，这将导致服务器长时间单方面等待，造成资源浪费。</p>
</li>
<li><p>三次握手才能让双方均确认自己和对方的发送和接收能力都正常。</p>
<p>第一次握手：客户端只是发送处请求报文段，什么都无法确认，而服务器可以确认自己的接收能力和对方的发送能力正常；</p>
<p>第二次握手：客户端可以确认自己发送能力和接收能力正常，对方发送能力和接收能力正常；</p>
<p>第三次握手：服务器可以确认自己发送能力和接收能力正常，对方发送能力和接收能力正常；</p>
<p>可见三次握手才能让双方都确认自己和对方的发送和接收能力全部正常，这样就可以愉快地进行通信了。</p>
</li>
<li><p>告知对方自己的初始序号值，并确认收到对方的初始序号值。</p>
<p>TCP 实现了可靠的数据传输，原因之一就是 TCP 报文段中维护了序号字段和确认序号字段，通过这两个字段双方都可以知道在自己发出的数据中，哪些是已经被对方确认接收的。这两个字段的值会在初始序号值得基础递增，如果是两次握手，只有发起方的初始序号可以得到确认，而另一方的初始序号则得不到确认。</p>
</li>
</ol>
<h2 id="6-为什么要三次握手，而不是四次？"><a href="#6-为什么要三次握手，而不是四次？" class="headerlink" title="6. 为什么要三次握手，而不是四次？"></a>6. 为什么要三次握手，而不是四次？</h2><p>因为三次握手已经可以确认双方的发送接收能力正常，双方都知道彼此已经准备好，而且也可以完成对双方初始序号值得确认，也就无需再第四次握手了。</p>
<ul>
<li>第一次握手：服务端确认“自己收、客户端发”报文功能正常。</li>
<li>第二次握手：客户端确认“自己发、自己收、服务端收、客户端发”报文功能正常，客户端认为连接已建立。</li>
<li>第三次握手：服务端确认“自己发、客户端收”报文功能正常，此时双方均建立连接，可以正常通信。</li>
</ul>
<h2 id="7-什么是-SYN洪泛攻击？如何防范？"><a href="#7-什么是-SYN洪泛攻击？如何防范？" class="headerlink" title="7. 什么是 SYN洪泛攻击？如何防范？"></a>7. 什么是 SYN洪泛攻击？如何防范？</h2><p>SYN洪泛攻击属于 DOS 攻击的一种，它利用 TCP 协议缺陷，通过发送大量的半连接请求，耗费 CPU 和内存资源。</p>
<p>原理：</p>
<ul>
<li>在三次握手过程中，服务器发送 <code>[SYN/ACK]</code> 包（第二个包）之后、收到客户端的 <code>[ACK]</code> 包（第三个包）之前的 TCP 连接称为半连接（half-open connect），此时服务器处于 <code>SYN_RECV</code>（等待客户端响应）状态。如果接收到客户端的 <code>[ACK]</code>，则 TCP 连接成功，如果未接受到，则会<strong>不断重发请求</strong>直至成功。</li>
<li>SYN 攻击的攻击者在短时间内<strong>伪造大量不存在的 IP 地址</strong>，向服务器不断地发送 <code>[SYN]</code> 包，服务器回复 <code>[SYN/ACK]</code> 包，并等待客户的确认。由于源地址是不存在的，服务器需要不断的重发直至超时。</li>
<li>这些伪造的 <code>[SYN]</code> 包将长时间占用未连接队列，影响了正常的 SYN，导致目标系统运行缓慢、网络堵塞甚至系统瘫痪。</li>
</ul>
<p>检测：当在服务器上看到大量的半连接状态时，特别是源 IP 地址是随机的，基本上可以断定这是一次 SYN 攻击。</p>
<p>防范：</p>
<ul>
<li>通过防火墙、路由器等过滤网关防护。</li>
<li>通过加固 TCP&#x2F;IP 协议栈防范，如增加最大半连接数，缩短超时时间。</li>
<li>SYN cookies技术。SYN Cookies 是对 TCP 服务器端的三次握手做一些修改，专门用来防范 SYN 洪泛攻击的一种手段。</li>
</ul>
<h2 id="8-三次握手连接阶段，最后一次ACK包丢失，会发生什么？"><a href="#8-三次握手连接阶段，最后一次ACK包丢失，会发生什么？" class="headerlink" title="8. 三次握手连接阶段，最后一次ACK包丢失，会发生什么？"></a>8. 三次握手连接阶段，最后一次ACK包丢失，会发生什么？</h2><p><strong>服务端：</strong></p>
<ul>
<li>第三次的ACK在网络中丢失，那么服务端该TCP连接的状态为SYN_RECV,并且会根据 TCP的超时重传机制，会等待3秒、6秒、12秒后重新发送SYN+ACK包，以便客户端重新发送ACK包。</li>
<li>如果重发指定次数之后，仍然未收到 客户端的ACK应答，那么一段时间后，服务端自动关闭这个连接。</li>
</ul>
<p><strong>客户端：</strong></p>
<p>客户端认为这个连接已经建立，如果客户端向服务端发送数据，服务端将以RST包（Reset，标示复位，用于异常的关闭连接）响应。此时，客户端知道第三次握手失败。</p>
<h2 id="9-详细介绍一下-TCP-的四次挥手过程？"><a href="#9-详细介绍一下-TCP-的四次挥手过程？" class="headerlink" title="9. 详细介绍一下 TCP 的四次挥手过程？"></a>9. 详细介绍一下 TCP 的四次挥手过程？</h2><p><img src="http://blog-img.coolsen.cn/img/image-20210520180127547.png"></p>
<blockquote>
<p>图片来源：<a target="_blank" rel="noopener" href="https://juejin.im/post/5ddd1f30e51d4532c42c5abe">https://juejin.im/post/5ddd1f30e51d4532c42c5abe</a></p>
</blockquote>
<ul>
<li><p>第一次挥手：客户端向服务端发送连接释放报文（FIN&#x3D;1，ACK&#x3D;1），主动关闭连接，同时等待服务端的确认。</p>
<ul>
<li>序列号 seq &#x3D; u，即客户端上次发送的报文的最后一个字节的序号 + 1</li>
<li>确认号 ack &#x3D; k, 即服务端上次发送的报文的最后一个字节的序号 + 1</li>
</ul>
</li>
<li><p>第二次挥手：服务端收到连接释放报文后，立即发出<strong>确认报文</strong>（ACK&#x3D;1），序列号 seq &#x3D; k，确认号 ack &#x3D; u + 1。</p>
<p>这时 TCP 连接处于半关闭状态，即客户端到服务端的连接已经释放了，但是服务端到客户端的连接还未释放。这表示客户端已经没有数据发送了，但是服务端可能还要给客户端发送数据。</p>
</li>
<li><p>第三次挥手：服务端向客户端发送连接释放报文（FIN&#x3D;1，ACK&#x3D;1），主动关闭连接，同时等待 A 的确认。</p>
<ul>
<li>序列号 seq &#x3D; w，即服务端上次发送的报文的最后一个字节的序号 + 1。</li>
<li>确认号 ack &#x3D; u + 1，与第二次挥手相同，因为这段时间客户端没有发送数据</li>
</ul>
</li>
<li><p>第四次挥手：客户端收到服务端的连接释放报文后，立即发出<strong>确认报文</strong>（ACK&#x3D;1），序列号 seq &#x3D; u + 1，确认号为 ack &#x3D; w + 1。</p>
<p>此时，客户端就进入了 <code>TIME-WAIT</code> 状态。注意此时客户端到 TCP 连接还没有释放，必须经过 2*MSL（最长报文段寿命）的时间后，才进入 <code>CLOSED</code> 状态。而服务端只要收到客户端发出的确认，就立即进入 <code>CLOSED</code> 状态。可以看到，服务端结束 TCP 连接的时间要比客户端早一些。</p>
</li>
</ul>
<h2 id="10-为什么连接的时候是三次握手，关闭的时候却是四次握手？"><a href="#10-为什么连接的时候是三次握手，关闭的时候却是四次握手？" class="headerlink" title="10. 为什么连接的时候是三次握手，关闭的时候却是四次握手？"></a>10. 为什么连接的时候是三次握手，关闭的时候却是四次握手？</h2><p>服务器在收到客户端的 FIN 报文段后，可能还有一些数据要传输，所以不能马上关闭连接，但是会做出应答，返回 ACK 报文段.</p>
<p>接下来可能会继续发送数据，在数据发送完后，服务器会向客户单发送 FIN 报文，表示数据已经发送完毕，请求关闭连接。服务器的<strong>ACK和FIN一般都会分开发送</strong>，从而导致多了一次，因此一共需要四次挥手。</p>
<h2 id="11-为什么客户端的-TIME-WAIT-状态必须等待-2MSL-？"><a href="#11-为什么客户端的-TIME-WAIT-状态必须等待-2MSL-？" class="headerlink" title="11. 为什么客户端的 TIME-WAIT 状态必须等待 2MSL ？"></a>11. 为什么客户端的 TIME-WAIT 状态必须等待 2MSL ？</h2><p>主要有两个原因：</p>
<ol>
<li><p>确保 ACK 报文能够到达服务端，从而使服务端正常关闭连接。</p>
<p>第四次挥手时，客户端第四次挥手的 ACK 报文不一定会到达服务端。服务端会超时重传 FIN&#x2F;ACK 报文，此时如果客户端已经断开了连接，那么就无法响应服务端的二次请求，这样服务端迟迟收不到 FIN&#x2F;ACK 报文的确认，就无法正常断开连接。</p>
<p>MSL 是报文段在网络上存活的最长时间。客户端等待 2MSL 时间，即「客户端 ACK 报文 1MSL 超时 + 服务端 FIN 报文 1MSL 传输」，就能够收到服务端重传的 FIN&#x2F;ACK 报文，然后客户端重传一次 ACK 报文，并重新启动 2MSL 计时器。如此保证服务端能够正常关闭。</p>
<p>如果服务端重发的 FIN 没有成功地在 2MSL 时间里传给客户端，服务端则会继续超时重试直到断开连接。</p>
</li>
<li><p>防止已失效的连接请求报文段出现在之后的连接中。</p>
</li>
</ol>
<p>   TCP 要求在 2MSL 内不使用相同的序列号。客户端在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以保证本连接持续的时间内产生的所有报文段都从网络中消失。这样就可以使下一个连接中不会出现这种旧的连接请求报文段。或者即使收到这些过时的报文，也可以不处理它。</p>
<h2 id="12-如果已经建立了连接，但是客户端出现故障了怎么办？"><a href="#12-如果已经建立了连接，但是客户端出现故障了怎么办？" class="headerlink" title="12. 如果已经建立了连接，但是客户端出现故障了怎么办？"></a>12. 如果已经建立了连接，但是客户端出现故障了怎么办？</h2><p>或者说，如果三次握手阶段、四次挥手阶段的包丢失了怎么办？如“服务端重发 FIN丢失”的问题。</p>
<p>简而言之，通过<strong>定时器 + 超时重试机制</strong>，尝试获取确认，直到最后会自动断开连接。</p>
<p>具体而言，TCP 设有一个保活计时器。服务器每收到一次客户端的数据，都会重新复位这个计时器，时间通常是设置为 2 小时。若 2 小时还没有收到客户端的任何数据，服务器就开始重试：每隔 75 分钟发送一个探测报文段，若一连发送 10 个探测报文后客户端依然没有回应，那么服务器就认为连接已经断开了。</p>
<h2 id="13-TIME-WAIT-状态过多会产生什么后果？怎样处理？"><a href="#13-TIME-WAIT-状态过多会产生什么后果？怎样处理？" class="headerlink" title="13. TIME-WAIT 状态过多会产生什么后果？怎样处理？"></a>13. TIME-WAIT 状态过多会产生什么后果？怎样处理？</h2><p>从服务器来讲，短时间内关闭了大量的Client连接，就会造成服务器上出现大量的TIME_WAIT连接，严重消耗着服务器的资源，此时部分客户端就会显示连接不上。</p>
<p>从客户端来讲，客户端TIME_WAIT过多，就会导致端口资源被占用，因为端口就65536个，被占满就会导致无法创建新的连接。</p>
<p><strong>解决办法：</strong></p>
<ul>
<li><p>服务器可以设置 SO_REUSEADDR 套接字选项来避免 TIME_WAIT状态，此套接字选项告诉内核，即使此端口正忙（处于<br>TIME_WAIT状态），也请继续并重用它。</p>
</li>
<li><p>调整系统内核参数，修改&#x2F;etc&#x2F;sysctl.conf文件，即修改<code>net.ipv4.tcp_tw_reuse 和 tcp_timestamps</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。</span><br></pre></td></tr></table></figure>
</li>
<li><p>强制关闭，发送 RST 包越过TIME_WAIT状态，直接进入CLOSED状态。</p>
</li>
</ul>
<h2 id="14-TIME-WAIT-是服务器端的状态-还是客户端的状态"><a href="#14-TIME-WAIT-是服务器端的状态-还是客户端的状态" class="headerlink" title="14. TIME_WAIT 是服务器端的状态?还是客户端的状态?"></a>14. TIME_WAIT 是服务器端的状态?还是客户端的状态?</h2><p>TIME_WAIT 是主动断开连接的一方会进入的状态，一般情况下，都是客户端所处的状态;服务器端一般设置不主动关闭连接。</p>
<p>TIME_WAIT 需要等待 2MSL，在大量短连接的情况下，TIME_WAIT会太多，这也会消耗很多系统资源。对于服务器来说，在 HTTP 协议里指定 KeepAlive（浏览器重用一个 TCP 连接来处理多个 HTTP 请求），由浏览器来主动断开连接，可以一定程度上减少服务器的这个问题。</p>
<h2 id="15-TCP协议如何保证可靠性？"><a href="#15-TCP协议如何保证可靠性？" class="headerlink" title="15. TCP协议如何保证可靠性？"></a>15. TCP协议如何保证可靠性？</h2><p>TCP主要提供了检验和、序列号&#x2F;确认应答、超时重传、滑动窗口、拥塞控制和 流量控制等方法实现了可靠性传输。</p>
<ul>
<li><p>检验和：通过检验和的方式，接收端可以检测出来数据是否有差错和异常，假如有差错就会直接丢弃TCP段，重新发送。</p>
</li>
<li><p>序列号&#x2F;确认应答：</p>
<p>序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据。</p>
<p>TCP传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答。也就是发送ACK报文，这个ACK报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。</p>
</li>
<li><p>滑动窗口：滑动窗口既提高了报文传输的效率，也避免了发送方发送过多的数据而导致接收方无法正常处理的异常。</p>
</li>
<li><p>超时重传：超时重传是指发送出去的数据包到接收到确认包之间的时间，如果超过了这个时间会被认为是丢包了，需要重传。最大超时时间是动态计算的。</p>
</li>
<li><p>拥塞控制：在数据传输过程中，可能由于网络状态的问题，造成网络拥堵，此时引入拥塞控制机制，在保证TCP可靠性的同时，提高性能。</p>
</li>
<li><p>流量控制：如果主机A 一直向主机B发送数据，不考虑主机B的接受能力，则可能导致主机B的接受缓冲区满了而无法再接受数据，从而会导致大量的数据丢包，引发重传机制。而在重传的过程中，若主机B的接收缓冲区情况仍未好转，则会将大量的时间浪费在重传数据上，降低传送数据的效率。所以引入流量控制机制，主机B通过告诉主机A自己接收缓冲区的大小，来使主机A控制发送的数据量。流量控制与TCP协议报头中的窗口大小有关。</p>
</li>
</ul>
<h2 id="16-详细讲一下TCP的滑动窗口？"><a href="#16-详细讲一下TCP的滑动窗口？" class="headerlink" title="16. 详细讲一下TCP的滑动窗口？"></a>16. 详细讲一下TCP的滑动窗口？</h2><p>在进行数据传输时，如果传输的数据比较大，就需要拆分为多个数据包进行发送。TCP 协议需要对数据进行确认后，才可以发送下一个数据包。这样一来，就会在等待确认应答包环节浪费时间。</p>
<p>为了避免这种情况，TCP引入了窗口概念。窗口大小指的是不需要等待确认应答包而可以继续发送数据包的最大值。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210520214432214.png"></p>
<p>从上面的图可以看到滑动窗口左边的是已发送并且被确认的分组，滑动窗口右边是还没有轮到的分组。</p>
<p>滑动窗口里面也分为两块，一块是已经发送但是未被确认的分组，另一块是窗口内等待发送的分组。随着已发送的分组不断被确认，窗口内等待发送的分组也会不断被发送。整个窗口就会往右移动，让还没轮到的分组进入窗口内。</p>
<p>可以看到滑动窗口起到了一个限流的作用，也就是说当前滑动窗口的大小决定了当前 TCP 发送包的速率，而滑动窗口的大小取决于拥塞控制窗口和流量控制窗口的两者间的最小值。</p>
<h2 id="17-详细讲一下拥塞控制？"><a href="#17-详细讲一下拥塞控制？" class="headerlink" title="17. 详细讲一下拥塞控制？"></a>17. 详细讲一下拥塞控制？</h2><p>TCP 一共使用了四种算法来实现拥塞控制：</p>
<ul>
<li><p>慢开始 (slow-start)；</p>
</li>
<li><p>拥塞避免 (congestion avoidance)；</p>
</li>
<li><p>快速重传 (fast retransmit)；</p>
</li>
<li><p>快速恢复 (fast recovery)。</p>
</li>
</ul>
<p>发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。当cwndssthresh时，改用拥塞避免算法。</p>
<p><strong>慢开始：</strong>不要一开始就发送大量的数据，由小到大逐渐增加拥塞窗口的大小。</p>
<p><strong>拥塞避免：</strong>拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1而不是加倍。这样拥塞窗口按线性规律缓慢增长。</p>
<p><strong>快重传：</strong>我们可以剔除一些不必要的拥塞报文，提高网络吞吐量。比如接收方在<strong>收到一个失序的报文段后就立即发出重复确认，而不要等到自己发送数据时捎带确认。</strong>快重传规定：发送方只要<strong>一连收到三个</strong>重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210520214123058.png"></p>
<p><strong>快恢复：</strong>主要是配合快重传。当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半（为了预防网络发生拥塞），但<strong>接下来并不执行慢开始算法</strong>，因为如果网络出现拥塞的话就不会收到好几个重复的确认，收到三个重复确认说明网络状况还可以。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210520214146324.png"></p>
<h2 id="巨人的肩膀"><a href="#巨人的肩膀" class="headerlink" title="巨人的肩膀"></a>巨人的肩膀</h2><p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000021815671">https://segmentfault.com/a/1190000021815671</a></p>
<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844904005315854343">https://juejin.cn/post/6844904005315854343</a></p>
<p><a target="_blank" rel="noopener" href="https://www.nowcoder.com/discuss/568071">https://www.nowcoder.com/discuss/568071</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yrx420909/article/details/104483455">https://blog.csdn.net/yrx420909/article/details/104483455</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaolincoding/p/12638546.html">https://www.cnblogs.com/xiaolincoding/p/12638546.html</a></p>
<p><a target="_blank" rel="noopener" href="https://imageslr.com/2020/07/07/tcp-shake-wave.html">https://imageslr.com/2020/07/07/tcp-shake-wave.html</a></p>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1537628">https://cloud.tencent.com/developer/article/1537628</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8A/" data-id="cl3wpiog0000io0r49o2k97sm" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-面试题" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/02/%E9%9D%A2%E8%AF%95%E9%A2%98/" class="article-date">
  <time class="dt-published" datetime="2022-06-02T07:38:10.689Z" itemprop="datePublished">2022-06-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-解释一下什么是CAP？"><a href="#1-解释一下什么是CAP？" class="headerlink" title="1.解释一下什么是CAP？"></a>1.解释一下什么是CAP？</h2><ul>
<li>Consistency：一致性就是在客户端任何时候看到各节点的数据都是一致的。</li>
<li>Availability：可用性就是在任何时刻都可以提供读写。</li>
<li>Partition Tolerance：分区容错性是在网络故障、某些节点不能通信的时候系统仍能继续工作。<br>具体地讲在分布式系统中，在任何数据库设计中，一个Web应用最多只能同时支持上面的两个属性。显然，任何横向扩展策略都要依赖于数据分区。因此，设计人员必须在一致性与可用性之间做出选择。<br><img src="http://blog-img.coolsen.cn/img/801753-20151107213219867-1667011131.png" alt="img"></li>
</ul>
<p>AP（高可用&amp;&amp;分区容错）:</p>
<p>允许至少一个节点更新状态会导致数据不一致，即丧失了C性质（一致性）。会导致全局的数据不一致。</p>
<p>CP（一致&amp;&amp;分区容错）:</p>
<p>为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质（可用性）。分区同步会导致同步时间无限延长（也就是等数据同步完成之后才能正常访问）</p>
<p>CA（一致&amp;&amp;高可用）:</p>
<p>两个节点可以互相通信，才能既保证C（一致性）又保证A（可用性），这又会导致丧失P性质（分区容错性）。这样的话就分布式节点受阻，无法部署子节点,放弃了分布式系统的可扩展性。因为分布式系统与单机系统不同，它涉及到多节点间的通讯和交互，节点间的分区故障是必然发生的，所以在分布式系统中分区容错性是必须要考虑的。</p>
<h2 id="2-什么分布式事务？"><a href="#2-什么分布式事务？" class="headerlink" title="2.什么分布式事务？"></a>2.什么分布式事务？</h2><p>分布式事务服务（Distributed Transaction Service，DTS）是一个分布式事务框架，用来保障在大规模分布式环境下事务的最终一致性。</p>
<p>CAP理论告诉我们在分布式存储系统中，最多只能实现上面的两点。而由于当前的网络硬件肯定会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的，所以我们只能在一致性和可用性之间进行权衡。</p>
<p>为了保障系统的可用性，互联网系统大多将强一致性需求转换成最终一致性的需求，并通过系统执行幂等性的保证，保证数据的最终一致性。</p>
<h2 id="3-了解BASE理论吗？"><a href="#3-了解BASE理论吗？" class="headerlink" title="3.了解BASE理论吗？"></a>3.了解BASE理论吗？</h2><p>BASE理论指的是：</p>
<ul>
<li>Basically Available（基本可用）</li>
<li>Soft state（软状态）</li>
<li>Eventually consistent（最终一致性）<br>BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，是对互联网大规模分布式系统的实践总结，强调可用性。</li>
</ul>
<p>理论的核心思想就是：基本可用（Basically Available）和最终一致性（Eventually consistent）。虽然无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。</p>
<h2 id="4-实现分布式事务一致性（Consistency）的方法有哪些"><a href="#4-实现分布式事务一致性（Consistency）的方法有哪些" class="headerlink" title="4.实现分布式事务一致性（Consistency）的方法有哪些?"></a>4.实现分布式事务一致性（Consistency）的方法有哪些?</h2><p>最著名的就是二阶段提交协议、三阶段提交协议和Paxos算法。</p>
<p><strong>两阶段提交协议</strong></p>
<ul>
<li>prepare(准备阶段)</li>
</ul>
<p>当开始事务调用的时候，事务处理器向事务执行者（有可能是数据库本身支持）发出命令，事务执行者进行prepare操作。<br>当所有事务执行者都完成了prepare操作，就进行下一步行为。<br>如果有一个事务执行者在执行prepare的时候失败了，那么通知事务处理器，事务处理器再通知所有的事务执行者执行回滚操作。</p>
<ul>
<li>commit(提交阶段)</li>
</ul>
<p>当所有事务执行者都prepare成功以后，事务处理器会再次发送commit请求给事务执行者，所有事务执行者进行commit处理。<br>当所有commit处理都成功了，那么事务执行结束。<br>如果有一个事务执行者的commit处理不成功，这个时候就要通知事务处理器，事务处理器通知所有的事务执行者执行回滚(abort)操作。<br>但是两阶段提交的诟病就是在于性能问题。比如由于执行链比较长，锁定资源的时间也变长了。所以在高性能的系统中都会避免使用二阶段提交。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/02/%E9%9D%A2%E8%AF%95%E9%A2%98/" data-id="cl3wpiofz000go0r4e6r0881g" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-操作系统" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/02/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" class="article-date">
  <time class="dt-published" datetime="2022-06-02T07:38:04.351Z" itemprop="datePublished">2022-06-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-进程和线程的区别？"><a href="#1-进程和线程的区别？" class="headerlink" title="1. 进程和线程的区别？"></a>1. 进程和线程的区别？</h2><ul>
<li>调度：进程是资源管理的基本单位，线程是程序执行的基本单位。</li>
<li>切换：线程上下文切换比进程上下文切换要快得多。</li>
<li>拥有资源： 进程是拥有资源的一个独立单位，线程不拥有系统资源，但是可以访问隶属于进程的资源。</li>
<li>系统开销： 创建或撤销进程时，系统都要为之分配或回收系统资源，如内存空间，I&#x2F;O设备等，OS所付出的开销显著大于在创建或撤销线程时的开销，进程切换的开销也远大于线程切换的开销。</li>
</ul>
<h2 id="2-协程与线程的区别？"><a href="#2-协程与线程的区别？" class="headerlink" title="2. 协程与线程的区别？"></a>2. 协程与线程的区别？</h2><ul>
<li>线程和进程都是同步机制，而协程是异步机制。</li>
<li>线程是抢占式，而协程是非抢占式的。需要用户释放使用权切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。</li>
<li>一个线程可以有多个协程，一个进程也可以有多个协程。</li>
<li>协程不被操作系统内核管理，而完全是由程序控制。线程是被分割的CPU资源，协程是组织好的代码流程，线程是协程的资源。但协程不会直接使用线程，协程直接利用的是执行器关联任意线程或线程池。</li>
<li>协程能保留上一次调用时的状态。</li>
</ul>
<h2 id="3-并发和并行有什么区别？"><a href="#3-并发和并行有什么区别？" class="headerlink" title="3. 并发和并行有什么区别？"></a>3. 并发和并行有什么区别？</h2><p>并发就是在一段时间内，多个任务都会被处理；但在某一时刻，只有一个任务在执行。单核处理器可以做到并发。比如有两个进程<code>A</code>和<code>B</code>，<code>A</code>运行一个时间片之后，切换到<code>B</code>，<code>B</code>运行一个时间片之后又切换到<code>A</code>。因为切换速度足够快，所以宏观上表现为在一段时间内能同时运行多个程序。</p>
<p>并行就是在同一时刻，有多个任务在执行。这个需要多核处理器才能完成，在微观上就能同时执行多条指令，不同的程序被放到不同的处理器上运行，这个是物理上的多个进程同时进行。</p>
<h2 id="4-进程与线程的切换流程？"><a href="#4-进程与线程的切换流程？" class="headerlink" title="4. 进程与线程的切换流程？"></a>4. 进程与线程的切换流程？</h2><p>进程切换分两步：</p>
<p>1、切换<strong>页表</strong>以使用新的地址空间，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。</p>
<p>2、切换内核栈和硬件上下文。</p>
<p>对于linux来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1步是不需要做的，第2步是进程和线程切换都要做的。</p>
<p>因为每个进程都有自己的虚拟地址空间，而线程是共享所在进程的虚拟地址空间的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换。</p>
<h2 id="5-为什么虚拟地址空间切换会比较耗时？"><a href="#5-为什么虚拟地址空间切换会比较耗时？" class="headerlink" title="5. 为什么虚拟地址空间切换会比较耗时？"></a>5. 为什么虚拟地址空间切换会比较耗时？</h2><p>进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表查找是一个很慢的过程，因此通常使用Cache来缓存常用的地址映射，这样可以加速页表查找，这个Cache就是TLB（translation Lookaside Buffer，TLB本质上就是一个Cache，是用来加速页表查找的）。</p>
<p>由于每个进程都有自己的虚拟地址空间，那么显然每个进程都有自己的页表，那么<strong>当进程切换后页表也要进行切换，页表切换后TLB就失效了</strong>，Cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢，而线程切换则不会导致TLB失效，因为线程无需切换地址空间，因此我们通常说线程切换要比较进程切换块，原因就在这里。</p>
<h2 id="6-进程间通信方式有哪些？"><a href="#6-进程间通信方式有哪些？" class="headerlink" title="6. 进程间通信方式有哪些？"></a>6. 进程间通信方式有哪些？</h2><ul>
<li><p>管道：管道这种通讯方式有两种限制，一是半双工的通信，数据只能单向流动，二是只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。</p>
<p>管道可以分为两类：匿名管道和命名管道。匿名管道是单向的，只能在有亲缘关系的进程间通信；命名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。</p>
</li>
<li><p>信号 ： 信号是一种比较复杂的通信方式，信号可以在任何时候发给某一进程，而无需知道该进程的状态。</p>
<blockquote>
<p> <strong>Linux系统中常用信号</strong>：<br> （1）<strong>SIGHUP</strong>：用户从终端注销，所有已启动进程都将收到该进程。系统缺省状态下对该信号的处理是终止进程。</p>
<p> （2）<strong>SIGINT</strong>：程序终止信号。程序运行过程中，按<code>Ctrl+C</code>键将产生该信号。</p>
<p> （3）<strong>SIGQUIT</strong>：程序退出信号。程序运行过程中，按<code>Ctrl+\\</code>键将产生该信号。</p>
<p> （4）<strong>SIGBUS和SIGSEGV</strong>：进程访问非法地址。</p>
<p> （5）<strong>SIGFPE</strong>：运算中出现致命错误，如除零操作、数据溢出等。</p>
<p> （6）<strong>SIGKILL</strong>：用户终止进程执行信号。shell下执行<code>kill -9</code>发送该信号。</p>
<p> （7）<strong>SIGTERM</strong>：结束进程信号。shell下执行<code>kill 进程pid</code>发送该信号。</p>
<p> （8）<strong>SIGALRM</strong>：定时器信号。</p>
<p> （9）<strong>SIGCLD</strong>：子进程退出信号。如果其父进程没有忽略该信号也没有处理该信号，则子进程退出后将形成僵尸进程。</p>
</blockquote>
</li>
<li><p>信号量：信号量是一个<strong>计数器</strong>，可以用来控制多个进程对共享资源的访问。它常作为一种<strong>锁机制</strong>，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。</p>
</li>
<li><p>消息队列：消息队列是消息的链接表，包括Posix消息队列和System V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。</p>
</li>
<li><p>共享内存：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。</p>
</li>
<li><p>Socket：与其他通信机制不同的是，它可用于不同机器间的进程通信。</p>
</li>
</ul>
<p><strong>优缺点</strong>：</p>
<ul>
<li><p>管道：速度慢，容量有限；</p>
</li>
<li><p>Socket：任何进程间都能通讯，但速度慢；</p>
</li>
<li><p>消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题；</p>
</li>
<li><p>信号量：不能传递复杂消息，只能用来同步；</p>
</li>
<li><p>共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存。</p>
</li>
</ul>
<h2 id="7-进程间同步的方式有哪些？"><a href="#7-进程间同步的方式有哪些？" class="headerlink" title="7. 进程间同步的方式有哪些？"></a>7. 进程间同步的方式有哪些？</h2><p>1、临界区：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。</p>
<p>优点：保证在某一时刻只有一个线程能访问数据的简便办法。</p>
<p>缺点：虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程。</p>
<p>2、互斥量：为协调共同对一个共享资源的单独访问而设计的。互斥量跟临界区很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。</p>
<p>优点：使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。</p>
<p>缺点：</p>
<ul>
<li><p>互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。</p>
</li>
<li><p>通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程&#x2F;进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号量对象可以说是一种资源计数器。</p>
</li>
</ul>
<p>3、信号量：为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数&#x3D;1就是互斥量了。</p>
<p>优点：适用于对Socket（套接字）程序中线程的同步。</p>
<p>缺点:</p>
<ul>
<li><p>信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点；</p>
</li>
<li><p>信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和维护都很困难，加重了程序员的编码负担；</p>
</li>
<li><p>核心操作P-V分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和纠正。</p>
</li>
</ul>
<p>4、事件： 用来通知线程有一些事件已发生，从而启动后继任务的开始。</p>
<p>优点：事件对象通过通知操作的方式来保持线程的同步，并且可以实现不同进程中的线程同步操作。</p>
<h2 id="8-线程同步的方式有哪些？"><a href="#8-线程同步的方式有哪些？" class="headerlink" title="8. 线程同步的方式有哪些？"></a>8. 线程同步的方式有哪些？</h2><p>1、临界区：当多个线程访问一个独占性共享资源时，可以使用临界区对象。拥有临界区的线程可以访问被保护起来的资源或代码段，其他线程若想访问，则被挂起，直到拥有临界区的线程放弃临界区为止，以此达到用原子方式操 作共享资源的目的。</p>
<p>2、事件：事件机制，则允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。</p>
<p>3、互斥量：互斥对象和临界区对象非常相似，只是其允许在进程间使用，而临界区只限制与同一进程的各个线程之间使用，但是更节省资源，更有效率。</p>
<p>4、信号量：当需要一个计数器来限制可以使用某共享资源的线程数目时，可以使用“信号量”对象。</p>
<p>区别：</p>
<ul>
<li><p>互斥量与临界区的作用非常相似，但互斥量是可以命名的，也就是说互斥量可以跨越进程使用，但创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量 。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。</p>
</li>
<li><p>互斥量，信号量，事件都可以被跨越进程使用来进行同步数据操作。</p>
</li>
</ul>
<h2 id="9-线程的分类？"><a href="#9-线程的分类？" class="headerlink" title="9. 线程的分类？"></a>9. 线程的分类？</h2><p>从线程的运行空间来说，分为用户级线程（user-level thread, ULT）和内核级线程（kernel-level, KLT）</p>
<p><strong>内核级线程</strong>：这类线程依赖于内核，又称为内核支持的线程或轻量级进程。无论是在用户程序中的线程还是系统进程中的线程，它们的创建、撤销和切换都由内核实现。比如英特尔i5-8250U是4核8线程，这里的线程就是内核级线程</p>
<p><strong>用户级线程</strong>：它仅存在于用户级中，这种线程是<strong>不依赖于操作系统核心</strong>的。应用进程利用<strong>线程库来完成其创建和管理</strong>，速度比较快，<strong>操作系统内核无法感知用户级线程的存在</strong>。</p>
<h2 id="10-什么是临界区，如何解决冲突？"><a href="#10-什么是临界区，如何解决冲突？" class="headerlink" title="10. 什么是临界区，如何解决冲突？"></a>10. 什么是临界区，如何解决冲突？</h2><p>每个进程中访问临界资源的那段程序称为临界区，<strong>一次仅允许一个进程使用的资源称为临界资源。</strong></p>
<p>解决冲突的办法：</p>
<ul>
<li>如果有若干进程要求进入空闲的临界区，<strong>一次仅允许一个进程进入</strong>，如已有进程进入自己的临界区，则其它所有试图进入临界区的进程必须等待；</li>
<li>进入临界区的进程要在<strong>有限时间内退出</strong>。</li>
<li>如果进程不能进入自己的临界区，则应<strong>让出CPU</strong>，避免进程出现“忙等”现象。</li>
</ul>
<h2 id="11-什么是死锁？死锁产生的条件？"><a href="#11-什么是死锁？死锁产生的条件？" class="headerlink" title="11. 什么是死锁？死锁产生的条件？"></a>11. 什么是死锁？死锁产生的条件？</h2><p><strong>什么是死锁</strong>：</p>
<p>在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲就是两个或多个进程无限期的阻塞、相互等待的一种状态。</p>
<p><strong>死锁产生的四个必要条件</strong>：（有一个条件不成立，则不会产生死锁）</p>
<ul>
<li>互斥条件：一个资源一次只能被一个进程使用</li>
<li>请求与保持条件：一个进程因请求资源而阻塞时，对已获得资源保持不放</li>
<li>不剥夺条件：进程获得的资源，在未完全使用完之前，不能强行剥夺</li>
<li>循环等待条件：若干进程之间形成一种头尾相接的环形等待资源关系</li>
</ul>
<h3 id="如何处理死锁问题"><a href="#如何处理死锁问题" class="headerlink" title="如何处理死锁问题"></a><strong>如何处理死锁问题</strong></h3><p>常用的处理死锁的方法有：死锁预防、死锁避免、死锁检测、死锁解除、鸵鸟策略。</p>
<p><strong>（1）死锁的预防：</strong>基本思想就是确保死锁发生的四个必要条件中至少有一个不成立：</p>
<blockquote>
<ul>
<li>① 破除资源互斥条件</li>
<li>② 破除“请求与保持”条件：实行资源预分配策略，进程在运行之前，必须一次性获取所有的资源。缺点：在很多情况下，无法预知进程执行前所需的全部资源，因为进程是动态执行的，同时也会降低资源利用率，导致降低了进程的并发性。</li>
<li>③ 破除“不可剥夺”条件：允许进程强行从占有者那里夺取某些资源。当一个已经保持了某些不可被抢占资源的进程，提出新的资源请求而不能得到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。这意味着进程已经占有的资源会被暂时被释放，或者说被抢占了。</li>
<li>④ 破除“循环等待”条件：实行资源有序分配策略，对所有资源排序编号，按照顺序获取资源，将紧缺的，稀少的采用较大的编号，在申请资源时必须按照编号的顺序进行，一个进程只有获得较小编号的进程才能申请较大编号的进程。</li>
</ul>
</blockquote>
<p><strong>（2）死锁避免：</strong></p>
<p>死锁预防通过约束资源请求，防止4个必要条件中至少一个的发生，可以通过直接或间接预防方法，但是都会导致低效的资源使用和低效的进程执行。而死锁避免则允许前三个必要条件，但是通过动态地检测资源分配状态，以确保循环等待条件不成立，从而确保系统处于安全状态。所谓安全状态是指：如果系统能按某个顺序为每个进程分配资源（不超过其最大值），那么系统状态是安全的，换句话说就是，如果存在一个安全序列，那么系统处于安全状态。银行家算法是经典的死锁避免的算法。</p>
<p><strong>（3）死锁检测：</strong></p>
<p>死锁预防策略是非常保守的，他们通过限制访问资源和在进程上强加约束来解决死锁的问题。死锁检测则是完全相反，它不限制资源访问或约束进程行为，只要有可能，被请求的资源就被授权给进程。但是操作系统会周期性地执行一个算法检测前面的循环等待的条件。死锁检测算法是通过资源分配图来检测是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有存在环，也就是检测到死锁的发生。</p>
<blockquote>
<ul>
<li>（1）如果进程-资源分配图中无环路，此时系统没有死锁。 </li>
<li>（2）如果进程-资源分配图中有环路，且每个资源类中只有一个资源，则系统发生死锁。 </li>
<li>（3）如果进程-资源分配图中有环路，且所涉及的资源类有多个资源，则不一定会发生死锁。</li>
</ul>
</blockquote>
<p><strong>（4）死锁解除：</strong></p>
<p>死锁解除的常用方法就是终止进程和资源抢占，回滚。所谓进程终止就是简单地终止一个或多个进程以打破循环等待，包括两种方式：终止所有死锁进程和一次只终止一个进程直到取消死锁循环为止；所谓资源抢占就是从一个或者多个死锁进程那里抢占一个或多个资源。</p>
<p><strong>（5）鸵鸟策略：</strong></p>
<p>把头埋在沙子里，假装根本没发生问题。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任何措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。</p>
<h2 id="12-进程调度策略有哪几种？"><a href="#12-进程调度策略有哪几种？" class="headerlink" title="12. 进程调度策略有哪几种？"></a>12. 进程调度策略有哪几种？</h2><ul>
<li><p><strong>先来先服务</strong>：非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。另外，对<code>I/O</code>密集型进程也不利，因为这种进程每次进行<code>I/O</code>操作之后又得重新排队。</p>
</li>
<li><p><strong>短作业优先</strong>：非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。</p>
</li>
<li><p><strong>最短剩余时间优先</strong>：最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。</p>
</li>
<li><p><strong>时间片轮转</strong>：将所有就绪进程按 <code>FCFS</code> 的原则排成一个队列，每次调度时，把 <code>CPU</code> 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 <code>CPU</code> 时间分配给队首的进程。</p>
<p>时间片轮转算法的效率和时间片的大小有很大关系：因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。 </p>
</li>
<li><p><strong>优先级调度</strong>：为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。</p>
</li>
</ul>
<h2 id="13-进程有哪些状态？"><a href="#13-进程有哪些状态？" class="headerlink" title="13. 进程有哪些状态？"></a>13. 进程有哪些状态？</h2><p>进程一共有<code>5</code>种状态，分别是创建、就绪、运行（执行）、终止、阻塞。 </p>
<p><img src="http://blog-img.coolsen.cn/img/A61F5B5322ED49038C64BDD82D341987" alt="进程五种状态转换图"></p>
<ul>
<li>运行状态就是进程正在<code>CPU</code>上运行。在单处理机环境下，每一时刻最多只有一个进程处于运行状态。 </li>
<li>就绪状态就是说进程已处于准备运行的状态，即进程获得了除<code>CPU</code>之外的一切所需资源，一旦得到<code>CPU</code>即可运行。 </li>
<li>阻塞状态就是进程正在等待某一事件而暂停运行，比如等待某资源为可用或等待<code>I/O</code>完成。即使<code>CPU</code>空闲，该进程也不能运行。</li>
</ul>
<p><strong>运行态→阻塞态</strong>：往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。<br><strong>阻塞态→就绪态</strong>：则是等待的条件已满足，只需分配到处理器后就能运行。<br><strong>运行态→就绪态</strong>：不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。<br><strong>就绪态→运行态</strong>：系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态。</p>
<h2 id="14-什么是分页？"><a href="#14-什么是分页？" class="headerlink" title="14. 什么是分页？"></a>14. 什么是分页？</h2><p>把内存空间划分为<strong>大小相等且固定的块</strong>，作为主存的基本单位。因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，<strong>因此需要一个页表来记录映射关系，以实现从页号到物理块号的映射。</strong></p>
<p>访问分页系统中内存数据需要<strong>两次的内存访问</strong> (一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址；第二次就是根据第一次得到的物理地址访问内存取出数据)。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210610173249387.png"></p>
<h2 id="15-什么是分段？"><a href="#15-什么是分段？" class="headerlink" title="15. 什么是分段？"></a>15. 什么是分段？</h2><p><strong>分页是为了提高内存利用率，而分段是为了满足程序员在编写代码的时候的一些逻辑需求(比如数据共享，数据保护，动态链接等)。</strong></p>
<p>分段内存管理当中，<strong>地址是二维的，一维是段号，二维是段内地址；其中每个段的长度是不一样的，而且每个段内部都是从0开始编址的</strong>。由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210610173410509.png"></p>
<h2 id="16-分页和分段有什区别？"><a href="#16-分页和分段有什区别？" class="headerlink" title="16. 分页和分段有什区别？"></a>16. 分页和分段有什区别？</h2><ul>
<li>分页对程序员是透明的，但是分段需要程序员显式划分每个段。 </li>
<li>分页的地址空间是一维地址空间，分段是二维的。 </li>
<li>页的大小不可变，段的大小可以动态改变。 </li>
<li>分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。</li>
</ul>
<h2 id="17-什么是交换空间？"><a href="#17-什么是交换空间？" class="headerlink" title="17. 什么是交换空间？"></a>17. 什么是交换空间？</h2><p>操作系统把物理内存(physical RAM)分成一块一块的小内存，每一块内存被称为<strong>页(page)<strong>。当内存资源不足时，</strong>Linux把某些页的内容转移至硬盘上的一块空间上，以释放内存空间</strong>。硬盘上的那块空间叫做<strong>交换空间</strong>(swap space),而这一过程被称为交换(swapping)。<strong>物理内存和交换空间的总容量就是虚拟内存的可用容量。</strong></p>
<p>用途：</p>
<ul>
<li>物理内存不足时一些不常用的页可以被交换出去，腾给系统。</li>
<li>程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。</li>
</ul>
<h2 id="18-物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别"><a href="#18-物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别" class="headerlink" title="18. 物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别?"></a>18. 物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别?</h2><p>物理地址就是内存中真正的地址，它就相当于是你家的门牌号，你家就肯定有这个门牌号，具有唯一性。<strong>不管哪种地址，最终都会映射为物理地址</strong>。</p>
<p>在<code>实模式</code>下，段基址 + 段内偏移经过地址加法器的处理，经过地址总线传输，最终也会转换为<code>物理地址</code>。</p>
<p>但是在<code>保护模式</code>下，段基址 + 段内偏移被称为<code>线性地址</code>，不过此时的段基址不能称为真正的地址，而是会被称作为一个<code>选择子</code>的东西，选择子就是个索引，相当于数组的下标，通过这个索引能够在 GDT 中找到相应的段描述符，段描述符记录了<strong>段的起始、段的大小</strong>等信息，这样便得到了基地址。如果此时没有开启内存分页功能，那么这个线性地址可以直接当做物理地址来使用，直接访问内存。如果开启了分页功能，那么这个线性地址又多了一个名字，这个名字就是<code>虚拟地址</code>。</p>
<p>不论在实模式还是保护模式下，段内偏移地址都叫做<code>有效地址</code>。有效抵制也是逻辑地址。</p>
<p>线性地址可以看作是<code>虚拟地址</code>，虚拟地址不是真正的物理地址，但是虚拟地址会最终被映射为物理地址。下面是虚拟地址 -&gt; 物理地址的映射。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210807152300643.png" alt="image-20210807152300643"></p>
<h2 id="19-页面替换算法有哪些？"><a href="#19-页面替换算法有哪些？" class="headerlink" title="19. 页面替换算法有哪些？"></a>19. 页面替换算法有哪些？</h2><p>在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210807152232136.png" alt="image-20210807152232136"></p>
<ul>
<li><code>最优算法</code>在当前页面中置换最后要访问的页面。不幸的是，没有办法来判定哪个页面是最后一个要访问的，<code>因此实际上该算法不能使用</code>。然而，它可以作为衡量其他算法的标准。</li>
<li><code>NRU</code> 算法根据 R 位和 M 位的状态将页面分为四类。从编号最小的类别中随机选择一个页面。NRU 算法易于实现，但是性能不是很好。存在更好的算法。</li>
<li><code>FIFO</code> 会跟踪页面加载进入内存中的顺序，并把页面放入一个链表中。有可能删除存在时间最长但是还在使用的页面，因此这个算法也不是一个很好的选择。</li>
<li><code>第二次机会</code>算法是对 FIFO 的一个修改，它会在删除页面之前检查这个页面是否仍在使用。如果页面正在使用，就会进行保留。这个改进大大提高了性能。</li>
<li><code>时钟</code> 算法是第二次机会算法的另外一种实现形式，时钟算法和第二次算法的性能差不多，但是会花费更少的时间来执行算法。</li>
<li><code>LRU</code> 算法是一个非常优秀的算法，但是没有<code>特殊的硬件(TLB)</code>很难实现。如果没有硬件，就不能使用 LRU 算法。</li>
<li><code>NFU</code> 算法是一种近似于 LRU 的算法，它的性能不是非常好。</li>
<li><code>老化</code> 算法是一种更接近 LRU 算法的实现，并且可以更好的实现，因此是一个很好的选择</li>
<li>最后两种算法都使用了工作集算法。工作集算法提供了合理的性能开销，但是它的实现比较复杂。<code>WSClock</code> 是另外一种变体，它不仅能够提供良好的性能，而且可以高效地实现。</li>
</ul>
<p><strong>最好的算法是老化算法和WSClock算法</strong>。他们分别是基于 LRU 和工作集算法。他们都具有良好的性能并且能够被有效的实现。还存在其他一些好的算法，但实际上这两个可能是最重要的。</p>
<h2 id="20-什么是缓冲区溢出？有什么危害？"><a href="#20-什么是缓冲区溢出？有什么危害？" class="headerlink" title="20. 什么是缓冲区溢出？有什么危害？"></a>20. 什么是缓冲区溢出？有什么危害？</h2><p>缓冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上。</p>
<p>危害有以下两点：</p>
<ul>
<li>程序崩溃，导致拒绝额服务</li>
<li>跳转并且执行一段恶意代码</li>
</ul>
<p>造成缓冲区溢出的主要原因是程序中没有仔细检查用户输入。</p>
<h2 id="21-什么是虚拟内存？"><a href="#21-什么是虚拟内存？" class="headerlink" title="21. 什么是虚拟内存？"></a>21. 什么是虚拟内存？</h2><p>虚拟内存就是说，让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。虚拟内存使用部分加载的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。</p>
<h2 id="22-虚拟内存的实现方式有哪些"><a href="#22-虚拟内存的实现方式有哪些" class="headerlink" title="22. 虚拟内存的实现方式有哪些?"></a>22. 虚拟内存的实现方式有哪些?</h2><p>虚拟内存中，允许将一个作业分多次调入内存。釆用连续分配方式时，会使相当一部分内存空间都处于暂时或<code>永久</code>的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟内存的实需要建立在离散分配的内存管理方式的基础上。虚拟内存的实现有以下三种方式：</p>
<ul>
<li>请求分页存储管理。</li>
<li>请求分段存储管理。</li>
<li>请求段页式存储管理。</li>
</ul>
<h2 id="23-讲一讲IO多路复用？"><a href="#23-讲一讲IO多路复用？" class="headerlink" title="23. 讲一讲IO多路复用？"></a>23. 讲一讲IO多路复用？</h2><p><strong>IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。IO多路复用适用如下场合</strong>：</p>
<ul>
<li>当客户处理多个描述字时（一般是交互式输入和网络套接口），必须使用I&#x2F;O复用。</li>
<li>当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。</li>
<li>如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I&#x2F;O复用。</li>
<li>如果一个服务器即要处理TCP，又要处理UDP，一般要使用I&#x2F;O复用。</li>
<li>如果一个服务器要处理多个服务或多个协议，一般要使用I&#x2F;O复用。</li>
<li>与多进程和多线程技术相比，I&#x2F;O多路复用技术的最大优势是系统开销小，系统不必创建进程&#x2F;线程，也不必维护这些进程&#x2F;线程，从而大大减小了系统的开销。</li>
</ul>
<h2 id="24-硬链接和软链接有什么区别？"><a href="#24-硬链接和软链接有什么区别？" class="headerlink" title="24. 硬链接和软链接有什么区别？"></a>24. 硬链接和软链接有什么区别？</h2><ul>
<li>硬链接就是在目录下创建一个条目，记录着文件名与 <code>inode</code> 编号，这个 <code>inode</code> 就是源文件的 <code>inode</code>。删除任意一个条目，文件还是存在，只要引用数量不为 <code>0</code>。但是硬链接有限制，它不能跨越文件系统，也不能对目录进行链接。</li>
<li>符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 <code>Windows</code> 的快捷方式。当源文件被删除了，链接文件就打不开了。因为记录的是路径，所以可以为目录建立符号链接。</li>
</ul>
<h2 id="25-中断的处理过程"><a href="#25-中断的处理过程" class="headerlink" title="25. 中断的处理过程?"></a>25. 中断的处理过程?</h2><ol>
<li>保护现场：将当前执行程序的相关数据保存在寄存器中，然后入栈。</li>
<li>开中断：以便执行中断时能响应较高级别的中断请求。</li>
<li>中断处理</li>
<li>关中断：保证恢复现场时不被新中断打扰</li>
<li>恢复现场：从堆栈中按序取出程序数据，恢复中断前的执行状态。</li>
</ol>
<h2 id="26-中断和轮询有什么区别？"><a href="#26-中断和轮询有什么区别？" class="headerlink" title="26. 中断和轮询有什么区别？"></a>26. 中断和轮询有什么区别？</h2><ul>
<li>轮询：CPU对<strong>特定设备</strong>轮流询问。中断：通过<strong>特定事件</strong>提醒CPU。</li>
<li>轮询：效率低等待时间长，CPU利用率不高。中断：容易遗漏问题，CPU利用率不高。</li>
</ul>
<h2 id="27-什么是用户态和内核态？"><a href="#27-什么是用户态和内核态？" class="headerlink" title="27. 什么是用户态和内核态？"></a>27. 什么是用户态和内核态？</h2><p>用户态和系统态是操作系统的两种运行状态：</p>
<blockquote>
<ul>
<li>内核态：内核态运行的程序可以访问计算机的任何数据和资源，不受限制，包括外围设备，比如网卡、硬盘等。处于内核态的 CPU 可以从一个程序切换到另外一个程序，并且占用 CPU 不会发生抢占情况。</li>
<li>用户态：用户态运行的程序只能受限地访问内存，只能直接读取用户程序的数据，并且不允许访问外围设备，用户态下的 CPU 不允许独占，也就是说 CPU 能够被其他程序获取。</li>
</ul>
</blockquote>
<p>将操作系统的运行状态分为用户态和内核态，主要是为了对访问能力进行限制，防止随意进行一些比较危险的操作导致系统的崩溃，比如设置时钟、内存清理，这些都需要在内核态下完成 。</p>
<h2 id="28-用户态和内核态是如何切换的"><a href="#28-用户态和内核态是如何切换的" class="headerlink" title="28. 用户态和内核态是如何切换的?"></a>28. 用户态和内核态是如何切换的?</h2><p>所有的用户进程都是运行在用户态的，但是我们上面也说了，用户程序的访问能力有限，一些比较重要的比如从硬盘读取数据，从键盘获取数据的操作则是内核态才能做的事情，而这些数据却又对用户程序来说非常重要。所以就涉及到两种模式下的转换，即<strong>用户态 -&gt; 内核态 -&gt; 用户态</strong>，而唯一能够做这些操作的只有 <code>系统调用</code>，而能够执行系统调用的就只有 <code>操作系统</code>。</p>
<p>一般用户态 -&gt; 内核态的转换我们都称之为 trap 进内核，也被称之为 <code>陷阱指令(trap instruction)</code>。</p>
<p>他们的工作流程如下：</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210807152619210.png" alt="image-20210807152619210"></p>
<ul>
<li>首先用户程序会调用 <code>glibc</code> 库，glibc 是一个标准库，同时也是一套核心库，库中定义了很多关键 API。</li>
<li>glibc 库知道针对不同体系结构调用<code>系统调用</code>的正确方法，它会根据体系结构应用程序的二进制接口设置用户进程传递的参数，来准备系统调用。</li>
<li>然后，glibc 库调用<code>软件中断指令(SWI)</code> ，这个指令通过更新 <code>CPSR</code> 寄存器将模式改为超级用户模式，然后跳转到地址 <code>0x08</code> 处。</li>
<li>到目前为止，整个过程仍处于用户态下，在执行 SWI 指令后，允许进程执行内核代码，MMU 现在允许内核虚拟内存访问</li>
<li>从地址 0x08 开始，进程执行加载并跳转到中断处理程序，这个程序就是 ARM 中的 <code>vector_swi()</code>。</li>
<li>在 vector_swi() 处，从 SWI 指令中提取系统调用号 SCNO，然后使用 SCNO 作为系统调用表 <code>sys_call_table</code> 的索引，调转到系统调用函数。</li>
<li>执行系统调用完成后，将还原用户模式寄存器，然后再以用户模式执行。</li>
</ul>
<h2 id="29-Unix-常见的IO模型："><a href="#29-Unix-常见的IO模型：" class="headerlink" title="29. Unix 常见的IO模型："></a>29. Unix 常见的IO模型：</h2><p>对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：</p>
<blockquote>
<ul>
<li>等待数据准备就绪 (Waiting for the data to be ready)</li>
<li>将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)</li>
</ul>
</blockquote>
<p>正式因为这两个阶段，linux系统产生了下面五种网络模式的方案：</p>
<blockquote>
<ul>
<li>阻塞式IO模型(blocking IO model)</li>
<li>非阻塞式IO模型(noblocking IO model)</li>
<li>IO复用式IO模型(IO multiplexing model)</li>
<li>信号驱动式IO模型(signal-driven IO model)</li>
<li>异步IO式IO模型(asynchronous IO model)</li>
</ul>
</blockquote>
<p>对于这几种 IO 模型的详细说明，可以参考这篇文章：<a target="_blank" rel="noopener" href="https://juejin.cn/post/6942686874301857800#heading-13">https://juejin.cn/post/6942686874301857800#heading-13</a></p>
<p>其中，IO多路复用模型指的是：使用单个进程同时处理多个网络连接IO，他的原理就是select、poll、epoll 不断轮询所负责的所有 socket，当某个socket有数据到达了，就通知用户进程。该模型的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。</p>
<h2 id="30-select、poll-和-epoll-之间的区别"><a href="#30-select、poll-和-epoll-之间的区别" class="headerlink" title="30. select、poll 和 epoll 之间的区别?"></a>30. select、poll 和 epoll 之间的区别?</h2><p>（1）select：时间复杂度 O(n)</p>
<p>select 仅仅知道有 I&#x2F;O 事件发生，但并不知道是哪几个流，所以只能无差别轮询所有流，找出能读出数据或者写入数据的流，并对其进行操作。所以 select 具有 O(n) 的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。</p>
<p>（2）poll：时间复杂度 O(n)</p>
<p>poll 本质上和 select 没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个 fd 对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的。</p>
<p>（3）epoll：时间复杂度 O(1)</p>
<p>epoll 可以理解为 event poll，不同于忙轮询和无差别轮询，epoll 会把哪个流发生了怎样的 I&#x2F;O 事件通知我们。所以说 epoll 实际上是事件驱动（每个事件关联上 fd）的。</p>
<blockquote>
<p>select，poll，epoll 都是 IO 多路复用的机制。I&#x2F;O 多路复用就是通过一种机制监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），就通知程序进行相应的读写操作。但 select，poll，epoll 本质上都是同步 I&#x2F;O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步 I&#x2F;O 则无需自己负责进行读写，异步 I&#x2F;O 的实现会负责把数据从内核拷贝到用户空间。</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/02/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" data-id="cl3wpiog3000mo0r44vfwdhof" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Spring" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/02/Spring/" class="article-date">
  <time class="dt-published" datetime="2022-06-02T07:37:59.120Z" itemprop="datePublished">2022-06-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-使用Spring框架的好处是什么？"><a href="#1-使用Spring框架的好处是什么？" class="headerlink" title="1. 使用Spring框架的好处是什么？"></a>1. 使用Spring框架的好处是什么？</h2><ul>
<li><strong>轻量：</strong>Spring 是轻量的，基本的版本大约2MB</li>
<li><strong>控制反转：</strong>Spring通过控制反转实现了松散耦合，对象们给出它们的依赖，而不是创建或查找依赖的对象们</li>
<li><strong>面向切面的编程(AOP)：</strong>Spring支持面向切面的编程，并且把应用业务逻辑和系统服务分开</li>
<li><strong>容器：</strong>Spring 包含并管理应用中对象的生命周期和配置</li>
<li><strong>MVC框架：</strong>Spring的WEB框架是个精心设计的框架，是Web框架的一个很好的替代品</li>
<li><strong>事务管理：</strong>Spring 提供一个持续的事务管理接口，可以扩展到上至本地事务下至全局事务（JTA）</li>
<li><strong>异常处理：</strong>Spring 提供方便的API把具体技术相关的异常（比如由JDBC，Hibernate or JDO抛出的）转化为一致的unchecked 异常。</li>
</ul>
<h2 id="2-什么是-Spring-IOC-容器？"><a href="#2-什么是-Spring-IOC-容器？" class="headerlink" title="2. 什么是 Spring IOC 容器？"></a>2. 什么是 Spring IOC 容器？</h2><p>Spring 框架的核心是 Spring 容器。容器创建对象，将它们装配在一起，配置它们并管理它们的完整生命周期。Spring 容器使用依赖注入来管理组成应用程序的组件。容器通过读取提供的配置元数据来接收对象进行实例化，配置和组装的指令。该元数据可以通过 XML，Java 注解或 Java 代码提供。</p>
<p><img src="http://blog-img.coolsen.cn/img/3101171-33099411d16ca051.png" alt="image.png"></p>
<h2 id="3-什么是依赖注入？可以通过多少种方式完成依赖注入？"><a href="#3-什么是依赖注入？可以通过多少种方式完成依赖注入？" class="headerlink" title="3. 什么是依赖注入？可以通过多少种方式完成依赖注入？"></a>3. 什么是依赖注入？可以通过多少种方式完成依赖注入？</h2><p>在依赖注入中，您不必创建对象，但必须描述如何创建它们。您不是直接在代码中将组件和服务连接在一起，而是描述配置文件中哪些组件需要哪些服务。由 IoC 容器将它们装配在一起。</p>
<p>通常，依赖注入可以通过三种方式完成，即：</p>
<ul>
<li>构造函数注入</li>
<li>setter 注入</li>
<li>接口注入</li>
</ul>
<p>在 Spring Framework 中，仅使用构造函数和 setter 注入。</p>
<h2 id="4-区分-BeanFactory-和-ApplicationContext？"><a href="#4-区分-BeanFactory-和-ApplicationContext？" class="headerlink" title="4. 区分 BeanFactory 和 ApplicationContext？"></a>4. 区分 BeanFactory 和 ApplicationContext？</h2><table>
<thead>
<tr>
<th>BeanFactory</th>
<th>ApplicationContext</th>
</tr>
</thead>
<tbody><tr>
<td>它使用懒加载</td>
<td>它使用即时加载</td>
</tr>
<tr>
<td>它使用语法显式提供资源对象</td>
<td>它自己创建和管理资源对象</td>
</tr>
<tr>
<td>不支持国际化</td>
<td>支持国际化</td>
</tr>
<tr>
<td>不支持基于依赖的注解</td>
<td>支持基于依赖的注解</td>
</tr>
</tbody></table>
<p>BeanFactory和ApplicationContext的优缺点分析：</p>
<p>BeanFactory的优缺点：</p>
<ul>
<li>优点：应用启动的时候占用资源很少，对资源要求较高的应用，比较有优势；</li>
<li>缺点：运行速度会相对来说慢一些。而且有可能会出现空指针异常的错误，而且通过Bean工厂创建的Bean生命周期会简单一些。</li>
</ul>
<p>ApplicationContext的优缺点：</p>
<ul>
<li>优点：所有的Bean在启动的时候都进行了加载，系统运行的速度快；在系统启动的时候，可以发现系统中的配置问题。</li>
<li>缺点：把费时的操作放到系统启动中完成，所有的对象都可以预加载，缺点就是内存占用较大。</li>
</ul>
<h2 id="5-区分构造函数注入和-setter-注入"><a href="#5-区分构造函数注入和-setter-注入" class="headerlink" title="5. 区分构造函数注入和 setter 注入"></a>5. 区分构造函数注入和 setter 注入</h2><table>
<thead>
<tr>
<th>构造函数注入</th>
<th>setter 注入</th>
</tr>
</thead>
<tbody><tr>
<td>没有部分注入</td>
<td>有部分注入</td>
</tr>
<tr>
<td>不会覆盖 setter 属性</td>
<td>会覆盖 setter 属性</td>
</tr>
<tr>
<td>任意修改都会创建一个新实例</td>
<td>任意修改不会创建一个新实例</td>
</tr>
<tr>
<td>适用于设置很多属性</td>
<td>适用于设置少量属性</td>
</tr>
</tbody></table>
<h2 id="6-spring-提供了哪些配置方式？"><a href="#6-spring-提供了哪些配置方式？" class="headerlink" title="6. spring 提供了哪些配置方式？"></a>6. spring 提供了哪些配置方式？</h2><ul>
<li>基于 xml 配置</li>
</ul>
<p>bean 所需的依赖项和服务在 XML 格式的配置文件中指定。这些配置文件通常包含许多 bean 定义和特定于应用程序的配置选项。它们通常以 bean 标签开头。例如：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;studentbean&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.edureka.firstSpring.StudentBean&quot;</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;name&quot;</span> <span class="attr">value</span>=<span class="string">&quot;Edureka&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>基于注解配置</li>
</ul>
<p>您可以通过在相关的类，方法或字段声明上使用注解，将 bean 配置为组件类本身，而不是使用 XML 来描述 bean 装配。默认情况下，Spring 容器中未打开注解装配。因此，您需要在使用它之前在 Spring 配置文件中启用它。例如：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">beans</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">context:annotation-config</span>/&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- bean definitions go here --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>基于 Java API 配置</li>
</ul>
<p>Spring 的 Java 配置是通过使用 @Bean 和 @Configuration 来实现。</p>
<ol>
<li>@Bean 注解扮演与 <code>&lt;bean /&gt;</code> 元素相同的角色。</li>
<li>@Configuration 类允许通过简单地调用同一个类中的其他 @Bean 方法来定义 bean 间依赖关系。</li>
</ol>
<p>例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">StudentConfig</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> StudentBean <span class="title function_">myStudent</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">StudentBean</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="7-Spring-中的-bean-的作用域有哪些"><a href="#7-Spring-中的-bean-的作用域有哪些" class="headerlink" title="7. Spring 中的 bean 的作用域有哪些?"></a>7. Spring 中的 bean 的作用域有哪些?</h2><ul>
<li>singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。</li>
<li>prototype : 每次请求都会创建一个新的 bean 实例。</li>
<li>request : 每一次HTTP请求都会产生一个新的bean，该bean仅在当前HTTP request内有效。</li>
<li>session : ：在一个HTTP Session中，一个Bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效。</li>
<li>global-session： 全局session作用域，仅仅在基于portlet的web应用中才有意义，Spring5已经没有了。Portlet是能够生成语义代码(例如：HTML)片段的小型Java Web插件。它们基于portlet容器，可以像servlet一样处理HTTP请求。但是，与 servlet 不同，每个 portlet 都有不同的会话</li>
</ul>
<h2 id="8-如何理解IoC和DI？"><a href="#8-如何理解IoC和DI？" class="headerlink" title="8. 如何理解IoC和DI？"></a>8. 如何理解IoC和DI？</h2><p>IOC就是控制反转，通俗的说就是我们不用自己创建实例对象，这些都交给Spring的bean工厂帮我们创建管理。这也是Spring的核心思想，通过面向接口编程的方式来是实现对业务组件的动态依赖。这就意味着IOC是Spring针对解决程序耦合而存在的。在实际应用中，Spring通过配置文件（xml或者properties）指定需要实例化的java类（类名的完整字符串），包括这些java类的一组初始化值，通过加载读取配置文件，用Spring提供的方法（getBean()）就可以获取到我们想要的根据指定配置进行初始化的实例对象。</p>
<ul>
<li>优点：IOC或依赖注入减少了应用程序的代码量。它使得应用程序的测试很简单，因为在单元测试中不再需要单例或JNDI查找机制。简单的实现以及较少的干扰机制使得松耦合得以实现。IOC容器支持勤性单例及延迟加载服务。</li>
</ul>
<p><strong>DI：DI—Dependency</strong> Injection，即“依赖注入”：组件之间依赖关系由容器在运行期决定，形象的说，即由容器动态的将某个依赖关系注入到组件之中。依赖注入的目的并非为软件系统带来更多功能，而是为了提升组件重用的频率，并为系统搭建一个灵活、可扩展的平台。通过依赖注入机制，我们只需要通过简单的配置，而无需任何代码就可指定目标需要的资源，完成自身的业务逻辑，而不需要关心具体的资源来自何处，由谁实现。</p>
<h2 id="9-将一个类声明为Spring的-bean-的注解有哪些"><a href="#9-将一个类声明为Spring的-bean-的注解有哪些" class="headerlink" title="9. 将一个类声明为Spring的 bean 的注解有哪些?"></a>9. 将一个类声明为Spring的 bean 的注解有哪些?</h2><p>我们一般使用 @Autowired 注解自动装配 bean，要想把类标识成可用于 @Autowired 注解自动装配的 bean 的类,采用以下注解可实现：</p>
<ul>
<li>@Component ：通用的注解，可标注任意类为 Spring 组件。如果一个Bean不知道属于哪个层，可以使用@Component 注解标注。<br>8 @Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。</li>
<li>@Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao层。</li>
<li>@Controller : 对应 Spring MVC 控制层，主要用户接受用户请求并调用 Service 层返回数据给前端页面。</li>
</ul>
<h2 id="10-spring-支持几种-bean-scope？"><a href="#10-spring-支持几种-bean-scope？" class="headerlink" title="10. spring 支持几种 bean scope？"></a>10. spring 支持几种 bean scope？</h2><p>Spring bean 支持 5 种 scope：</p>
<ul>
<li><strong>Singleton</strong> - 每个 Spring IoC 容器仅有一个单实例。</li>
<li><strong>Prototype</strong> - 每次请求都会产生一个新的实例。</li>
<li><strong>Request</strong> - 每一次 HTTP 请求都会产生一个新的实例，并且该 bean 仅在当前 HTTP 请求内有效。</li>
<li><strong>Session</strong> - 每一次 HTTP 请求都会产生一个新的 bean，同时该 bean 仅在当前 HTTP session 内有效。</li>
<li><strong>Global-session</strong> - 类似于标准的 HTTP Session 作用域，不过它仅仅在基于 portlet 的 web 应用中才有意义。Portlet 规范定义了全局 Session 的概念，它被所有构成某个 portlet web 应用的各种不同的 portlet 所共享。在 global session 作用域中定义的 bean 被限定于全局 portlet Session 的生命周期范围内。如果你在 web 中使用 global session 作用域来标识 bean，那么 web 会自动当成 session 类型来使用。</li>
</ul>
<p>仅当用户使用支持 Web 的 ApplicationContext 时，最后三个才可用。</p>
<h2 id="11-Spring-中的-bean-生命周期"><a href="#11-Spring-中的-bean-生命周期" class="headerlink" title="11. Spring 中的 bean 生命周期?"></a>11. Spring 中的 bean 生命周期?</h2><p>Bean的生命周期是由容器来管理的。主要在创建和销毁两个时期。</p>
<p><img src="http://blog-img.coolsen.cn/img/1583675090641_51.png"></p>
<h3 id="创建过程："><a href="#创建过程：" class="headerlink" title="创建过程："></a>创建过程：</h3><p>1，实例化bean对象，以及设置bean属性；<br>2，如果通过Aware接口声明了依赖关系，则会注入Bean对容器基础设施层面的依赖，Aware接口是为了感知到自身的一些属性。容器管理的Bean一般不需要知道容器的状态和直接使用容器。但是在某些情况下是需要在Bean中对IOC容器进行操作的。这时候需要在bean中设置对容器的感知。SpringIOC容器也提供了该功能，它是通过特定的Aware接口来完成的。<br>比如BeanNameAware接口，可以知道自己在容器中的名字。<br>如果这个Bean已经实现了BeanFactoryAware接口，可以用这个方式来获取其它Bean。<br>（如果Bean实现了BeanNameAware接口，调用setBeanName()方法，传入Bean的名字。<br>如果Bean实现了BeanClassLoaderAware接口，调用setBeanClassLoader()方法，传入ClassLoader对象的实例。<br>如果Bean实现了BeanFactoryAware接口，调用setBeanFactory()方法，传入BeanFactory对象的实例。）<br>3，紧接着会调用BeanPostProcess的前置初始化方法postProcessBeforeInitialization，主要作用是在Spring完成实例化之后，初始化之前，对Spring容器实例化的Bean添加自定义的处理逻辑。有点类似于AOP。<br>4，如果实现了BeanFactoryPostProcessor接口的afterPropertiesSet方法，做一些属性被设定后的自定义的事情。<br>5，调用Bean自身定义的init方法，去做一些初始化相关的工作。<br>6，调用BeanPostProcess的后置初始化方法，postProcessAfterInitialization去做一些bean初始化之后的自定义工作。<br>7，完成以上创建之后就可以在应用里使用这个Bean了。</p>
<h3 id="销毁过程："><a href="#销毁过程：" class="headerlink" title="销毁过程："></a>销毁过程：</h3><p>当Bean不再用到，便要销毁<br>1，若实现了DisposableBean接口，则会调用destroy方法；<br>2，若配置了destry-method属性，则会调用其配置的销毁方法；</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>主要把握创建过程和销毁过程这两个大的方面；<br>创建过程：首先实例化Bean，并设置Bean的属性，根据其实现的Aware接口（主要是BeanFactoryAware接口，BeanFactoryAware，ApplicationContextAware）设置依赖信息，<br>接下来调用BeanPostProcess的postProcessBeforeInitialization方法，完成initial前的自定义逻辑；afterPropertiesSet方法做一些属性被设定后的自定义的事情;调用Bean自身定义的init方法，去做一些初始化相关的工作;然后再调用postProcessAfterInitialization去做一些bean初始化之后的自定义工作。这四个方法的调用有点类似AOP。<br>此时，Bean初始化完成，可以使用这个Bean了。<br>销毁过程：如果实现了DisposableBean的destroy方法，则调用它，如果实现了自定义的销毁方法，则调用之。 </p>
<h2 id="12-什么是-spring-的内部-bean？"><a href="#12-什么是-spring-的内部-bean？" class="headerlink" title="12. 什么是 spring 的内部 bean？"></a>12. 什么是 spring 的内部 bean？</h2><p>只有将 bean 用作另一个 bean 的属性时，才能将 bean 声明为内部 bean。为了定义 bean，Spring 的基于 XML 的配置元数据在 <code>&lt;property&gt;</code> 或 <code>&lt;constructor-arg&gt;</code> 中提供了 <code>&lt;bean&gt;</code> 元素的使用。内部 bean 总是匿名的，它们总是作为原型。</p>
<p>例如，假设我们有一个 Student 类，其中引用了 Person 类。这里我们将只创建一个 Person 类实例并在 Student 中使用它。</p>
<p>Student.java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Student</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Person person;</span><br><span class="line">    <span class="comment">//Setters and Getters</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Person</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> String address;</span><br><span class="line">    <span class="comment">//Setters and Getters</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>bean.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">“StudentBean</span>&quot; <span class="attr">class</span>=<span class="string">&quot;com.edureka.Student&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;person&quot;</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--This is inner bean --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">bean</span> <span class="attr">class</span>=<span class="string">&quot;com.edureka.Person&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;name&quot;</span> <span class="attr">value</span>=<span class="string">“Scott</span>&quot;&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;address&quot;</span> <span class="attr">value</span>=<span class="string">“Bangalore</span>&quot;&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="13-什么是-spring-装配？"><a href="#13-什么是-spring-装配？" class="headerlink" title="13. 什么是 spring 装配？"></a>13. 什么是 spring 装配？</h2><p>当 bean 在 Spring 容器中组合在一起时，它被称为装配或 bean 装配。 Spring 容器需要知道需要什么 bean 以及容器应该如何使用依赖注入来将 bean 绑定在一起，同时装配 bean。</p>
<p>Spring 容器能够自动装配 bean。也就是说，可以通过检查 BeanFactory 的内容让 Spring 自动解析 bean 的协作者。</p>
<p>自动装配的不同模式：</p>
<ul>
<li><strong>no</strong> - 这是默认设置，表示没有自动装配。应使用显式 bean 引用进行装配。</li>
<li><strong>byName</strong> - 它根据 bean 的名称注入对象依赖项。它匹配并装配其属性与 XML 文件中由相同名称定义的 bean。</li>
<li><strong>byType</strong> - 它根据类型注入对象依赖项。如果属性的类型与 XML 文件中的一个 bean 名称匹配，则匹配并装配属性。</li>
<li><strong>构造函数</strong> - 它通过调用类的构造函数来注入依赖项。它有大量的参数。</li>
<li><strong>autodetect</strong> - 首先容器尝试通过构造函数使用 autowire 装配，如果不能，则尝试通过 byType 自动装配。</li>
</ul>
<h2 id="14-自动装配有什么局限？"><a href="#14-自动装配有什么局限？" class="headerlink" title="14. 自动装配有什么局限？"></a>14. 自动装配有什么局限？</h2><ul>
<li>覆盖的可能性 - 您始终可以使用 <code>&lt;constructor-arg&gt;</code> 和 <code>&lt;property&gt;</code> 设置指定依赖项，这将覆盖自动装配。</li>
<li>基本元数据类型 - 简单属性（如原数据类型，字符串和类）无法自动装配。</li>
<li>令人困惑的性质 - 总是喜欢使用明确的装配，因为自动装配不太精确。</li>
</ul>
<h2 id="15-Spring中出现同名bean怎么办？"><a href="#15-Spring中出现同名bean怎么办？" class="headerlink" title="15. Spring中出现同名bean怎么办？"></a>15. Spring中出现同名bean怎么办？</h2><ul>
<li>同一个配置文件内同名的Bean，以最上面定义的为准</li>
<li>不同配置文件中存在同名Bean，后解析的配置文件会覆盖先解析的配置文件</li>
<li>同文件中ComponentScan和@Bean出现同名Bean。同文件下@Bean的会生效，@ComponentScan扫描进来不会生效。通过@ComponentScan扫描进来的优先级是最低的，原因就是它扫描进来的Bean定义是最先被注册的~</li>
</ul>
<h2 id="16-Spring-怎么解决循环依赖问题？"><a href="#16-Spring-怎么解决循环依赖问题？" class="headerlink" title="16. Spring 怎么解决循环依赖问题？"></a>16. Spring 怎么解决循环依赖问题？</h2><p>spring对循环依赖的处理有三种情况：<br>①构造器的循环依赖：这种依赖spring是处理不了的，直 接抛出BeanCurrentlylnCreationException异常。<br>②单例模式下的setter循环依赖：通过“三级缓存”处理循环依赖。<br>③非单例循环依赖：无法处理。</p>
<p>下面分析单例模式下的setter循环依赖如何解决</p>
<p>Spring的单例对象的初始化主要分为三步：<br><img src="http://blog-img.coolsen.cn/img/1584761413341_12.png"></p>
<p>（1）createBeanInstance：实例化，其实也就是调用对象的构造方法实例化对象</p>
<p>（2）populateBean：填充属性，这一步主要是多bean的依赖属性进行填充</p>
<p>（3）initializeBean：调用spring xml中的init 方法。</p>
<p>从上面讲述的单例bean初始化步骤我们可以知道，循环依赖主要发生在第一、第二部。也就是构造器循环依赖和field循环依赖。</p>
<p><img src="http://blog-img.coolsen.cn/img/1584758309616_10.png"></p>
<p>举例：A的某个field或者setter依赖了B的实例对象，同时B的某个field或者setter依赖了A的实例对象”这种循环依赖的情况。A首先完成了</p>
<p>初始化的第一步（createBeanINstance实例化），并且将自己提前曝光到singletonFactories中。</p>
<p>此时进行初始化的第二步，发现自己依赖对象B，此时就尝试去get(B)，发现B还没有被create，所以走create流程，B在初始化第一步的时候发现自己依赖了对象A，于是尝试get(A)，尝试一级缓存singletonObjects(肯定没有，因为A还没初始化完全)，尝试二级缓存earlySingletonObjects（也没有），尝试三级缓存singletonFactories，由于A通过ObjectFactory将自己提前曝光了，所以B能够通过</p>
<p>ObjectFactory.getObject拿到A对象(虽然A还没有初始化完全，但是总比没有好呀)，B拿到A对象后顺利完成了初始化阶段1、2、3，完全初始化之后将自己放入到一级缓存singletonObjects中。</p>
<p>此时返回A中，A此时能拿到B的对象顺利完成自己的初始化阶段2、3，最终A也完成了初始化，进去了一级缓存singletonObjects中，而且更加幸运的是，由于B拿到了A的对象引用，所以B现在hold住的A对象完成了初始化。</p>
<h2 id="17-Spring-中的单例-bean-的线程安全问题？"><a href="#17-Spring-中的单例-bean-的线程安全问题？" class="headerlink" title="17. Spring 中的单例 bean 的线程安全问题？"></a>17. Spring 中的单例 bean 的线程安全问题？</h2><p>当多个用户同时请求一个服务时，容器会给每一个请求分配一个线程，这时多个线程会并发执行该请求对应的业务逻辑（成员方法），此时就要注意了，如果该处理逻辑中有对单例状态的修改（体现为该单例的成员属性），则必须考虑线程同步问题。<br><strong>线程安全问题都是由全局变量及静态变量引起的。</strong><br>若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则就可能影响线程安全.</p>
<p><strong>无状态bean和有状态bean</strong></p>
<ul>
<li>有状态就是有数据存储功能。有状态对象(Stateful Bean)，就是有实例变量的对象，可以保存数据，是非线程安全的。在不同方法调用间不保留任何状态。</li>
<li>无状态就是一次操作，不能保存数据。无状态对象(Stateless Bean)，就是没有实例变量的对象 .不能保存数据，是不变类，是线程安全的。</li>
</ul>
<p>在spring中无状态的Bean适合用不变模式，就是单例模式，这样可以共享实例提高性能。有状态的Bean在多线程环境下不安全，适合用Prototype原型模式。<br>Spring使用ThreadLocal解决线程安全问题。如果你的Bean有多种状态的话（比如 View Model 对象），就需要自行保证线程安全 。</p>
<h2 id="18-什么是-AOP？"><a href="#18-什么是-AOP？" class="headerlink" title="18. 什么是 AOP？"></a>18. 什么是 AOP？</h2><p>AOP(Aspect-Oriented Programming), 即 <strong>面向切面编程</strong>, 它与 OOP( Object-Oriented Programming, 面向对象编程) 相辅相成, 提供了与 OOP 不同的抽象软件结构的视角.<br>在 OOP 中, 我们以类(class)作为我们的基本单元, 而 AOP 中的基本单元是 <strong>Aspect(切面)</strong></p>
<h2 id="19-AOP-有哪些实现方式？"><a href="#19-AOP-有哪些实现方式？" class="headerlink" title="19. AOP 有哪些实现方式？"></a>19. AOP 有哪些实现方式？</h2><p>实现 AOP 的技术，主要分为两大类：</p>
<ul>
<li>静态代理 - 指使用 AOP 框架提供的命令进行编译，从而在编译阶段就可生成 AOP 代理类，因此也称为编译时增强；<ul>
<li>编译时编织（特殊编译器实现）</li>
<li>类加载时编织（特殊的类加载器实现）。</li>
</ul>
</li>
<li>动态代理 - 在运行时在内存中“临时”生成 AOP 动态代理类，因此也被称为运行时增强。<ul>
<li><code>JDK</code> 动态代理：通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口 。JDK 动态代理的核心是 InvocationHandler 接口和 Proxy 类 。</li>
<li><code>CGLIB</code>动态代理： 如果目标类没有实现接口，那么 <code>Spring AOP</code> 会选择使用 <code>CGLIB</code> 来动态代理目标类 。<code>CGLIB</code> （ Code Generation Library ），是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意， <code>CGLIB</code> 是通过继承的方式做的动态代理，因此如果某个类被标记为 <code>final</code> ，那么它是无法使用 <code>CGLIB</code> 做动态代理的。</li>
</ul>
</li>
</ul>
<h2 id="20-Spring-AOP-and-AspectJ-AOP-有什么区别？"><a href="#20-Spring-AOP-and-AspectJ-AOP-有什么区别？" class="headerlink" title="20. Spring AOP and AspectJ AOP 有什么区别？"></a>20. Spring AOP and AspectJ AOP 有什么区别？</h2><p>Spring AOP 基于动态代理方式实现；AspectJ 基于静态代理方式实现。<br>Spring AOP 仅支持方法级别的 PointCut；提供了完全的 AOP 支持，它还支持属性级别的 PointCut。</p>
<h2 id="21-Spring-框架中用到了哪些设计模式？"><a href="#21-Spring-框架中用到了哪些设计模式？" class="headerlink" title="21. Spring 框架中用到了哪些设计模式？"></a>21. Spring 框架中用到了哪些设计模式？</h2><p><strong>工厂设计模式</strong> : Spring使用工厂模式通过 <code>BeanFactory</code>、<code>ApplicationContext</code> 创建 bean 对象。</p>
<p><strong>代理设计模式</strong> : Spring AOP 功能的实现。</p>
<p><strong>单例设计模式</strong> : Spring 中的 Bean 默认都是单例的。</p>
<p><strong>模板方法模式</strong> : Spring 中 <code>jdbcTemplate</code>、<code>hibernateTemplate</code> 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。</p>
<p><strong>包装器设计模式</strong> : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。</p>
<p><strong>观察者模式:</strong> Spring 事件驱动模型就是观察者模式很经典的一个应用。</p>
<p><strong>适配器模式</strong> :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配<code>Controller</code>。</p>
<h2 id="22-Spring-事务实现方式有哪些？"><a href="#22-Spring-事务实现方式有哪些？" class="headerlink" title="22. Spring 事务实现方式有哪些？"></a>22. Spring 事务实现方式有哪些？</h2><ul>
<li>编程式事务管理：这意味着你可以通过编程的方式管理事务，这种方式带来了很大的灵活性，但很难维护。</li>
<li>声明式事务管理：这种方式意味着你可以将事务管理和业务代码分离。你只需要通过注解或者XML配置管理事务。</li>
</ul>
<h2 id="23-Spring框架的事务管理有哪些优点？"><a href="#23-Spring框架的事务管理有哪些优点？" class="headerlink" title="23. Spring框架的事务管理有哪些优点？"></a>23. Spring框架的事务管理有哪些优点？</h2><ul>
<li><p>它提供了跨不同事务api（如JTA、JDBC、Hibernate、JPA和JDO）的一致编程模型。</p>
</li>
<li><p>它为编程事务管理提供了比JTA等许多复杂事务API更简单的API。</p>
</li>
<li><p>它支持声明式事务管理。</p>
</li>
<li><p>它很好地集成了Spring的各种数据访问抽象。</p>
</li>
</ul>
<h2 id="24-spring事务定义的传播规则"><a href="#24-spring事务定义的传播规则" class="headerlink" title="24. spring事务定义的传播规则"></a>24. spring事务定义的传播规则</h2><ul>
<li>PROPAGATION_REQUIRED: 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。</li>
<li>PROPAGATION_SUPPORTS: 支持当前事务，如果当前没有事务，就以非事务方式执行。</li>
<li>PROPAGATION_MANDATORY: 支持当前事务，如果当前没有事务，就抛出异常。</li>
<li>PROPAGATION_REQUIRES_NEW: 新建事务，如果当前存在事务，把当前事务挂起。</li>
<li>PROPAGATION_NOT_SUPPORTED: 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。</li>
<li>PROPAGATION_NEVER: 以非事务方式执行，如果当前存在事务，则抛出异常。</li>
<li>PROPAGATION_NESTED:如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。</li>
</ul>
<h2 id="25-SpringMVC-工作原理了解吗"><a href="#25-SpringMVC-工作原理了解吗" class="headerlink" title="25. SpringMVC 工作原理了解吗?"></a>25. SpringMVC 工作原理了解吗?</h2><p><strong>原理如下图所示：</strong></p>
<p><img src="http://blog-img.coolsen.cn/img/SpingMVC-Process.jpg" alt="img"></p>
<p>上图的一个笔误的小问题：Spring MVC 的入口函数也就是前端控制器 <code>DispatcherServlet</code> 的作用是接收请求，响应结果。</p>
<p><strong>流程说明（重要）：</strong></p>
<ol>
<li>客户端（浏览器）发送请求，直接请求到 <code>DispatcherServlet</code>。</li>
<li><code>DispatcherServlet</code> 根据请求信息调用 <code>HandlerMapping</code>，解析请求对应的 <code>Handler</code>。</li>
<li>解析到对应的 <code>Handler</code>（也就是我们平常说的 <code>Controller</code> 控制器）后，开始由 <code>HandlerAdapter</code> 适配器处理。</li>
<li><code>HandlerAdapter</code> 会根据 <code>Handler</code>来调用真正的处理器开处理请求，并处理相应的业务逻辑。</li>
<li>处理器处理完业务后，会返回一个 <code>ModelAndView</code> 对象，<code>Model</code> 是返回的数据对象，<code>View</code> 是个逻辑上的 <code>View</code>。</li>
<li><code>ViewResolver</code> 会根据逻辑 <code>View</code> 查找实际的 <code>View</code>。</li>
<li><code>DispaterServlet</code> 把返回的 <code>Model</code> 传给 <code>View</code>（视图渲染）。</li>
<li>把 <code>View</code> 返回给请求者（浏览器）</li>
</ol>
<h2 id="26-简单介绍-Spring-MVC-的核心组件"><a href="#26-简单介绍-Spring-MVC-的核心组件" class="headerlink" title="26. 简单介绍 Spring MVC 的核心组件"></a>26. 简单介绍 Spring MVC 的核心组件</h2><p>那么接下来就简单介绍一下 <code>DispatcherServlet</code> 和九大组件（按使用顺序排序的）：</p>
<table>
<thead>
<tr>
<th align="left">组件</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">DispatcherServlet</td>
<td align="left">Spring MVC 的核心组件，是请求的入口，负责协调各个组件工作</td>
</tr>
<tr>
<td align="left">MultipartResolver</td>
<td align="left">内容类型( <code>Content-Type</code> )为 <code>multipart/*</code> 的请求的解析器，例如解析处理文件上传的请求，便于获取参数信息以及上传的文件</td>
</tr>
<tr>
<td align="left">HandlerMapping</td>
<td align="left">请求的处理器匹配器，负责为请求找到合适的 <code>HandlerExecutionChain</code> 处理器执行链，包含处理器（<code>handler</code>）和拦截器们（<code>interceptors</code>）</td>
</tr>
<tr>
<td align="left">HandlerAdapter</td>
<td align="left">处理器的适配器。因为处理器 <code>handler</code> 的类型是 Object 类型，需要有一个调用者来实现 <code>handler</code> 是怎么被执行。Spring 中的处理器的实现多变，比如用户处理器可以实现 Controller 接口、HttpRequestHandler 接口，也可以用 <code>@RequestMapping</code> 注解将方法作为一个处理器等，这就导致 Spring MVC 无法直接执行这个处理器。所以这里需要一个处理器适配器，由它去执行处理器</td>
</tr>
<tr>
<td align="left">HandlerExceptionResolver</td>
<td align="left">处理器异常解析器，将处理器（ <code>handler</code> ）执行时发生的异常，解析( 转换 )成对应的 ModelAndView 结果</td>
</tr>
<tr>
<td align="left">RequestToViewNameTranslator</td>
<td align="left">视图名称转换器，用于解析出请求的默认视图名</td>
</tr>
<tr>
<td align="left">LocaleResolver</td>
<td align="left">本地化（国际化）解析器，提供国际化支持</td>
</tr>
<tr>
<td align="left">ThemeResolver</td>
<td align="left">主题解析器，提供可设置应用整体样式风格的支持</td>
</tr>
<tr>
<td align="left">ViewResolver</td>
<td align="left">视图解析器，根据视图名和国际化，获得最终的视图 View 对象</td>
</tr>
<tr>
<td align="left">FlashMapManager</td>
<td align="left">FlashMap 管理器，负责重定向时，保存参数至临时存储（默认 Session）</td>
</tr>
</tbody></table>
<p>Spring MVC 对各个组件的职责划分的比较清晰。<code>DispatcherServlet</code> 负责协调，其他组件则各自做分内之事，互不干扰。</p>
<h2 id="27-Controller-注解有什么用？"><a href="#27-Controller-注解有什么用？" class="headerlink" title="27. @Controller 注解有什么用？"></a>27. @Controller 注解有什么用？</h2><p><code>@Controller</code> 注解标记一个类为 Spring Web MVC <strong>控制器</strong> Controller。Spring MVC 会将扫描到该注解的类，然后扫描这个类下面带有 <code>@RequestMapping</code> 注解的方法，根据注解信息，为这个方法生成一个对应的<strong>处理器</strong>对象，在上面的 HandlerMapping 和 HandlerAdapter组件中讲到过。</p>
<p>当然，除了添加 <code>@Controller</code> 注解这种方式以外，你还可以实现 Spring MVC 提供的 <code>Controller</code> 或者 <code>HttpRequestHandler</code> 接口，对应的实现类也会被作为一个<strong>处理器</strong>对象</p>
<h2 id="28-RequestMapping-注解有什么用？"><a href="#28-RequestMapping-注解有什么用？" class="headerlink" title="28. @RequestMapping 注解有什么用？"></a>28. @RequestMapping 注解有什么用？</h2><p><code>@RequestMapping</code> 注解，在上面已经讲过了，配置<strong>处理器</strong>的 HTTP 请求方法，URI等信息，这样才能将请求和方法进行映射。这个注解可以作用于类上面，也可以作用于方法上面，在类上面一般是配置这个<strong>控制器</strong>的 URI 前缀</p>
<h2 id="29-RestController-和-Controller-有什么区别？"><a href="#29-RestController-和-Controller-有什么区别？" class="headerlink" title="29. @RestController 和 @Controller 有什么区别？"></a>29. @RestController 和 @Controller 有什么区别？</h2><p><code>@RestController</code> 注解，在 <code>@Controller</code> 基础上，增加了 <code>@ResponseBody</code> 注解，更加适合目前前后端分离的架构下，提供 Restful API ，返回例如 JSON 数据格式。当然，返回什么样的数据格式，根据客户端的 <code>ACCEPT</code> 请求头来决定。</p>
<h2 id="30-RequestMapping-和-GetMapping-注解的不同之处在哪里？"><a href="#30-RequestMapping-和-GetMapping-注解的不同之处在哪里？" class="headerlink" title="30. @RequestMapping 和 @GetMapping 注解的不同之处在哪里？"></a>30. @RequestMapping 和 @GetMapping 注解的不同之处在哪里？</h2><ol>
<li><code>@RequestMapping</code>：可注解在类和方法上；<code>@GetMapping</code> 仅可注册在方法上</li>
<li><code>@RequestMapping</code>：可进行 GET、POST、PUT、DELETE 等请求方法；<code>@GetMapping</code> 是 <code>@RequestMapping</code> 的 GET 请求方法的特例，目的是为了提高清晰度。</li>
</ol>
<h2 id="31-RequestParam-和-PathVariable-两个注解的区别"><a href="#31-RequestParam-和-PathVariable-两个注解的区别" class="headerlink" title="31. @RequestParam 和 @PathVariable 两个注解的区别"></a>31. @RequestParam 和 @PathVariable 两个注解的区别</h2><p>两个注解都用于方法参数，获取参数值的方式不同，<code>@RequestParam</code> 注解的参数从请求携带的参数中获取，而 <code>@PathVariable</code> 注解从请求的 URI 中获取</p>
<h2 id="32-返回-JSON-格式使用什么注解？"><a href="#32-返回-JSON-格式使用什么注解？" class="headerlink" title="32. 返回 JSON 格式使用什么注解？"></a>32. 返回 JSON 格式使用什么注解？</h2><p>可以使用 <strong><code>@ResponseBody</code></strong> 注解，或者使用包含 <code>@ResponseBody</code> 注解的 <strong><code>@RestController</code></strong> 注解。</p>
<p>当然，还是需要配合相应的支持 JSON 格式化的 HttpMessageConverter 实现类。例如，Spring MVC 默认使用 MappingJackson2HttpMessageConverter。</p>
<h2 id="33-什么是springmvc拦截器以及如何使用它？"><a href="#33-什么是springmvc拦截器以及如何使用它？" class="headerlink" title="33. 什么是springmvc拦截器以及如何使用它？"></a>33. 什么是springmvc拦截器以及如何使用它？</h2><p>Spring的处理程序映射机制包括处理程序拦截器，当你希望将特定功能应用于某些请求时，例如，检查用户主题时，这些拦截器非常有用。拦截器必须实现org.springframework.web.servlet包的HandlerInterceptor。此接口定义了三种方法：</p>
<ul>
<li>preHandle：在执行实际处理程序之前调用。</li>
<li>postHandle：在执行完实际程序之后调用。</li>
<li>afterCompletion：在完成请求后调用。</li>
</ul>
<h2 id="34-Spring-MVC-和-Struts2-的异同？"><a href="#34-Spring-MVC-和-Struts2-的异同？" class="headerlink" title="34. Spring MVC 和 Struts2 的异同？"></a>34. Spring MVC 和 Struts2 的异同？</h2><p><strong>入口</strong>不同</p>
<ul>
<li>Spring MVC 的入门是一个 Servlet <strong>控制器</strong>。</li>
<li>Struts2 入门是一个 Filter <strong>过滤器</strong>。</li>
</ul>
<p><strong>配置映射</strong>不同，</p>
<ul>
<li>Spring MVC 是基于<strong>方法</strong>开发，传递参数是通过<strong>方法形参</strong>，一般设置为<strong>单例</strong>。</li>
<li>Struts2 是基于<strong>类</strong>开发，传递参数是通过<strong>类的属性</strong>，只能设计为<strong>多例</strong>。</li>
</ul>
<p><strong>视图</strong>不同</p>
<ul>
<li>Spring MVC 通过参数解析器是将 Request 对象内容进行解析成方法形参，将响应数据和页面封装成 <strong>ModelAndView</strong> 对象，最后又将模型数据通过 <strong>Request</strong> 对象传输到页面。其中，如果视图使用 JSP 时，默认使用 <strong>JSTL</strong> 。</li>
<li>Struts2 采用<strong>值栈</strong>存储请求和响应的数据，通过 <strong>OGNL</strong> 存取数据。</li>
</ul>
<h2 id="35-REST-代表着什么"><a href="#35-REST-代表着什么" class="headerlink" title="35. REST 代表着什么?"></a>35. REST 代表着什么?</h2><p>REST 代表着抽象状态转移，它是根据 HTTP 协议从客户端发送数据到服务端，例如：服务端的一本书可以以 XML 或 JSON 格式传递到客户端</p>
<p>可以看看 <a target="_blank" rel="noopener" href="http://bit.ly/2zIGzWK">REST API design and development</a> ，知乎上的 <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/28557115">《怎样用通俗的语言解释 REST，以及 RESTful？》</a>了解。</p>
<h2 id="36-什么是安全的-REST-操作"><a href="#36-什么是安全的-REST-操作" class="headerlink" title="36. 什么是安全的 REST 操作?"></a>36. 什么是安全的 REST 操作?</h2><p>REST 接口是通过 HTTP 方法完成操作</p>
<ul>
<li>一些 HTTP 操作是安全的，如 GET 和 HEAD ，它不能在服务端修改资源</li>
<li>换句话说，PUT、POST 和 DELETE 是不安全的，因为他们能修改服务端的资源</li>
</ul>
<p>所以，是否安全的界限，在于<strong>是否修改</strong>服务端的资源</p>
<h2 id="37-REST-API-是无状态的吗"><a href="#37-REST-API-是无状态的吗" class="headerlink" title="37. REST API 是无状态的吗?"></a>37. REST API 是无状态的吗?</h2><p><strong>是的</strong>，REST API 应该是无状态的，因为它是基于 HTTP 的，它也是无状态的</p>
<p>REST API 中的请求应该包含处理它所需的所有细节。它<strong>不应该</strong>依赖于以前或下一个请求或服务器端维护的一些数据，例如会话</p>
<p><strong>REST 规范为使其无状态设置了一个约束，在设计 REST API 时，你应该记住这一点</strong></p>
<h2 id="38-REST安全吗-你能做什么来保护它"><a href="#38-REST安全吗-你能做什么来保护它" class="headerlink" title="38. REST安全吗? 你能做什么来保护它?"></a>38. REST安全吗? 你能做什么来保护它?</h2><p>安全是一个宽泛的术语。它可能意味着消息的安全性，这是通过认证和授权提供的加密或访问限制提供的</p>
<p>REST 通常不是安全的，需要开发人员自己实现安全机制</p>
<h2 id="39-为什么要用SpringBoot"><a href="#39-为什么要用SpringBoot" class="headerlink" title="39. 为什么要用SpringBoot?"></a>39. 为什么要用SpringBoot?</h2><p>在使用Spring框架进行开发的过程中，需要配置很多Spring框架包的依赖，如spring-core、spring-bean、spring-context等，而这些配置通常都是重复添加的，而且需要做很多框架使用及环境参数的重复配置，如开启注解、配置日志等。Spring Boot致力于弱化这些不必要的操作，提供默认配置，当然这些默认配置是可以按需修改的，快速搭建、开发和运行Spring应用。</p>
<p>以下是使用SpringBoot的一些好处：</p>
<ul>
<li>自动配置，使用基于类路径和应用程序上下文的智能默认值，当然也可以根据需要重写它们以满足开发人员的需求。</li>
<li>创建Spring Boot Starter 项目时，可以选择选择需要的功能，Spring Boot将为你管理依赖关系。</li>
<li>SpringBoot项目可以打包成jar文件。可以使用Java-jar命令从命令行将应用程序作为独立的Java应用程序运行。</li>
<li>在开发web应用程序时，springboot会配置一个嵌入式Tomcat服务器，以便它可以作为独立的应用程序运行。（Tomcat是默认的，当然你也可以配置Jetty或Undertow）</li>
<li>SpringBoot包括许多有用的非功能特性（例如安全和健康检查）。</li>
</ul>
<h2 id="40-Spring-Boot中如何实现对不同环境的属性配置文件的支持？"><a href="#40-Spring-Boot中如何实现对不同环境的属性配置文件的支持？" class="headerlink" title="40. Spring Boot中如何实现对不同环境的属性配置文件的支持？"></a>40. Spring Boot中如何实现对不同环境的属性配置文件的支持？</h2><p>Spring Boot支持不同环境的属性配置文件切换，通过创建application-{profile}.properties文件，其中{profile}是具体的环境标识名称，例如：application-dev.properties用于开发环境，application-test.properties用于测试环境，application-uat.properties用于uat环境。如果要想使用application-dev.properties文件，则在application.properties文件中添加spring.profiles.active&#x3D;dev。</p>
<p>如果要想使用application-test.properties文件，则在application.properties文件中添加spring.profiles.active&#x3D;test。</p>
<h2 id="41-Spring-Boot-的核心注解是哪个？它主要由哪几个注解组成的？"><a href="#41-Spring-Boot-的核心注解是哪个？它主要由哪几个注解组成的？" class="headerlink" title="41. Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的？"></a>41. Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的？</h2><p>启动类上面的注解是@SpringBootApplication，它也是 Spring Boot 的核心注解，主要组合包含了以下 3 个注解：</p>
<p>@SpringBootConfiguration：组合了 @Configuration 注解，实现配置文件的功能。</p>
<p>@EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项，如关闭数据源自动配置功能： @SpringBootApplication(exclude &#x3D; { DataSourceAutoConfiguration.class })。</p>
<p>@ComponentScan：Spring组件扫描。</p>
<h2 id="42-你如何理解-Spring-Boot-中的-Starters？"><a href="#42-你如何理解-Spring-Boot-中的-Starters？" class="headerlink" title="42. 你如何理解 Spring Boot 中的 Starters？"></a>42. 你如何理解 Spring Boot 中的 Starters？</h2><p>Starters可以理解为启动器，它包含了一系列可以集成到应用里面的依赖包，你可以一站式集成 Spring 及其他技术，而不需要到处找示例代码和依赖包。如你想使用 Spring JPA 访问数据库，只要加入 spring-boot-starter-data-jpa 启动器依赖就能使用了。</p>
<p>Starters包含了许多项目中需要用到的依赖，它们能快速持续的运行，都是一系列得到支持的管理传递性依赖。</p>
<h2 id="43-Spring-Boot-Starter-的工作原理是什么？"><a href="#43-Spring-Boot-Starter-的工作原理是什么？" class="headerlink" title="43. Spring Boot Starter 的工作原理是什么？"></a>43. Spring Boot Starter 的工作原理是什么？</h2><p>Spring Boot 在启动的时候会干这几件事情：</p>
<ul>
<li>Spring Boot 在启动时会去依赖的 Starter 包中寻找 resources&#x2F;META-INF&#x2F;spring.factories 文件，然后根据文件中配置的 Jar 包去扫描项目所依赖的 Jar 包。</li>
<li>根据 spring.factories 配置加载 AutoConfigure 类</li>
<li>根据 @Conditional 注解的条件，进行自动配置并将 Bean 注入 Spring Context</li>
</ul>
<p>总结一下，其实就是 Spring Boot 在启动的时候，按照约定去读取 Spring Boot Starter 的配置信息，再根据配置信息对资源进行初始化，并注入到 Spring 容器中。这样 Spring Boot 启动完毕后，就已经准备好了一切资源，使用过程中直接注入对应 Bean 资源即可</p>
<h2 id="44-保护-Spring-Boot-应用有哪些方法？"><a href="#44-保护-Spring-Boot-应用有哪些方法？" class="headerlink" title="44. 保护 Spring Boot 应用有哪些方法？"></a>44. 保护 Spring Boot 应用有哪些方法？</h2><ul>
<li>在生产中使用HTTPS</li>
<li>使用Snyk检查你的依赖关系</li>
<li>升级到最新版本</li>
<li>启用CSRF保护</li>
<li>使用内容安全策略防止XSS攻击</li>
</ul>
<h2 id="45-Spring-、Spring-Boot-和-Spring-Cloud-的关系"><a href="#45-Spring-、Spring-Boot-和-Spring-Cloud-的关系" class="headerlink" title="45. Spring 、Spring Boot 和 Spring Cloud 的关系?"></a>45. Spring 、Spring Boot 和 Spring Cloud 的关系?</h2><p>Spring 最初最核心的两大核心功能 Spring Ioc 和 Spring Aop 成就了 Spring，Spring 在这两大核心的功能上不断的发展，才有了 Spring 事务、Spring Mvc 等一系列伟大的产品，最终成就了 Spring 帝国，到了后期 Spring 几乎可以解决企业开发中的所有问题。</p>
<p>Spring Boot 是在强大的 Spring 帝国生态基础上面发展而来，发明 Spring Boot 不是为了取代 Spring ,是为了让人们更容易的使用 Spring 。</p>
<p>Spring Cloud 是一系列框架的有序集合。它利用 Spring Boot 的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用 Spring Boot 的开发风格做到一键启动和部署。</p>
<p>Spring Cloud 是为了解决微服务架构中服务治理而提供的一系列功能的开发框架，并且 Spring Cloud 是完全基于 Spring Boot 而开发，Spring Cloud 利用 Spring Boot 特性整合了开源行业中优秀的组件，整体对外提供了一套在微服务架构中服务治理的解决方案。</p>
<p>用一组不太合理的包含关系来表达它们之间的关系。</p>
<p>Spring ioc&#x2F;aop &gt; Spring &gt; Spring Boot &gt; Spring Cloud</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844903860658503693">https://juejin.cn/post/6844903860658503693</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/jingmoxukong/p/9408037.html">https://www.cnblogs.com/jingmoxukong/p/9408037.html</a></p>
<p><a target="_blank" rel="noopener" href="http://www.ityouknow.com/springboot/2019/07/24/springboot-interview.html">http://www.ityouknow.com/springboot/2019/07/24/springboot-interview.html</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/02/Spring/" data-id="cl3wpiog3000lo0r4ha4v6xzf" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Redis" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/02/Redis/" class="article-date">
  <time class="dt-published" datetime="2022-06-02T07:37:54.197Z" itemprop="datePublished">2022-06-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="1-Redis是什么？简述它的优缺点？"><a href="#1-Redis是什么？简述它的优缺点？" class="headerlink" title="1. Redis是什么？简述它的优缺点？"></a>1. Redis是什么？简述它的优缺点？</h2><p>﻿Redis本质上是一个Key-Value类型的内存数据库，很像Memcached，整个数据库加载在内存当中操作，定期通过异步操作把数据库中的数据flush到硬盘上进行保存。</p>
<p>﻿因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value 数据库。</p>
<p><strong>优点</strong>：</p>
<ul>
<li>读写性能极高， Redis能读的速度是110000次&#x2F;s，写的速度是81000次&#x2F;s。</li>
<li>支持数据持久化，支持AOF和RDB两种持久化方式。</li>
<li>支持事务， Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。</li>
<li>数据结构丰富，除了支持string类型的value外，还支持hash、set、zset、list等数据结构。</li>
<li>支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。</li>
<li>丰富的特性 – Redis还支持 publish&#x2F;subscribe， 通知， key 过期等特性。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。</li>
<li>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。</li>
</ul>
<h2 id="2-Redis为什么这么快？"><a href="#2-Redis为什么这么快？" class="headerlink" title="2. Redis为什么这么快？"></a>2. Redis为什么这么快？</h2><ul>
<li><p>内存存储：Redis是使用内存(in-memeroy)存储，没有磁盘IO上的开销。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)。</p>
</li>
<li><p>单线程实现（ Redis 6.0以前）：Redis使用单个线程处理请求，避免了多个线程之间线程切换和锁资源争用的开销。注意：单线程是指的是在核心网络模型中，网络请求模块使用一个线程来处理，即一个线程处理所有网络请求。</p>
</li>
<li><p>非阻塞IO：Redis使用多路复用IO技术，将epoll作为I&#x2F;O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I&#x2F;O上浪费过多的时间。</p>
</li>
<li><p>优化的数据结构：Redis有诸多可以直接应用的优化数据结构的实现，应用层可以直接使用原生的数据结构提升性能。</p>
</li>
<li><p>使用底层模型不同：Redis直接自己构建了 VM (虚拟内存)机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。</p>
<blockquote>
<p>Redis的VM(虚拟内存)机制就是暂时把不经常访问的数据(冷数据)从内存交换到磁盘中，从而腾出宝贵的内存空间用于其它需要访问的数据(热数据)。通过VM功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就可以避免因为内存不足而造成访问速度下降的问题。</p>
<p>Redis提高数据库容量的办法有两种：一种是可以将数据分割到多个RedisServer上；另一种是使用虚拟内存把那些不经常访问的数据交换到磁盘上。<strong>需要特别注意的是Redis并没有使用OS提供的Swap，而是自己实现。</strong></p>
</blockquote>
</li>
</ul>
<h2 id="3-Redis相比Memcached有哪些优势？"><a href="#3-Redis相比Memcached有哪些优势？" class="headerlink" title="3. Redis相比Memcached有哪些优势？"></a>3. Redis相比Memcached有哪些优势？</h2><ul>
<li><p>数据类型：Memcached所有的值均是简单的字符串，Redis支持更为丰富的数据类型，支持string(字符串)，list(列表)，Set(集合)、Sorted Set(有序集合)、Hash(哈希)等。</p>
</li>
<li><p>持久化：Redis支持数据落地持久化存储，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 memcache不支持数据持久存储 。</p>
</li>
<li><p>集群模式：Redis提供主从同步机制，以及 Cluster集群部署能力，能够提供高可用服务。Memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据</p>
</li>
<li><p>性能对比：Redis的速度比Memcached快很多。</p>
</li>
<li><p>网络IO模型：Redis使用单线程的多路 IO 复用模型，Memcached使用多线程的非阻塞IO模式。</p>
</li>
<li><p>Redis支持服务器端的数据操作：Redis相比Memcached来说，拥有更多的数据结构和并支持更丰富的数据操作，通常在Memcached里，你需要将数据拿到客户端来进行类似的修改再set回去。</p>
<p>这大大增加了网络IO的次数和数据体积。在Redis中，这些复杂的操作通常和一般的GET&#x2F;SET一样高效。所以，如果需要缓存能够支持更复杂的结构和操作，那么Redis会是不错的选择。</p>
</li>
</ul>
<h2 id="4-为什么要用-Redis-做缓存？"><a href="#4-为什么要用-Redis-做缓存？" class="headerlink" title="4. 为什么要用 Redis 做缓存？"></a>4. 为什么要用 Redis 做缓存？</h2><p><strong>从高并发上来说：</strong></p>
<ul>
<li>直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。</li>
</ul>
<p><strong>从高性能上来说：</strong></p>
<ul>
<li>用户第一次访问数据库中的某些数据。 因为是从硬盘上读取的所以这个过程会比较慢。将该用户访问的数据存在缓存中，下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据。</li>
</ul>
<h2 id="5-为什么要用-Redis-而不用-map-x2F-guava-做缓存"><a href="#5-为什么要用-Redis-而不用-map-x2F-guava-做缓存" class="headerlink" title="5. 为什么要用 Redis 而不用 map&#x2F;guava 做缓存?"></a>5. 为什么要用 Redis 而不用 map&#x2F;guava 做缓存?</h2><p>缓存分为本地缓存和分布式缓存。以java为例，使用自带的map或者guava实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着jvm的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。</p>
<p>使用Redis或memcached之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持Redis或memcached服务的高可用，整个程序架构上较为复杂。</p>
<p>对比:</p>
<ul>
<li>Redis 可以用几十 G 内存来做缓存，Map 不行，一般 JVM 也就分几个 G 数据就够大了；</li>
<li>Redis 的缓存可以持久化，Map 是内存对象，程序一重启数据就没了；</li>
<li>Redis 可以实现分布式的缓存，Map 只能存在创建它的程序里；</li>
<li>Redis 可以处理每秒百万级的并发，是专业的缓存服务，Map 只是一个普通的对象；</li>
<li>Redis 缓存有过期机制，Map 本身无此功能；Redis 有丰富的 API，Map 就简单太多了；</li>
<li>Redis可单独部署，多个项目之间可以共享，本地内存无法共享；</li>
<li>Redis有专门的管理工具可以查看缓存数据。</li>
</ul>
<h2 id="6-Redis的常用场景有哪些"><a href="#6-Redis的常用场景有哪些" class="headerlink" title="6. Redis的常用场景有哪些?"></a>6. Redis的常用场景有哪些?</h2><p><strong>1、缓存</strong></p>
<p>缓存现在几乎是所有中大型网站都在用的必杀技，合理的利用缓存不仅能够提升网站访问速度，还能大大降低数据库的压力。Redis提供了键过期功能，也提供了灵活的键淘汰策略，所以，现在Redis用在缓存的场合非常多。</p>
<p><strong>2、排行榜</strong></p>
<p>很多网站都有排行榜应用的，如京东的月度销量榜单、商品按时间的上新排行榜等。Redis提供的有序集合数据类构能实现各种复杂的排行榜应用。</p>
<p><strong>3、计数器</strong></p>
<p>什么是计数器，如电商网站商品的浏览量、视频网站视频的播放数等。为了保证数据实时效，每次浏览都得给+1，并发量高时如果每次都请求数据库操作无疑是种挑战和压力。Redis提供的incr命令来实现计数器功能，内存操作，性能非常好，非常适用于这些计数场景。</p>
<p><strong>4、分布式会话</strong></p>
<p>集群模式下，在应用不多的情况下一般使用容器自带的session复制功能就能满足，当应用增多相对复杂的系统中，一般都会搭建以Redis等内存数据库为中心的session服务，session不再由容器管理，而是由session服务及内存数据库管理。</p>
<p><strong>5、分布式锁</strong></p>
<p>在很多互联网公司中都使用了分布式技术，分布式技术带来的技术挑战是对同一个资源的并发访问，如全局ID、减库存、秒杀等场景，并发量不大的场景可以使用数据库的悲观锁、乐观锁来实现，但在并发量高的场合中，利用数据库锁来控制资源的并发访问是不太理想的，大大影响了数据库的性能。可以利用Redis的setnx功能来编写分布式的锁，如果设置返回1说明获取锁成功，否则获取锁失败，实际应用中要考虑的细节要更多。</p>
<p><strong>6、 社交网络</strong></p>
<p>点赞、踩、关注&#x2F;被关注、共同好友等是社交网站的基本功能，社交网站的访问量通常来说比较大，而且传统的关系数据库类型不适合存储这种类型的数据，Redis提供的哈希、集合等数据结构能很方便的的实现这些功能。如在微博中的共同好友，通过Redis的set能够很方便得出。</p>
<p><strong>7、最新列表</strong></p>
<p>Redis列表结构，LPUSH可以在列表头部插入一个内容ID作为关键字，LTRIM可用来限制列表的数量，这样列表永远为N个ID，无需查询最新的列表，直接根据ID去到对应的内容页即可。</p>
<p><strong>8、消息系统</strong></p>
<p>消息队列是大型网站必用中间件，如ActiveMQ、RabbitMQ、Kafka等流行的消息队列中间件，主要用于业务解耦、流量削峰及异步处理实时性低的业务。Redis提供了发布&#x2F;订阅及阻塞队列功能，能实现一个简单的消息队列系统。另外，这个不能和专业的消息中间件相比。</p>
<h2 id="7-Redis的数据类型有哪些？"><a href="#7-Redis的数据类型有哪些？" class="headerlink" title="7. Redis的数据类型有哪些？"></a>7. Redis的数据类型有哪些？</h2><p>有五种常用数据类型：String、Hash、Set、List、SortedSet。以及三种特殊的数据类型：Bitmap、HyperLogLog、Geospatial ，其中HyperLogLog、Bitmap的底层都是 String 数据类型，Geospatial 的底层是 Sorted Set 数据类型。</p>
<p><strong>五种常用的数据类型</strong>：</p>
<p>1、String：String是最常用的一种数据类型，普通的key- value 存储都可以归为此类。其中Value既可以是数字也可以是字符串。使用场景：常规key-value缓存应用。常规计数: 微博数， 粉丝数。</p>
<p>2、Hash：Hash 是一个键值(key &#x3D;&gt; value)对集合。Redishash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象，并且可以像数据库中update一个属性一样只修改某一项属性值。</p>
<p>3、Set：Set是一个无序的天然去重的集合，即Key-Set。此外还提供了交集、并集等一系列直接操作集合的方法，对于求共同好友、共同关注什么的功能实现特别方便。</p>
<p>4、List：List是一个有序可重复的集合，其遵循FIFO的原则，底层是依赖双向链表实现的，因此支持正向、反向双重查找。通过List，我们可以很方面的获得类似于最新回复这类的功能实现。</p>
<p>5、SortedSet：类似于java中的TreeSet，是Set的可排序版。此外还支持优先级排序，维护了一个score的参数来实现。适用于排行榜和带权重的消息队列等场景。</p>
<p><strong>三种特殊的数据类型</strong>：</p>
<p>1、Bitmap：位图，Bitmap想象成一个以位为单位数组，数组中的每个单元只能存0或者1，数组的下标在Bitmap中叫做偏移量。使用Bitmap实现统计功能，更省空间。如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用 Bitmap，因为它只用一个 bit 位就能表示 0 或 1。</p>
<p>2、Hyperloglog。HyperLogLog 是一种用于统计基数的数据集合类型，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大</p>
<p>时，计算基数所需的空间总是固定 的、并且是很小的。每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。场景：统计网页的UV（即Unique Visitor，不重复访客，一个人访问某个网站多次，但是还是只计算为一次）。</p>
<p>要注意，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。</p>
<p>3、Geospatial ：主要用于存储地理位置信息，并对存储的信息进行操作，适用场景如朋友的定位、附近的人、打车距离计算等。</p>
<h1 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h1><h2 id="8-Redis持久化机制？"><a href="#8-Redis持久化机制？" class="headerlink" title="8. Redis持久化机制？"></a>8. Redis持久化机制？</h2><p>为了能够重用Redis数据，或者防止系统故障，我们需要将Redis中的数据写入到磁盘空间中，即持久化。</p>
<p>Redis提供了两种不同的持久化方法可以将数据存储在磁盘中，一种叫快照<code>RDB</code>，另一种叫只追加文件<code>AOF</code>。</p>
<p><strong>RDB</strong></p>
<p>在指定的时间间隔内将内存中的数据集快照写入磁盘(<code>Snapshot</code>)，它恢复时是将快照文件直接读到内存里。</p>
<p><strong>优势</strong>：适合大规模的数据恢复；对数据完整性和一致性要求不高</p>
<p><strong>劣势</strong>：在一定间隔时间做一次备份，所以如果Redis意外<code>down</code>掉的话，就会丢失最后一次快照后的所有修改。</p>
<p><strong>AOF</strong></p>
<p>以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，Redis启动之初会读取该文件重新构建数据，换言之，Redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。</p>
<p>AOF采用文件追加方式，文件会越来越大，为避免出现此种情况，新增了重写机制，当AOF文件的大小超过所设定的阈值时， Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集.。</p>
<p><strong>优势</strong></p>
<ul>
<li>每修改同步：<code>appendfsync always</code> 同步持久化，每次发生数据变更会被立即记录到磁盘，性能较差但数据完整性比较好</li>
<li>每秒同步：<code>appendfsync everysec</code> 异步操作，每秒记录，如果一秒内宕机，有数据丢失</li>
<li>不同步：<code>appendfsync no</code>   从不同步</li>
</ul>
<p><strong>劣势</strong></p>
<ul>
<li>相同数据集的数据而言<code>aof</code>文件要远大于<code>rdb</code>文件，恢复速度慢于<code>rdb</code></li>
<li><code>aof</code>运行效率要慢于<code>rdb</code>，每秒同步策略效率较好，不同步效率和<code>rdb</code>相同</li>
</ul>
<h2 id="9-如何选择合适的持久化方式"><a href="#9-如何选择合适的持久化方式" class="headerlink" title="9. 如何选择合适的持久化方式"></a>9. 如何选择合适的持久化方式</h2><ul>
<li>如果是数据不那么敏感，且可以从其他地方重新生成补回的，那么可以关闭持久化。</li>
<li>如果是数据比较重要，不想再从其他地方获取，且可以承受数分钟的数据丢失，比如缓存等，那么可以只使用RDB。</li>
<li>如果是用做内存数据库，要使用Redis的持久化，建议是RDB和AOF都开启，或者定期执行bgsave做快照备份，RDB方式更适合做数据的备份，AOF可以保证数据的不丢失。</li>
</ul>
<p><strong>补充：Redis4.0 对于持久化机制的优化</strong></p>
<p>Redis4.0相对与3.X版本其中一个比较大的变化是4.0添加了新的混合持久化方式。</p>
<p>简单的说：新的AOF文件前半段是RDB格式的全量数据后半段是AOF格式的增量数据，如下图：</p>
<p><img src="https://images2018.cnblogs.com/blog/1075473/201807/1075473-20180726181756270-1907770368.png"></p>
<p><strong>优势</strong>：混合持久化结合了RDB持久化 和 AOF 持久化的优点， 由于绝大部分都是RDB格式，加载速度快，同时结合AOF，增量的数据以AOF方式保存了，数据更少的丢失。</p>
<p><strong>劣势</strong>：兼容性差，一旦开启了混合持久化，在4.0之前版本都不识别该aof文件，同时由于前部分是RDB格式，阅读性较差。</p>
<h2 id="10-Redis持久化数据和缓存怎么做扩容？"><a href="#10-Redis持久化数据和缓存怎么做扩容？" class="headerlink" title="10. Redis持久化数据和缓存怎么做扩容？"></a>10. Redis持久化数据和缓存怎么做扩容？</h2><ul>
<li><p>如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。</p>
</li>
<li><p>如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。</p>
</li>
</ul>
<h1 id="过期键的删除策略、淘汰策略"><a href="#过期键的删除策略、淘汰策略" class="headerlink" title="过期键的删除策略、淘汰策略"></a>过期键的删除策略、淘汰策略</h1><h2 id="11-Redis过期键的删除策略"><a href="#11-Redis过期键的删除策略" class="headerlink" title="11. Redis过期键的删除策略"></a>11. Redis过期键的删除策略</h2><p><strong>Redis的过期删除策略就是：惰性删除和定期删除两种策略配合使用。</strong></p>
<p><strong>惰性删除</strong>：惰性删除不会去主动删除数据，而是在访问数据的时候，再检查当前键值是否过期，如果过期则执行删除并返回 null 给客户端，如果没有过期则返回正常信息给客户端。它的优点是简单，不需要对过期的数据做额外的处理，只有在每次访问的时候才会检查键值是否过期，缺点是删除过期键不及时，造成了一定的空间浪费。</p>
<p><strong>定期删除</strong>：Redis会周期性的随机测试一批设置了过期时间的key并进行处理。测试到的已过期的key将被删除。</p>
<p>附：删除key常见的三种处理方式。</p>
<p><strong>1、定时删除</strong></p>
<p>在设置某个key 的过期时间同时，我们创建一个定时器，让定时器在该过期时间到来时，立即执行对其进行删除的操作。</p>
<p>优点：定时删除对内存是最友好的，能够保存内存的key一旦过期就能立即从内存中删除。</p>
<p>缺点：对CPU最不友好，在过期键比较多的时候，删除过期键会占用一部分 CPU 时间，对服务器的响应时间和吞吐量造成影响。</p>
<p><strong>2、惰性删除</strong></p>
<p>设置该key 过期时间后，我们不去管它，当需要该key时，我们在检查其是否过期，如果过期，我们就删掉它，反之返回该key。</p>
<p>优点：对 CPU友好，我们只会在使用该键时才会进行过期检查，对于很多用不到的key不用浪费时间进行过期检查。</p>
<p>缺点：对内存不友好，如果一个键已经过期，但是一直没有使用，那么该键就会一直存在内存中，如果数据库中有很多这种使用不到的过期键，这些键便永远不会被删除，内存永远不会释放。从而造成内存泄漏。</p>
<p><strong>3、定期删除</strong></p>
<p>每隔一段时间，我们就对一些key进行检查，删除里面过期的key。</p>
<p>优点：可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响。另外定期删除，也能有效释放过期键占用的内存。</p>
<p>缺点：难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好。如果执行的太少，那又和惰性删除一样了，过期键占用的内存不会及时得到释放。另外最重要的是，在获取某个键时，如果某个键的过期时间已经到了，但是还没执行定期删除，那么就会返回这个键的值，这是业务不能忍受的错误。</p>
<h2 id="12-Redis-key的过期时间和永久有效分别怎么设置？"><a href="#12-Redis-key的过期时间和永久有效分别怎么设置？" class="headerlink" title="12. Redis key的过期时间和永久有效分别怎么设置？"></a>12. Redis key的过期时间和永久有效分别怎么设置？</h2><p>通过expire或pexpire命令，客户端可以以秒或毫秒的精度为数据库中的某个键设置生存时间。</p>
<p>与expire和pexpire命令类似，客户端可以通过expireat和pexpireat命令，以秒或毫秒精度给数据库中的某个键设置过期时间，可以理解为：让某个键在某个时间点过期。</p>
<h2 id="13-Redis内存淘汰策略"><a href="#13-Redis内存淘汰策略" class="headerlink" title="13. Redis内存淘汰策略"></a>13. Redis内存淘汰策略</h2><p>Redis是不断的删除一些过期数据，但是很多没有设置过期时间的数据也会越来越多，那么Redis内存不够用的时候是怎么处理的呢？答案就是淘汰策略。此类的</p>
<p>当Redis的内存超过最大允许的内存之后，Redis会触发内存淘汰策略，删除一些不常用的数据，以保证Redis服务器的正常运行。</p>
<p><strong>Redisv4.0前提供 6种数据淘汰策略</strong>：</p>
<ul>
<li>volatile-lru：利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used )</li>
<li>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）</li>
<li>volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰</li>
<li>volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰</li>
<li>allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰</li>
<li>no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！</li>
</ul>
<p><strong>Redisv4.0后增加以下两种</strong>：</p>
<ul>
<li>volatile-lfu：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰(LFU(Least Frequently Used)算法，也就是最频繁被访问的数据将来最有可能被访问到)</li>
<li>allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key。</li>
</ul>
<p>内存淘汰策略可以通过配置文件来修改，Redis.conf对应的配置项是maxmemory-policy 修改对应的值就行，默认是noeviction。</p>
<h1 id="缓存异常"><a href="#缓存异常" class="headerlink" title="缓存异常"></a>缓存异常</h1><blockquote>
<p>缓存异常有四种类型，分别是缓存和数据库的数据不一致、缓存雪崩、缓存击穿和缓存穿透。</p>
</blockquote>
<h2 id="14-如何保证缓存与数据库双写时的数据一致性？"><a href="#14-如何保证缓存与数据库双写时的数据一致性？" class="headerlink" title="14. 如何保证缓存与数据库双写时的数据一致性？"></a>14. 如何保证缓存与数据库双写时的数据一致性？</h2><blockquote>
<p>背景：使用到缓存，无论是本地内存做缓存还是使用 Redis 做缓存，那么就会存在数据同步的问题，因为配置信息缓存在内存中，而内存时无法感知到数据在数据库的修改。这样就会造成数据库中的数据与缓存中数据不一致的问题。</p>
</blockquote>
<p>共有四种方案：</p>
<ol>
<li>先更新数据库，后更新缓存</li>
<li>先更新缓存，后更新数据库</li>
<li>先删除缓存，后更新数据库</li>
<li>先更新数据库，后删除缓存</li>
</ol>
<p>第一种和第二种方案，没有人使用的，因为第一种方案存在问题是：并发更新数据库场景下，会将脏数据刷到缓存。</p>
<p>第二种方案存在的问题是：如果先更新缓存成功，但是数据库更新失败，则肯定会造成数据不一致。</p>
<p>目前主要用第三和第四种方案。</p>
<h2 id="15-先删除缓存，后更新数据库"><a href="#15-先删除缓存，后更新数据库" class="headerlink" title="15. 先删除缓存，后更新数据库"></a>15. 先删除缓存，后更新数据库</h2><p>该方案也会出问题，此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作）</p>
<ol>
<li>请求A进行写操作，删除缓存</li>
<li>请求B查询发现缓存不存在</li>
<li>请求B去数据库查询得到旧值</li>
<li>请求B将旧值写入缓存</li>
<li>请求A将新值写入数据库</li>
</ol>
<p>上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。</p>
<h3 id="答案一：延时双删"><a href="#答案一：延时双删" class="headerlink" title="答案一：延时双删"></a>答案一：延时双删</h3><p>最简单的解决办法延时双删</p>
<p>使用伪代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(String key,Object data)</span>&#123;</span><br><span class="line">		Redis.delKey(key);</span><br><span class="line">	    db.updateData(data);</span><br><span class="line">	    Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">	    Redis.delKey(key);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<p>转化为中文描述就是<br>（1）先淘汰缓存<br>（2）再写数据库（这两步和原来一样）<br>（3）休眠1秒，再次淘汰缓存，这么做，可以将1秒内所造成的缓存脏数据，再次删除。确保读请求结束，写请求可以删除读请求造成的缓存脏数据。自行评估自己的项目的读数据业务逻辑的耗时，写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。</p>
<p>如果使用的是 Mysql 的读写分离的架构的话，那么其实主从同步之间也会有时间差。</p>
<p><img src="http://blog-img.coolsen.cn/img/1735bb5881bbb1d4~tplv-t2oaga2asx-watermark.awebp" alt="主从同步时间差"></p>
<p>此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作）</p>
<ol>
<li>请求 A 更新操作，删除了 Redis</li>
<li>请求主库进行更新操作，主库与从库进行同步数据的操作</li>
<li>请 B 查询操作，发现 Redis 中没有数据</li>
<li>去从库中拿去数据</li>
<li>此时同步数据还未完成，拿到的数据是旧数据</li>
</ol>
<p>此时的解决办法就是如果是对 Redis 进行填充数据的查询数据库操作，那么就强制将其指向主库进行查询。</p>
<p><img src="http://blog-img.coolsen.cn/img/1735bb5881a19fec~tplv-t2oaga2asx-watermark.awebp" alt="从主库中拿数据"></p>
<h3 id="答案二：-更新与读取操作进行异步串行化"><a href="#答案二：-更新与读取操作进行异步串行化" class="headerlink" title="答案二： 更新与读取操作进行异步串行化"></a>答案二： <strong>更新与读取操作进行异步串行化</strong></h3><p>采用<strong>更新与读取操作进行异步串行化</strong></p>
<p><strong>异步串行化</strong></p>
<p>我在系统内部维护n个内存队列，更新数据的时候，根据数据的唯一标识，将该操作路由之后，发送到其中一个jvm内部的内存队列中（对同一数据的请求发送到同一个队列）。读取数据的时候，如果发现数据不在缓存中，并且此时队列里有更新库存的操作，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也将发送到同一个jvm内部的内存队列中。然后每个队列对应一个工作线程，每个工作线程串行地拿到对应的操作，然后一条一条的执行。</p>
<p>这样的话，一个数据变更的操作，先执行删除缓存，然后再去更新数据库，但是还没完成更新的时候，如果此时一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，排在刚才更新库的操作之后，然后同步等待缓存更新完成，再读库。</p>
<p><strong>读操作去重</strong></p>
<p>多个读库更新缓存的请求串在同一个队列中是没意义的，因此可以做过滤，如果发现队列中已经有了该数据的更新缓存的请求了，那么就不用再放进去了，直接等待前面的更新操作请求完成即可，待那个队列对应的工作线程完成了上一个操作（数据库的修改）之后，才会去执行下一个操作（读库更新缓存），此时会从数据库中读取最新的值，然后写入缓存中。</p>
<p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。（返回旧值不是又导致缓存和数据库不一致了么？那至少可以减少这个情况发生，因为等待超时也不是每次都是，几率很小吧。这里我想的是，如果超时了就直接读旧值，这时候仅仅是读库后返回而不放缓存）</p>
<h2 id="16-先更新数据库，后删除缓存"><a href="#16-先更新数据库，后删除缓存" class="headerlink" title="16. 先更新数据库，后删除缓存"></a>16. 先更新数据库，后删除缓存</h2><p>这一种情况也会出现问题，比如更新数据库成功了，但是在删除缓存的阶段出错了没有删除成功，那么此时再读取缓存的时候每次都是错误的数据了。</p>
<p><img src="http://blog-img.coolsen.cn/img/1735bb5881fb4a1b~tplv-t2oaga2asx-watermark.awebp" alt="先更新数据库，后删除缓存"></p>
<p>此时解决方案就是利用消息队列进行删除的补偿。具体的业务逻辑用语言描述如下：</p>
<ol>
<li>请求 A 先对数据库进行更新操作</li>
<li>在对 Redis 进行删除操作的时候发现报错，删除失败</li>
<li>此时将Redis 的 key 作为消息体发送到消息队列中</li>
<li>系统接收到消息队列发送的消息后再次对 Redis 进行删除操作</li>
</ol>
<p>但是这个方案会有一个缺点就是会对业务代码造成大量的侵入，深深的耦合在一起，所以这时会有一个优化的方案，我们知道对 Mysql 数据库更新操作后再 binlog 日志中我们都能够找到相应的操作，那么我们可以订阅 Mysql 数据库的 binlog 日志对缓存进行操作。</p>
<p><img src="http://blog-img.coolsen.cn/img/1735bb588215b298~tplv-t2oaga2asx-watermark.awebp" alt="利用订阅 binlog 删除缓存"></p>
<h2 id="17-什么是缓存击穿"><a href="#17-什么是缓存击穿" class="headerlink" title="17. 什么是缓存击穿?"></a>17. 什么是缓存击穿?</h2><p>缓存击穿跟缓存雪崩有点类似，缓存雪崩是大规模的key失效，而缓存击穿是某个热点的key失效，大并发集中对其进行请求，就会造成大量请求读缓存没读到数据，从而导致高并发访问数据库，引起数据库压力剧增。这种现象就叫做缓存击穿。</p>
<p>从两个方面解决，第一是否可以考虑热点key不设置过期时间，第二是否可以考虑降低打在数据库上的请求数量。</p>
<p>解决方案：</p>
<ul>
<li><p>在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降</p>
</li>
<li><p>热点数据缓存永远不过期。永不过期实际包含两层意思：</p>
<ul>
<li>物理不过期，针对热点key不设置过期时间</li>
<li>逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建</li>
</ul>
</li>
</ul>
<h2 id="18-什么是缓存穿透"><a href="#18-什么是缓存穿透" class="headerlink" title="18. 什么是缓存穿透?"></a>18. 什么是缓存穿透?</h2><p>缓存穿透是指用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍。如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至导致数据库承受不住而宕机崩溃。</p>
<blockquote>
<p> 缓存穿透的关键在于在Redis中查不到key值，它和缓存击穿的根本区别在于传进来的key在Redis中是不存在的。假如有黑客传进大量的不存在的key，那么大量的请求打在数据库上是很致命的问题，所以在日常开发中要对参数做好校验，一些非法的参数，不可能存在的key就直接返回错误提示。</p>
</blockquote>
<p><img src="http://blog-img.coolsen.cn/img/2021013117512340.png" alt="img"></p>
<p>解决方法：</p>
<ul>
<li>将无效的key存放进Redis中：</li>
</ul>
<p>当出现Redis查不到数据，数据库也查不到数据的情况，我们就把这个key保存到Redis中，设置value&#x3D;”null”，并设置其过期时间极短，后面再出现查询这个key的请求的时候，直接返回null，就不需要再查询数据库了。但这种处理方式是有问题的，假如传进来的这个不存在的Key值每次都是随机的，那存进Redis也没有意义。</p>
<ul>
<li>使用布隆过滤器：</li>
</ul>
<p>如果布隆过滤器判定某个 key 不存在布隆过滤器中，那么就一定不存在，如果判定某个 key 存在，那么很大可能是存在(存在一定的误判率)。于是我们可以在缓存之前再加一个布隆过滤器，将数据库中的所有key都存储在布隆过滤器中，在查询Redis前先去布隆过滤器查询 key 是否存在，如果不存在就直接返回，不让其访问数据库，从而避免了对底层存储系统的查询压力。</p>
<blockquote>
<p>如何选择：针对一些恶意攻击，攻击带过来的大量key是随机，那么我们采用第一种方案就会缓存大量不存在key的数据。那么这种方案就不合适了，我们可以先对使用布隆过滤器方案进行过滤掉这些key。所以，针对这种key异常多、请求重复率比较低的数据，优先使用第二种方案直接过滤掉。而对于空数据的key有限的，重复率比较高的，则可优先采用第一种方式进行缓存。</p>
</blockquote>
<h2 id="19-什么是缓存雪崩"><a href="#19-什么是缓存雪崩" class="headerlink" title="19. 什么是缓存雪崩?"></a>19. 什么是缓存雪崩?</h2><p>如果缓在某一个时刻出现大规模的key失效，那么就会导致大量的请求打在了数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。这时候如果运维马上又重启数据库，马上又会有新的流量把数据库打死。这就是缓存雪崩。</p>
<p>造成缓存雪崩的关键在于同一时间的大规模的key失效，主要有两种可能：第一种是Redis宕机，第二种可能就是采用了相同的过期时间。</p>
<p>解决方案：</p>
<p>1、事前：</p>
<ul>
<li><p>均匀过期：设置不同的过期时间，让缓存失效的时间尽量均匀，避免相同的过期时间导致缓存雪崩，造成大量数据库的访问。如把每个Key的失效时间都加个随机值，<code>setRedis（Key，value，time + Math.random() * 10000）；</code>，保证数据不会在同一时间大面积失效。</p>
</li>
<li><p>分级缓存：第一级缓存失效的基础上，访问二级缓存，每一级缓存的失效时间都不同。</p>
</li>
<li><p>热点数据缓存永远不过期。永不过期实际包含两层意思：</p>
<ul>
<li>物理不过期，针对热点key不设置过期时间</li>
<li>逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建</li>
</ul>
</li>
<li><p>保证Redis缓存的高可用，防止Redis宕机导致缓存雪崩的问题。可以使用 主从+ 哨兵，Redis集群来避免 Redis 全盘崩溃的情况。</p>
</li>
</ul>
<p>2、事中：</p>
<ul>
<li><p>互斥锁：在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降</p>
</li>
<li><p>使用熔断机制，限流降级。当流量达到一定的阈值，直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上将数据库击垮，至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。</p>
</li>
</ul>
<p>3、事后：</p>
<p>开启Redis持久化机制，尽快恢复缓存数据，一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。</p>
<h2 id="20-什么是缓存预热"><a href="#20-什么是缓存预热" class="headerlink" title="20. 什么是缓存预热?"></a>20. 什么是缓存预热?</h2><p>缓存预热是指系统上线后，提前将相关的缓存数据加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户直接查询事先被预热的缓存数据。</p>
<p>如果不进行预热，那么Redis初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。</p>
<p>缓存预热解决方案：</p>
<ul>
<li><p>数据量不大的时候，工程启动的时候进行加载缓存动作；</p>
</li>
<li><p>数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；</p>
</li>
<li><p>数据量太大的时候，优先保证热点数据进行提前加载到缓存。</p>
</li>
</ul>
<h2 id="21-什么是缓存降级？"><a href="#21-什么是缓存降级？" class="headerlink" title="21. 什么是缓存降级？"></a>21. 什么是缓存降级？</h2><p>缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。</p>
<p>在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：</p>
<ul>
<li><p>一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</p>
</li>
<li><p>警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；</p>
</li>
<li><p>错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；</p>
</li>
<li><p>严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</p>
</li>
</ul>
<h1 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h1><h2 id="22-Redis为何选择单线程？"><a href="#22-Redis为何选择单线程？" class="headerlink" title="22. Redis为何选择单线程？"></a>22. Redis为何选择单线程？</h2><p>在Redis 6.0以前，Redis的核心网络模型选择用单线程来实现。先来看下官方的回答：</p>
<blockquote>
<p>It’s not very frequent that CPU becomes your bottleneck with Redis， as usually Redisis either memory or network bound. For instance， using pipelining Redisrunning on an average Linux system can deliver even 1 million requests per second， so if your application mainly uses O(N) or O(log(N)) commands， it is hardly going to use too much CPU.</p>
</blockquote>
<p>核心意思就是，对于一个 DB 来说，CPU 通常不会是瓶颈，因为大多数请求不会是 CPU 密集型的，而是 I&#x2F;O 密集型。具体到 Redis的话，如果不考虑 RDB&#x2F;AOF 等持久化方案，Redis是完全的纯内存操作，执行速度是非常快的，因此这部分操作通常不会是性能瓶颈，Redis真正的性能瓶颈在于网络 I&#x2F;O，也就是客户端和服务端之间的网络传输延迟，因此 Redis选择了单线程的 I&#x2F;O 多路复用来实现它的核心网络模型。</p>
<p>实际上更加具体的选择单线程的原因如下：</p>
<ul>
<li>避免过多的上下文切换开销：如果是单线程则可以规避进程内频繁的线程切换开销，因为程序始终运行在进程中单个线程内，没有多线程切换的场景。</li>
<li>避免同步机制的开销：如果 Redis选择多线程模型，又因为 Redis是一个数据库，那么势必涉及到底层数据同步的问题，则必然会引入某些同步机制，比如锁，而我们知道 Redis不仅仅提供了简单的 key-value 数据结构，还有 list、set 和 hash 等等其他丰富的数据结构，而不同的数据结构对同步访问的加锁粒度又不尽相同，可能会导致在操作数据过程中带来很多加锁解锁的开销，增加程序复杂度的同时还会降低性能。</li>
<li>简单可维护：如果 Redis使用多线程模式，那么所有的底层数据结构都必须实现成线程安全的，这无疑又使得 Redis的实现变得更加复杂。</li>
</ul>
<p>总而言之，Redis选择单线程可以说是多方博弈之后的一种权衡：在保证足够的性能表现之下，使用单线程保持代码的简单和可维护性。</p>
<h2 id="23-Redis真的是单线程？"><a href="#23-Redis真的是单线程？" class="headerlink" title="23. Redis真的是单线程？"></a>23. Redis真的是单线程？</h2><p>讨论 这个问题前，先看下 Redis的版本中两个重要的节点：</p>
<ol>
<li>Redisv4.0（引入多线程处理异步任务）</li>
<li>Redis 6.0（在网络模型中实现多线程 I&#x2F;O ）</li>
</ol>
<p>所以，网络上说的Redis是单线程，通常是指在Redis 6.0之前，其核心网络模型使用的是单线程。</p>
<p>且Redis6.0引入<strong>多线程I&#x2F;O</strong>，只是用来<strong>处理网络数据的读写和协议的解析</strong>，而<strong>执行命令依旧是单线程</strong>。</p>
<blockquote>
<p>Redis在 v4.0 版本的时候就已经引入了的多线程来做一些异步操作，此举主要针对的是那些非常耗时的命令，通过将这些命令的执行进行异步化，避免阻塞单线程的事件循环。</p>
<p>在 Redisv4.0 之后增加了一些的非阻塞命令如 <code>UNLINK</code>、<code>FLUSHALL ASYNC</code>、<code>FLUSHDB ASYNC</code>。</p>
</blockquote>
<h2 id="24-Redis-6-0为何引入多线程？"><a href="#24-Redis-6-0为何引入多线程？" class="headerlink" title="24. Redis 6.0为何引入多线程？"></a>24. Redis 6.0为何引入多线程？</h2><p>很简单，就是 Redis的网络 I&#x2F;O 瓶颈已经越来越明显了。</p>
<p>随着互联网的飞速发展，互联网业务系统所要处理的线上流量越来越大，Redis的单线程模式会导致系统消耗很多 CPU 时间在网络 I&#x2F;O 上从而降低吞吐量，要提升 Redis的性能有两个方向：</p>
<ul>
<li>优化网络 I&#x2F;O 模块</li>
<li>提高机器内存读写的速度</li>
</ul>
<p>后者依赖于硬件的发展，暂时无解。所以只能从前者下手，网络 I&#x2F;O 的优化又可以分为两个方向：</p>
<ul>
<li>零拷贝技术或者 DPDK 技术</li>
<li>利用多核优势</li>
</ul>
<p>零拷贝技术有其局限性，无法完全适配 Redis这一类复杂的网络 I&#x2F;O 场景，更多网络 I&#x2F;O 对 CPU 时间的消耗和 Linux 零拷贝技术。而 DPDK 技术通过旁路网卡 I&#x2F;O 绕过内核协议栈的方式又太过于复杂以及需要内核甚至是硬件的支持。</p>
<p>总结起来，Redis支持多线程主要就是两个原因：</p>
<ul>
<li><p>可以充分利用服务器 CPU 资源，目前主线程只能利用一个核</p>
</li>
<li><p>多线程任务可以分摊 Redis 同步 IO 读写负荷</p>
</li>
</ul>
<h2 id="25-Redis-6-0-采用多线程后，性能的提升效果如何？"><a href="#25-Redis-6-0-采用多线程后，性能的提升效果如何？" class="headerlink" title="25. Redis 6.0 采用多线程后，性能的提升效果如何？"></a>25. Redis 6.0 采用多线程后，性能的提升效果如何？</h2><p>Redis 作者 antirez 在 RedisConf 2019 分享时曾提到：Redis 6 引入的多线程 IO 特性对性能提升至少是一倍以上。</p>
<p>国内也有大牛曾使用 unstable 版本在阿里云 esc 进行过测试，GET&#x2F;SET 命令在 4 线程 IO 时性能相比单线程是几乎是翻倍了。</p>
<h2 id="26-介绍下Redis的线程模型"><a href="#26-介绍下Redis的线程模型" class="headerlink" title="26. 介绍下Redis的线程模型"></a>26. 介绍下Redis的线程模型</h2><p>Redis的线程模型包括Redis 6.0之前和Redis 6.0。</p>
<p>下面介绍的是Redis 6.0之前。</p>
<p>Redis 是基于 reactor 模式开发了网络事件处理器，这个处理器叫做文件事件处理器（file event handler）。由于这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。采用 IO 多路复用机制同时监听多个 Socket，根据 socket 上的事件来选择对应的事件处理器来处理这个事件。</p>
<blockquote>
<p>IO多路复用是 IO 模型的一种，有时也称为异步阻塞 IO，是基于经典的 Reactor 设计模式设计的。多路指的是多个 Socket 连接，复用指的是复用一个线程。多路复用主要有三种技术：Select，Poll，Epoll。</p>
<p>Epoll 是最新的也是目前最好的多路复用技术。</p>
</blockquote>
<p>模型如下图：</p>
<p><img src="http://blog-img.coolsen.cn/img/202105092153018231.png" alt="202105092153018231.png"></p>
<p>文件事件处理器的结构包含了四个部分：</p>
<ul>
<li>多个 Socket。Socket 会产生 AE_READABLE 和 AE_WRITABLE 事件：<ul>
<li>当 socket 变得可读时或者有新的可以应答的 socket 出现时，socket 就会产生一个 AE_READABLE 事件</li>
<li>当 socket 变得可写时，socket 就会产生一个 AE_WRITABLE 事件。</li>
</ul>
</li>
<li>IO 多路复用程序</li>
<li>文件事件分派器</li>
<li>事件处理器。事件处理器包括：连接应答处理器、命令请求处理器、命令回复处理器，每个处理器对应不同的 socket 事件：<ul>
<li>如果是客户端要连接 Redis，那么会为 socket 关联连接应答处理器</li>
<li>如果是客户端要写数据到 Redis（读、写请求命令），那么会为 socket 关联命令请求处理器</li>
<li>如果是客户端要从 Redis 读数据，那么会为 socket 关联命令回复处理器</li>
</ul>
</li>
</ul>
<p>多个 socket 会产生不同的事件，不同的事件对应着不同的操作，IO 多路复用程序监听着这些 Socket，当这些 Socket 产生了事件，IO 多路复用程序会将这些事件放到一个队列中，通过这个队列，以有序、同步、每次一个事件的方式向文件时间分派器中传送。当事件处理器处理完一个事件后，IO 多路复用程序才会继续向文件分派器传送下一个事件。</p>
<p>下图是客户端与 Redis 通信的一次完整的流程：</p>
<p><img src="http://blog-img.coolsen.cn/img/202105092153019692.png" alt="202105092153019692.png"></p>
<ol>
<li>Redis 启动初始化的时候，Redis 会将连接应答处理器与 AE_READABLE 事件关联起来。</li>
<li>如果一个客户端跟 Redis 发起连接，此时 Redis 会产生一个 AE_READABLE 事件，由于开始之初 AE_READABLE 是与连接应答处理器关联，所以由连接应答处理器来处理该事件，这时连接应答处理器会与客户端建立连接，创建客户端响应的 socket，同时将这个 socket 的 AE_READABLE 事件与命令请求处理器关联起来。</li>
<li>如果这个时间客户端向 Redis 发送一个命令（set k1 v1），这时 socket 会产生一个 AE_READABLE 事件，IO 多路复用程序会将该事件压入队列中，此时事件分派器从队列中取得该事件，由于该 socket 的 AE_READABLE 事件已经和命令请求处理器关联了，因此事件分派器会将该事件交给命令请求处理器处理，命令请求处理器读取事件中的命令并完成。操作完成后，Redis 会将该 socket 的 AE_WRITABLE 事件与命令回复处理器关联。</li>
<li>如果客户端已经准备好接受数据后，Redis 中的该 socket 会产生一个 AE_WRITABLE 事件，同样会压入队列然后被事件派发器取出交给相对应的命令回复处理器，由该命令回复处理器将准备好的响应数据写入 socket 中，供客户端读取。</li>
<li>命令回复处理器写完后，就会删除该 socket 的 AE_WRITABLE 事件与命令回复处理器的关联关系。</li>
</ol>
<h2 id="27-Redis-6-0-多线程的实现机制？"><a href="#27-Redis-6-0-多线程的实现机制？" class="headerlink" title="27. Redis 6.0 多线程的实现机制？"></a>27. Redis 6.0 多线程的实现机制？</h2><p><strong>流程简述如下</strong>：</p>
<ul>
<li>主线程负责接收建立连接请求，获取 Socket 放入全局等待读处理队列。</li>
<li>主线程处理完读事件之后，通过 RR（Round Robin）将这些连接分配给这些 IO 线程。</li>
<li>主线程阻塞等待 IO 线程读取 Socket 完毕。</li>
<li>主线程通过单线程的方式执行请求命令，请求数据读取并解析完成，但并不执行。</li>
<li>主线程阻塞等待 IO 线程将数据回写 Socket 完毕。</li>
</ul>
<p><img src="http://blog-img.coolsen.cn/img/image-20210828175543973.png" alt="image-20210828175543973"></p>
<p><strong>该设计有如下特点</strong>：</p>
<ul>
<li>IO 线程要么同时在读 Socket，要么同时在写，不会同时读或写。</li>
<li>IO 线程只负责读写 Socket 解析命令，不负责命令处理。</li>
</ul>
<h2 id="28-Redis-6-0开启多线程后，是否会存在线程并发安全问题？"><a href="#28-Redis-6-0开启多线程后，是否会存在线程并发安全问题？" class="headerlink" title="28. Redis 6.0开启多线程后，是否会存在线程并发安全问题？"></a>28. Redis 6.0开启多线程后，是否会存在线程并发安全问题？</h2><p>从实现机制可以看出，Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程顺序执行。</p>
<p>所以我们不需要去考虑控制 Key、Lua、事务，LPUSH&#x2F;LPOP 等等的并发及线程安全问题。</p>
<h2 id="29-Redis-6-0-与-Memcached-多线程模型的对比"><a href="#29-Redis-6-0-与-Memcached-多线程模型的对比" class="headerlink" title="29. Redis 6.0 与 Memcached 多线程模型的对比"></a>29. Redis 6.0 与 Memcached 多线程模型的对比</h2><ul>
<li><p><strong>相同点：</strong>都采用了 Master 线程 -Worker 线程的模型。</p>
</li>
<li><p><strong>不同点</strong>：Memcached 执行主逻辑也是在 Worker 线程里，模型更加简单，实现了真正的线程隔离，符合我们对线程隔离的常规理解。</p>
<p>而 Redis 把处理逻辑交还给 Master 线程，虽然一定程度上增加了模型复杂度，但也解决了线程并发安全等问题。</p>
</li>
</ul>
<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><h2 id="30-Redis事务的概念"><a href="#30-Redis事务的概念" class="headerlink" title="30. Redis事务的概念"></a>30. Redis事务的概念</h2><p>Redis的事务并不是我们传统意义上理解的事务，我们都知道 单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis <strong>事务的执行并不是原子性的</strong>。</p>
<p>事务可以理解为一个<strong>打包的批量执行脚本</strong>，但<strong>批量指令并非原子化</strong>的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。</p>
<p><strong>总结：</strong></p>
<p> 　1.  Redis事务中如果有某一条命令执行失败，之前的命令不会回滚，其后的命令仍然会被继续执行。<strong>鉴于这个原因，所以说Redis的事务严格意义上来说是不具备原子性的</strong>。</p>
<p>　2.  Redis事务中所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</p>
<p>　3.  在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户端执行EXEC命令之后，那么该事务中的所有命令都会被服务器执行。</p>
<blockquote>
<p> 当使用Append-Only模式时，Redis会通过调用系统函数write将该事务内的所有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。Redis服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。此时，我们就要充分利用Redis工具包中提供的Redis-check-aof工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次重新启动Redis服务器了。</p>
</blockquote>
<h2 id="31-Redis事务的三个阶段"><a href="#31-Redis事务的三个阶段" class="headerlink" title="31. Redis事务的三个阶段"></a>31. Redis事务的三个阶段</h2><ol>
<li>multi 开启事务</li>
<li>大量指令入队</li>
<li>exec执行事务块内命令，<strong>截止此处一个事务已经结束。</strong></li>
<li>discard 取消事务</li>
<li>watch 监视一个或多个key，如果事务执行前key被改动，事务将打断。unwatch 取消监视。</li>
</ol>
<p>事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队.</p>
<h2 id="32-Redis事务相关命令"><a href="#32-Redis事务相关命令" class="headerlink" title="32. Redis事务相关命令"></a>32. Redis事务相关命令</h2><p>Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的</p>
<ul>
<li>WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。</li>
<li>MULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。</li>
<li>EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。<br>通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。</li>
<li>UNWATCH命令可以取消watch对所有key的监控。</li>
</ul>
<h2 id="33-Redis事务支持隔离性吗"><a href="#33-Redis事务支持隔离性吗" class="headerlink" title="33. Redis事务支持隔离性吗?"></a>33. Redis事务支持隔离性吗?</h2><p>Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，<strong>Redis 的事务是总是带有隔离性的</strong>。</p>
<h2 id="34-Redis为什么不支持事务回滚？"><a href="#34-Redis为什么不支持事务回滚？" class="headerlink" title="34. Redis为什么不支持事务回滚？"></a>34. Redis为什么不支持事务回滚？</h2><ul>
<li>Redis 命令只会因为错误的语法而失败，或是命令用在了错误类型的键上面，这些问题不能在入队时发现，这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中.</li>
<li>因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。</li>
</ul>
<h2 id="35-Redis事务其他实现"><a href="#35-Redis事务其他实现" class="headerlink" title="35. Redis事务其他实现"></a>35. Redis事务其他实现</h2><ul>
<li>基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行，<br>其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完。</li>
<li>基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐。</li>
</ul>
<h1 id="主从、哨兵、集群"><a href="#主从、哨兵、集群" class="headerlink" title="主从、哨兵、集群"></a>主从、哨兵、集群</h1><h2 id="36-Redis常见使用方式有哪些？"><a href="#36-Redis常见使用方式有哪些？" class="headerlink" title="36. Redis常见使用方式有哪些？"></a>36. Redis常见使用方式有哪些？</h2><p>Redis的几种常见使用方式包括：</p>
<ul>
<li>Redis单副本；</li>
<li>Redis多副本（主从）；</li>
<li>Redis Sentinel（哨兵）；</li>
<li>Redis Cluster；</li>
<li>Redis自研。</li>
</ul>
<p>使用场景：</p>
<p>如果数据量很少，主要是承载高并发高性能的场景，比如缓存一般就几个G的话，单机足够了。</p>
<p>主从模式：master 节点挂掉后，需要手动指定新的 master，可用性不高，基本不用。</p>
<p>哨兵模式：master 节点挂掉后，哨兵进程会主动选举新的 master，可用性高，但是每个节点存储的数据是一样的，浪费内存空间。数据量不是很多，集群规模不是很大，需要自动容错容灾的时候使用。</p>
<p>Redis cluster 主要是针对海量数据+高并发+高可用的场景，如果是海量数据，如果你的数据量很大，那么建议就用Redis cluster，所有master的容量总和就是Redis cluster可缓存的数据容量。</p>
<h2 id="37-介绍下Redis单副本"><a href="#37-介绍下Redis单副本" class="headerlink" title="37. 介绍下Redis单副本"></a>37. 介绍下Redis单副本</h2><p>Redis单副本，采用单个Redis节点部署架构，没有备用节点实时同步数据，不提供数据持久化和备份策略，适用于数据可靠性要求不高的纯缓存业务场景。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210829103307048.png" alt="image-20210829103307048"></p>
<p><strong>优点：</strong></p>
<ul>
<li>架构简单，部署方便；</li>
<li>高性价比：缓存使用时无需备用节点（单实例可用性可以用supervisor或crontab保证），当然为了满足业务的高可用性，也可以牺牲一个备用节点，但同时刻只有一个实例对外提供服务；</li>
<li>高性能。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>不保证数据的可靠性；</li>
<li>在缓存使用，进程重启后，数据丢失，即使有备用的节点解决高可用性，但是仍然不能解决缓存预热问题，因此不适用于数据可靠性要求高的业务；</li>
<li>高性能受限于单核CPU的处理能力（Redis是单线程机制），CPU为主要瓶颈，所以适合操作命令简单，排序、计算较少的场景。也可以考虑用Memcached替代。</li>
</ul>
<h2 id="38-介绍下Redis多副本（主从）"><a href="#38-介绍下Redis多副本（主从）" class="headerlink" title="38. 介绍下Redis多副本（主从）"></a>38. 介绍下Redis多副本（主从）</h2><p>Redis多副本，采用主从（replication）部署结构，相较于单副本而言最大的特点就是主从实例间数据实时同步，并且提供数据持久化和备份策略。主从实例部署在不同的物理服务器上，根据公司的基础环境配置，可以实现同时对外提供服务和读写分离策略。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210829103327631.png" alt="image-20210829103327631"></p>
<p><strong>优点：</strong></p>
<ul>
<li>高可靠性：一方面，采用双机主备架构，能够在主库出现故障时自动进行主备切换，从库提升为主库提供服务，保证服务平稳运行；另一方面，开启数据持久化功能和配置合理的备份策略，能有效的解决数据误操作和数据异常丢失的问题；</li>
<li>读写分离策略：从节点可以扩展主库节点的读能力，有效应对大并发量的读操作。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><p>故障恢复复杂，如果没有RedisHA系统（需要开发），当主库节点出现故障时，需要手动将一个从节点晋升为主节点，同时需要通知业务方变更配置，并且需要让其它从库节点去复制新主库节点，整个过程需要人为干预，比较繁琐；</p>
</li>
<li><p>主库的写能力受到单机的限制，可以考虑分片；</p>
</li>
<li><p>主库的存储能力受到单机的限制，可以考虑Pika；</p>
</li>
<li><p>原生复制的弊端在早期的版本中也会比较突出，如：Redis复制中断后，Slave会发起psync，此时如果同步不成功，则会进行全量同步，主库执行全量备份的同时可能会造成毫秒或秒级的卡顿；又由于COW机制，导致极端情况下的主库内存溢出，程序异常退出或宕机；主库节点生成备份文件导致服务器磁盘IO和CPU（压缩）资源消耗；发送数GB大小的备份文件导致服务器出口带宽暴增，阻塞请求，建议升级到最新版本。</p>
</li>
</ul>
<h2 id="39-介绍下Redis-Sentinel（哨兵）"><a href="#39-介绍下Redis-Sentinel（哨兵）" class="headerlink" title="39. 介绍下Redis Sentinel（哨兵）"></a>39. 介绍下Redis Sentinel（哨兵）</h2><blockquote>
<p>主从模式下，当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这种方式并不推荐，实际生产中，我们优先考虑哨兵模式。这种模式下，master 宕机，哨兵会自动选举 master 并将其他的 slave 指向新的 master。</p>
</blockquote>
<p>Redis Sentinel是社区版本推出的原生高可用解决方案，其部署架构主要包括两部分：Redis Sentinel集群和Redis数据集群。</p>
<p>其中Redis Sentinel集群是由若干Sentinel节点组成的分布式集群，可以实现故障发现、故障自动转移、配置中心和客户端通知。Redis Sentinel的节点数量要满足2n+1（n&gt;&#x3D;1）的奇数个。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210829103343110.png" alt="image-20210829103343110"></p>
<p><strong>优点：</strong></p>
<ul>
<li>Redis Sentinel集群部署简单；</li>
<li>能够解决Redis主从模式下的高可用切换问题；</li>
<li>很方便实现Redis数据节点的线形扩展，轻松突破Redis自身单线程瓶颈，可极大满足Redis大容量或高性能的业务需求；</li>
<li>可以实现一套Sentinel监控一组Redis数据节点或多组数据节点。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>部署相对Redis主从模式要复杂一些，原理理解更繁琐；</li>
<li>资源浪费，Redis数据节点中slave节点作为备份节点不提供服务；</li>
<li>Redis Sentinel主要是针对Redis数据节点中的主节点的高可用切换，对Redis的数据节点做失败判定分为主观下线和客观下线两种，对于Redis的从节点有对节点做主观下线操作，并不执行故障转移。</li>
<li>不能解决读写分离问题，实现起来相对复杂。</li>
</ul>
<h2 id="40-介绍下Redis-Cluster"><a href="#40-介绍下Redis-Cluster" class="headerlink" title="40. 介绍下Redis Cluster"></a>40. 介绍下Redis Cluster</h2><blockquote>
<p>Redis 的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下每台 Redis 服务器都存储相同的数据，很浪费内存，所以在 Redis3.0 上加入了 Cluster 集群模式，实现了 Redis 的分布式存储，对数据进行分片，也就是说每台 Redis 节点上存储不同的内容。</p>
</blockquote>
<p>Redis Cluster是社区版推出的Redis分布式集群解决方案，主要解决Redis分布式方面的需求，比如，当遇到单机内存，并发和流量等瓶颈的时候，Redis Cluster能起到很好的负载均衡的目的。</p>
<p>Redis Cluster集群节点最小配置6个节点以上（3主3从），其中主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。</p>
<p>Redis Cluster采用虚拟槽分区，所有的键根据哈希函数映射到0～16383个整数槽内，每个节点负责维护一部分槽以及槽所印映射的键值数据。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210829103444245.png" alt="image-20210829103444245"></p>
<p><strong>优点：</strong></p>
<ul>
<li>无中心架构；</li>
<li>数据按照slot存储分布在多个节点，节点间数据共享，可动态调整数据分布；</li>
<li>可扩展性：可线性扩展到1000多个节点，节点可动态添加或删除；</li>
<li>高可用性：部分节点不可用时，集群仍可用。通过增加Slave做standby数据副本，能够实现故障自动failover，节点之间通过gossip协议交换状态信息，用投票机制完成Slave到Master的角色提升；</li>
<li>降低运维成本，提高系统的扩展性和可用性。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>Client实现复杂，驱动要求实现Smart Client，缓存slots mapping信息并及时更新，提高了开发难度，客户端的不成熟影响业务的稳定性。目前仅JedisCluster相对成熟，异常处理部分还不完善，比如常见的“max redirect exception”。</li>
<li>节点会因为某些原因发生阻塞（阻塞时间大于clutser-node-timeout），被判断下线，这种failover是没有必要的。</li>
<li>数据通过异步复制，不保证数据的强一致性。</li>
<li>多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。</li>
<li>Slave在集群中充当“冷备”，不能缓解读压力，当然可以通过SDK的合理设计来提高Slave资源的利用率。</li>
<li>Key批量操作限制，如使用mset、mget目前只支持具有相同slot值的Key执行批量操作。对于映射为不同slot值的Key由于Keys不支持跨slot查询，所以执行mset、mget、sunion等操作支持不友好。</li>
<li>Key事务操作支持有限，只支持多key在同一节点上的事务操作，当多个Key分布于不同的节点上时无法使用事务功能。</li>
<li>Key作为数据分区的最小粒度，不能将一个很大的键值对象如hash、list等映射到不同的节点。</li>
<li>不支持多数据库空间，单机下的Redis可以支持到16个数据库，集群模式下只能使用1个数据库空间，即db 0。</li>
<li>复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。</li>
<li>避免产生hot-key，导致主库节点成为系统的短板。</li>
<li>避免产生big-key，导致网卡撑爆、慢查询等。</li>
<li>重试时间应该大于cluster-node-time时间。</li>
<li>Redis Cluster不建议使用pipeline和multi-keys操作，减少max redirect产生的场景。</li>
</ul>
<h2 id="41-介绍下Redis自研"><a href="#41-介绍下Redis自研" class="headerlink" title="41. 介绍下Redis自研"></a>41. 介绍下Redis自研</h2><p>Redis自研的高可用解决方案，主要体现在配置中心、故障探测和failover的处理机制上，通常需要根据企业业务的实际线上环境来定制化。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210829103426922.png" alt="image-20210829103426922"></p>
<p><strong>优点：</strong></p>
<ul>
<li>高可靠性、高可用性；</li>
<li>自主可控性高；</li>
<li>贴切业务实际需求，可缩性好，兼容性好。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>实现复杂，开发成本高；</li>
<li>需要建立配套的周边设施，如监控，域名服务，存储元数据信息的数据库等；</li>
<li>维护成本高。</li>
</ul>
<h2 id="42-Redis高可用方案具体怎么实施？"><a href="#42-Redis高可用方案具体怎么实施？" class="headerlink" title="42. Redis高可用方案具体怎么实施？"></a>42. Redis高可用方案具体怎么实施？</h2><p>使用官方推荐的哨兵(sentinel)机制就能实现，当主节点出现故障时，由Sentinel自动完成故障发现和转移，并通知应用方，实现高可用性。它有四个主要功能：</p>
<ul>
<li>集群监控，负责监控Redis master和slave进程是否正常工作。</li>
<li>消息通知，如果某个Redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员。</li>
<li>故障转移，如果master node挂掉了，会自动转移到slave node上。</li>
<li>配置中心，如果故障转移发生了，通知client客户端新的master地址。</li>
</ul>
<h2 id="43-了解主从复制的原理吗？"><a href="#43-了解主从复制的原理吗？" class="headerlink" title="43. 了解主从复制的原理吗？"></a>43. 了解主从复制的原理吗？</h2><p><strong>1、主从架构的核心原理</strong></p>
<p>当启动一个slave node的时候，它会发送一个PSYNC命令给master node</p>
<p>如果这是slave node重新连接master node，那么master node仅仅会复制给slave部分缺少的数据; 否则如果是slave node第一次连接master node，那么会触发一次full resynchronization</p>
<p>开始full resynchronization的时候，master会启动一个后台线程，开始生成一份RDB快照文件，同时还会将从客户端收到的所有写命令缓存在内存中。RDB文件生成完毕之后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中。然后master会将内存中缓存的写命令发送给slave，slave也会同步这些数据。</p>
<p>slave node如果跟master node有网络故障，断开了连接，会自动重连。master如果发现有多个slave node都来重新连接，仅仅会启动一个rdb save操作，用一份数据服务所有slave node。</p>
<p><strong>2、主从复制的断点续传</strong></p>
<p>从Redis 2.8开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份</p>
<p>master node会在内存中常见一个backlog，master和slave都会保存一个replica offset还有一个master id，offset就是保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制</p>
<p>但是如果没有找到对应的offset，那么就会执行一次resynchronization</p>
<p><strong>3、无磁盘化复制</strong></p>
<p>master在内存中直接创建rdb，然后发送给slave，不会在自己本地落地磁盘了</p>
<p>repl-diskless-sync repl-diskless-sync-delay，等待一定时长再开始复制，因为要等更多slave重新连接过来</p>
<p><strong>4、过期key处理</strong></p>
<p>slave不会过期key，只会等待master过期key。如果master过期了一个key，或者通过LRU淘汰了一个key，那么会模拟一条del命令发送给slave。</p>
<h2 id="44-由于主从延迟导致读取到过期数据怎么处理？"><a href="#44-由于主从延迟导致读取到过期数据怎么处理？" class="headerlink" title="44. 由于主从延迟导致读取到过期数据怎么处理？"></a>44. 由于主从延迟导致读取到过期数据怎么处理？</h2><ol>
<li>通过scan命令扫库：当Redis中的key被scan的时候，相当于访问了该key，同样也会做过期检测，充分发挥Redis惰性删除的策略。这个方法能大大降低了脏数据读取的概率，但缺点也比较明显，会造成一定的数据库压力，否则影响线上业务的效率。</li>
<li>Redis加入了一个新特性来解决主从不一致导致读取到过期数据问题，增加了key是否过期以及对主从库的判断，如果key已过期，当前访问的master则返回null；当前访问的是从库，且执行的是只读命令也返回null。</li>
</ol>
<h2 id="45-主从复制的过程中如果因为网络原因停止复制了会怎么样？"><a href="#45-主从复制的过程中如果因为网络原因停止复制了会怎么样？" class="headerlink" title="45. 主从复制的过程中如果因为网络原因停止复制了会怎么样？"></a>45. 主从复制的过程中如果因为网络原因停止复制了会怎么样？</h2><p>如果出现网络故障断开连接了，会自动重连的，从Redis 2.8开始，就支持主从复制的断点续传，可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。</p>
<p>master如果发现有多个slave node都来重新连接，仅仅会启动一个rdb save操作，用一份数据服务所有slave node。</p>
<p>master node会在内存中创建一个<code>backlog</code>，master和slave都会保存一个<code>replica offset</code>，还有一个<code>master id</code>，offset就是保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制。</p>
<p>但是如果没有找到对应的offset，那么就会执行一次<code>resynchronization</code>全量复制。</p>
<h2 id="46-Redis主从架构数据会丢失吗，为什么？"><a href="#46-Redis主从架构数据会丢失吗，为什么？" class="headerlink" title="46. Redis主从架构数据会丢失吗，为什么？"></a>46. Redis主从架构数据会丢失吗，为什么？</h2><p>有两种数据丢失的情况：</p>
<ol>
<li>异步复制导致的数据丢失：因为master -&gt; slave的复制是异步的，所以可能有部分数据还没复制到slave，master就宕机了，此时这些部分数据就丢失了。</li>
<li>脑裂导致的数据丢失：某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着，此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave切换成了master。这个时候，集群里就会有两个master，也就是所谓的脑裂。此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续写向旧master的数据可能也丢失了。因此旧master再次恢复的时候，会被作为一个slave挂到新的master上去，自己的数据会清空，重新从新的master复制数据。</li>
</ol>
<h2 id="47-如何解决主从架构数据丢失的问题？"><a href="#47-如何解决主从架构数据丢失的问题？" class="headerlink" title="47. 如何解决主从架构数据丢失的问题？"></a>47. 如何解决主从架构数据丢失的问题？</h2><p>数据丢失的问题是不可避免的，但是我们可以尽量减少。</p>
<p>在Redis的配置文件里设置参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min-slaves-to-write 1</span><br><span class="line">min-slaves-max-lag 10</span><br></pre></td></tr></table></figure>

<p><code>min-slaves-to-write</code>默认情况下是0，<code>min-slaves-max-lag</code>默认情况下是10。</p>
<p>上面的配置的意思是要求至少有1个slave，数据复制和同步的延迟不能超过10秒。如果说一旦所有的slave，数据复制和同步的延迟都超过了10秒钟，那么这个时候，master就不会再接收任何请求了。</p>
<p>减小<code>min-slaves-max-lag</code>参数的值，这样就可以避免在发生故障时大量的数据丢失，一旦发现延迟超过了该值就不会往master中写入数据。</p>
<p>那么对于client，我们可以采取降级措施，将数据暂时写入本地缓存和磁盘中，在一段时间后重新写入master来保证数据不丢失；也可以将数据写入kafka消息队列，隔一段时间去消费kafka中的数据。</p>
<h2 id="48-Redis哨兵是怎么工作的？"><a href="#48-Redis哨兵是怎么工作的？" class="headerlink" title="48. Redis哨兵是怎么工作的？"></a>48. Redis哨兵是怎么工作的？</h2><ol>
<li><p>每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他 Sentinel 实例发送一个 PING 命令。</p>
</li>
<li><p>如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被当前 Sentinel 标记为主观下线。</p>
</li>
<li><p>如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。</p>
</li>
<li><p>当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态， 则Master会被标记为客观下线 。</p>
</li>
<li><p>当Master被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次 （在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有Master，Slave发送 INFO 命令 ）。</p>
</li>
<li><p>若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就会变成主观下线。若 Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。</p>
</li>
<li><p>sentinel节点会与其他sentinel节点进行“沟通”，投票选举一个sentinel节点进行故障处理，在从节点中选取一个主节点，其他从节点挂载到新的主节点上自动复制新主节点的数据。</p>
</li>
</ol>
<h2 id="49-故障转移时会从剩下的slave选举一个新的master，被选举为master的标准是什么？"><a href="#49-故障转移时会从剩下的slave选举一个新的master，被选举为master的标准是什么？" class="headerlink" title="49. 故障转移时会从剩下的slave选举一个新的master，被选举为master的标准是什么？"></a>49. 故障转移时会从剩下的slave选举一个新的master，被选举为master的标准是什么？</h2><p>如果一个master被认为odown了，而且majority哨兵都允许了主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个slave来，会考虑slave的一些信息。</p>
<ul>
<li>跟master断开连接的时长。<br>如果一个slave跟master断开连接已经超过了down-after-milliseconds的10倍，外加master宕机的时长，那么slave就被认为不适合选举为master.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">( down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state</span><br></pre></td></tr></table></figure>

<ul>
<li><p>slave优先级。<br>按照slave优先级进行排序，slave priority越低，优先级就越高</p>
</li>
<li><p>复制offset。<br>如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高</p>
</li>
<li><p>run id<br>如果上面两个条件都相同，那么选择一个run id比较小的那个slave。</p>
</li>
</ul>
<h2 id="50-同步配置的时候其他哨兵根据什么更新自己的配置呢？"><a href="#50-同步配置的时候其他哨兵根据什么更新自己的配置呢？" class="headerlink" title="50. 同步配置的时候其他哨兵根据什么更新自己的配置呢？"></a>50. 同步配置的时候其他哨兵根据什么更新自己的配置呢？</h2><p>执行切换的那个哨兵，会从要切换到的新master（salve-&gt;master）那里得到一个configuration epoch，这就是一个version号，每次切换的version号都必须是唯一的。</p>
<p>如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待failover-timeout时间，然后接替继续执行切换，此时会重新获取一个新的configuration epoch 作为新的version号。</p>
<p>这个version号就很重要了，因为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的，其他的哨兵都是根据版本号的大小来更新自己的master配置的。</p>
<h2 id="51-为什么Redis哨兵集群只有2个节点无法正常工作？"><a href="#51-为什么Redis哨兵集群只有2个节点无法正常工作？" class="headerlink" title="51. 为什么Redis哨兵集群只有2个节点无法正常工作？"></a>51. 为什么Redis哨兵集群只有2个节点无法正常工作？</h2><p>哨兵集群必须部署2个以上节点。</p>
<p>如果两个哨兵实例，即两个Redis实例，一主一从的模式。</p>
<p>则Redis的配置quorum&#x3D;1，表示一个哨兵认为master宕机即可认为master已宕机。</p>
<p>但是如果是机器1宕机了，那哨兵1和master都宕机了，虽然哨兵2知道master宕机了，但是这个时候，需要majority，也就是大多数哨兵都是运行的，2个哨兵的majority就是2（2的majority&#x3D;2，3的majority&#x3D;2，5的majority&#x3D;3，4的majority&#x3D;2），2个哨兵都运行着，就可以允许执行故障转移。</p>
<p>但此时哨兵1没了就只有1个哨兵了了，此时就没有majority来允许执行故障转移，所以故障转移不会执行。</p>
<h2 id="52-Redis-cluster中是如何实现数据分布的？这种方式有什么优点？"><a href="#52-Redis-cluster中是如何实现数据分布的？这种方式有什么优点？" class="headerlink" title="52. Redis cluster中是如何实现数据分布的？这种方式有什么优点？"></a>52. Redis cluster中是如何实现数据分布的？这种方式有什么优点？</h2><p>Redis cluster有固定的16384个hash slot（哈希槽），对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot。</p>
<p>Redis cluster中每个master都会持有部分slot（槽），比如有3个master，那么可能每个master持有5000多个hash slot。</p>
<p>hash slot让node的增加和移除很简单，增加一个master，就将其他master的hash slot移动部分过去，减少一个master，就将它的hash slot移动到其他master上去。每次增加或减少master节点都是对16384取模，而不是根据master数量，这样原本在老的master上的数据不会因master的新增或减少而找不到。并且增加或减少master时Redis cluster移动hash slot的成本是非常低的。</p>
<h2 id="53-Redis-cluster节点间通信是什么机制？"><a href="#53-Redis-cluster节点间通信是什么机制？" class="headerlink" title="53. Redis cluster节点间通信是什么机制？"></a>53. Redis cluster节点间通信是什么机制？</h2><p>Redis cluster节点间采取gossip协议进行通信，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更之后U不断地i将元数据发送给其他节点让其他节点进行数据变更。</p>
<blockquote>
<p>节点互相之间不断通信，保持整个集群所有节点的数据是完整的。<br>主要交换故障信息、节点的增加和移除、hash slot信息等。</p>
</blockquote>
<p>这种机制的好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力;</p>
<p>缺点，元数据更新有延时，可能导致集群的一些操作会有一些滞后。</p>
<h1 id="分布式问题"><a href="#分布式问题" class="headerlink" title="分布式问题"></a>分布式问题</h1><h2 id="54-什么是分布式锁？为什么用分布式锁？"><a href="#54-什么是分布式锁？为什么用分布式锁？" class="headerlink" title="54. 什么是分布式锁？为什么用分布式锁？"></a>54. 什么是分布式锁？为什么用分布式锁？</h2><p>锁在程序中的作用就是同步工具，保证共享资源在同一时刻只能被一个线程访问，Java中的锁我们都很熟悉了，像synchronized 、Lock都是我们经常使用的，但是Java的锁只能保证单机的时候有效，分布式集群环境就无能为力了，这个时候我们就需要用到分布式锁。</p>
<p>分布式锁，顾名思义，就是分布式项目开发中用到的锁，可以用来控制分布式系统之间同步访问共享资源。</p>
<p>思路是：在整个系统提供一个<strong>全局、唯一</strong>的获取锁的“东西”，然后每个系统在需要加锁时，都去问这个“东西”拿到一把锁，这样不同的系统拿到的就可以认为是同一把锁。至于这个“东西”，可以是Redis、Zookeeper，也可以是数据库。</p>
<p>一般来说，分布式锁需要满足的特性有这么几点：</p>
<p>1、互斥性：在任何时刻，对于同一条数据，只有一台应用可以获取到分布式锁；</p>
<p>2、高可用性：在分布式场景下，一小部分服务器宕机不影响正常使用，这种情况就需要将提供分布式锁的服务以集群的方式部署；</p>
<p>3、防止锁超时：如果客户端没有主动释放锁，服务器会在一段时间之后自动释放锁，防止客户端宕机或者网络不可达时产生死锁；</p>
<p>4、独占性：加锁解锁必须由同一台服务器进行，也就是锁的持有者才可以释放锁，不能出现你加的锁，别人给你解锁了。</p>
<h2 id="55-常见的分布式锁有哪些解决方案？"><a href="#55-常见的分布式锁有哪些解决方案？" class="headerlink" title="55. 常见的分布式锁有哪些解决方案？"></a>55. 常见的分布式锁有哪些解决方案？</h2><p>实现分布式锁目前有三种流行方案，即基于关系型数据库、Redis、ZooKeeper 的方案</p>
<p> 1、基于关系型数据库，如MySQL<br>基于关系型数据库实现分布式锁，是依赖数据库的唯一性来实现资源锁定，比如主键和唯一索引等。</p>
<p>缺点：</p>
<ul>
<li>这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。</li>
<li>这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。</li>
<li>这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。</li>
<li>这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。</li>
</ul>
<p>2、基于Redis实现</p>
<p>优点：</p>
<p>Redis 锁实现简单，理解逻辑简单，性能好，可以支撑高并发的获取、释放锁操作。</p>
<p>缺点：</p>
<ul>
<li>Redis 容易单点故障，集群部署，并不是强一致性的，锁的不够健壮；</li>
<li>key 的过期时间设置多少不明确，只能根据实际情况调整；</li>
<li>需要自己不断去尝试获取锁，比较消耗性能。</li>
</ul>
<p>3、基于zookeeper</p>
<p>优点：</p>
<p>zookeeper 天生设计定位就是分布式协调，强一致性，锁很健壮。如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。</p>
<p>缺点：</p>
<p>在高请求高并发下，系统疯狂的加锁释放锁，最后 zk 承受不住这么大的压力可能会存在宕机的风险。</p>
<h2 id="56-Redis实现分布式锁"><a href="#56-Redis实现分布式锁" class="headerlink" title="56. Redis实现分布式锁"></a>56. Redis实现分布式锁</h2><h3 id="分布式锁的三个核心要素"><a href="#分布式锁的三个核心要素" class="headerlink" title="分布式锁的三个核心要素"></a>分布式锁的三个核心要素</h3><p>1、加锁</p>
<p>使用setnx来加锁。key是锁的唯一标识，按业务来决定命名，value这里设置为test。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setx key test</span><br></pre></td></tr></table></figure>

<p>当一个线程执行setnx返回1，说明key原本不存在，该线程成功得到了锁；当一个线程执行setnx返回0，说明key已经存在，该线程抢锁失败；</p>
<p>2、解锁</p>
<p>有加锁就得有解锁。当得到的锁的线程执行完任务，需要释放锁，以便其他线程可以进入。释放锁的最简单方式就是执行del指令。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">del key</span><br></pre></td></tr></table></figure>

<p>释放锁之后，其他线程就可以继续执行setnx命令来获得锁。</p>
<p>3、锁超时</p>
<p>锁超时知道的是：如果一个得到锁的线程在执行任务的过程中挂掉，来不及显式地释放锁，这块资源将会永远被锁住，别的线程北向进来。</p>
<p>所以，setnx的key必须设置一个超时时间，以保证即使没有被显式释放，这把锁也要在一段时间后自动释放。setnx不支持超时参数，所以需要额外指令，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">expire key 30</span><br></pre></td></tr></table></figure>

<h3 id="上述分布式锁存在的问题"><a href="#上述分布式锁存在的问题" class="headerlink" title="上述分布式锁存在的问题"></a>上述分布式锁存在的问题</h3><p><strong>通过上述<code>setnx</code> 、<code>del</code>和<code>expire</code>实现的分布式锁还是存在着一些问题。</strong></p>
<p>1、SETNX 和 EXPIRE 非原子性</p>
<p>假设一个场景中，某一个线程刚执行setnx，成功得到了锁。此时setnx刚执行成功，还未来得及执行expire命令，节点就挂掉了。此时这把锁就没有设置过期时间，别的线程就再也无法获得该锁。</p>
<p><strong>解决措施:</strong></p>
<p>由于<code>setnx</code>指令本身是不支持传入超时时间的，而在Redis2.6.12版本上为<code>set</code>指令增加了可选参数, 用法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET key value [EX seconds][PX milliseconds] [NX|XX]</span><br></pre></td></tr></table></figure>

<ul>
<li>EX second: 设置键的过期时间为second秒；</li>
<li>PX millisecond：设置键的过期时间为millisecond毫秒；</li>
<li>NX：只在键不存在时，才对键进行设置操作；</li>
<li>XX：只在键已经存在时，才对键进行设置操作；</li>
<li>SET操作完成时，返回OK，否则返回nil。</li>
</ul>
<p>2、锁误解除</p>
<p>如果线程 A 成功获取到了锁，并且设置了过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁；随后 A 执行完成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，线程 A 实际释放的线程 B 加的锁。</p>
<p><strong>解决办法：</strong></p>
<p>在del释放锁之前加一个判断，验证当前的锁是不是自己加的锁。</p>
<p>具体在加锁的时候把当前线程的id当做value，可生成一个 UUID 标识当前线程，在删除之前验证key对应的value是不是自己线程的id。</p>
<p>还可以使用 lua 脚本做验证标识和解锁操作。</p>
<p>3、超时解锁导致并发</p>
<p>如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁，线程 A 和线程 B 并发执行。</p>
<p>A、B 两个线程发生并发显然是不被允许的，一般有两种方式解决该问题：</p>
<ul>
<li>将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。</li>
<li>为获取锁的线程增加守护线程，为将要过期但未释放的锁增加有效时间。</li>
</ul>
<p>4、不可重入</p>
<p>当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的。如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败。Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时释放锁。</p>
<p>5、无法等待锁释放</p>
<p>上述命令执行都是立即返回的，如果客户端可以等待锁释放就无法使用。</p>
<ul>
<li>可以通过客户端轮询的方式解决该问题，当未获取到锁时，等待一段时间重新获取锁，直到成功获取锁或等待超时。这种方式比较消耗服务器资源，当并发量比较大时，会影响服务器的效率。</li>
<li>另一种方式是使用 Redis 的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。</li>
</ul>
<p>具体实现参考：<a target="_blank" rel="noopener" href="https://xiaomi-info.github.io/2019/12/17/Redis-distributed-lock/">https://xiaomi-info.github.io/2019/12/17/Redis-distributed-lock/</a></p>
<h2 id="57-了解RedLock吗？"><a href="#57-了解RedLock吗？" class="headerlink" title="57. 了解RedLock吗？"></a>57. 了解RedLock吗？</h2><p>Redlock是一种算法，Redlock也就是 Redis Distributed Lock，可用实现多节点Redis的分布式锁。</p>
<p>RedLock官方推荐，Redisson完成了对Redlock算法封装。</p>
<p>此种方式具有以下特性：</p>
<ul>
<li>互斥访问：即永远只有一个 client 能拿到锁</li>
<li>避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使锁定资源的服务崩溃或者分区，仍然能释放锁。</li>
<li>容错性：只要大部分 Redis 节点存活（一半以上），就可以正常提供服务</li>
</ul>
<h2 id="58-RedLock的原理"><a href="#58-RedLock的原理" class="headerlink" title="58. RedLock的原理"></a>58. RedLock的原理</h2><p>假设有5个完全独立的Redis主服务器</p>
<ol>
<li><p>获取当前时间戳</p>
</li>
<li><p>client尝试按照顺序使用相同的key,value获取所有Redis服务的锁，在获取锁的过程中的获取时间比锁过期时间短很多，这是为了不要过长时间等待已经关闭的Redis服务。并且试着获取下一个Redis实例。</p>
</li>
</ol>
<p>  比如：TTL为5s,设置获取锁最多用1s，所以如果一秒内无法获取锁，就放弃获取这个锁，从而尝试获取下个锁</p>
<ol start="3">
<li><p>client通过获取所有能获取的锁后的时间减去第一步的时间，这个时间差要小于TTL时间并且至少有3个Redis实例成功获取锁，才算真正的获取锁成功</p>
</li>
<li><p>如果成功获取锁，则锁的真正有效时间是 TTL减去第三步的时间差 的时间；比如：TTL 是5s,获取所有锁用了2s,则真正锁有效时间为3s(其实应该再减去时钟漂移);</p>
</li>
<li><p>如果客户端由于某些原因获取锁失败，便会开始解锁所有Redis实例；因为可能已经获取了小于3个锁，必须释放，否则影响其他client获取锁</p>
</li>
</ol>
<p>算法示意图如下：</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210829131128229.png" alt="image-20210829131128229"></p>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><h2 id="59-Redis如何做内存优化？"><a href="#59-Redis如何做内存优化？" class="headerlink" title="59. Redis如何做内存优化？"></a>59. Redis如何做内存优化？</h2><ul>
<li><p><strong>控制key的数量</strong>。当使用Redis存储大量数据时，通常会存在大量键，过多的键同样会消耗大量内存。Redis本质是一个数据结构服务器，它为我们提供多种数据结构，如hash，list，set，zset 等结构。使用Redis时不要进入一个误区，大量使用get&#x2F;set这样的API，把Redis当成Memcached使用。对于存储相同的数据内容利用Redis的数据结构降低外层键的数量，也可以节省大量内存。</p>
</li>
<li><p><strong>缩减键值对象</strong>，降低Redis内存使用最直接的方式就是缩减键（key）和值（value）的长度。</p>
<ul>
<li>key长度：如在设计键时，在完整描述业务情况下，键值越短越好。</li>
<li>value长度：值对象缩减比较复杂，常见需求是把业务对象序列化成二进制数组放入Redis。首先应该在业务上精简业务对象，去掉不必要的属性避免存储无效数据。其次在序列化工具选择上，应该选择更高效的序列化工具来降低字节数组大小。</li>
</ul>
</li>
<li><p><strong>编码优化</strong>。Redis对外提供了string,list,hash,set,zet等类型，但是Redis内部针对不同类型存在编码的概念，所谓编码就是具体使用哪种底层数据结构来实现。编码不同将直接影响数据的内存占用和读写效率。可参考文章：<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1162213">https://cloud.tencent.com/developer/article/1162213</a></p>
</li>
</ul>
<h2 id="60-如果现在有个读超高并发的系统，用Redis来抗住大部分读请求，你会怎么设计？"><a href="#60-如果现在有个读超高并发的系统，用Redis来抗住大部分读请求，你会怎么设计？" class="headerlink" title="60. 如果现在有个读超高并发的系统，用Redis来抗住大部分读请求，你会怎么设计？"></a>60. 如果现在有个读超高并发的系统，用Redis来抗住大部分读请求，你会怎么设计？</h2><p>如果是读高并发的话，先看读并发的数量级是多少，因为Redis单机的读QPS在万级，每秒几万没问题，使用一主多从+哨兵集群的缓存架构来承载每秒10W+的读并发，主从复制，读写分离。</p>
<p>使用哨兵集群主要是提高缓存架构的可用性，解决单点故障问题。主库负责写，多个从库负责读，支持水平扩容，根据读请求的QPS来决定加多少个Redis从实例。如果读并发继续增加的话，只需要增加Redis从实例就行了。</p>
<p>如果需要缓存1T+的数据，选择Redis cluster模式，每个主节点存一部分数据，假设一个master存32G，那只需要n*32G&gt;&#x3D;1T，n个这样的master节点就可以支持1T+的海量数据的存储了。</p>
<blockquote>
<p>Redis单主的瓶颈不在于读写的并发，而在于内存容量，即使是一主多从也是不能解决该问题，因为一主多从架构下，多个slave的数据和master的完全一样。假如master是10G那slave也只能存10G数据。所以数据量受单主的影响。<br>而这个时候又需要缓存海量数据，那就必须得有多主了，并且多个主保存的数据还不能一样。Redis官方给出的 Redis cluster 模式完美的解决了这个问题。</p>
</blockquote>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/02/Redis/" data-id="cl3wpiohb000po0r42r7w0zg9" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-MySQL索引连环18问！" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/02/MySQL%E7%B4%A2%E5%BC%95%E8%BF%9E%E7%8E%AF18%E9%97%AE%EF%BC%81/" class="article-date">
  <time class="dt-published" datetime="2022-06-02T07:37:48.648Z" itemprop="datePublished">2022-06-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-索引是什么？"><a href="#1-索引是什么？" class="headerlink" title="1. 索引是什么？"></a>1. 索引是什么？</h2><p>索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。</p>
<p>索引是一种数据结构。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。更通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。而且索引是一个文件，它是要占据物理空间的。</p>
<p>MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。比如我们在查字典的时候，前面都有检索的拼音和偏旁、笔画等，然后找到对应字典页码，这样然后就打开字典的页数就可以知道我们要搜索的某一个key的全部值的信息了。</p>
<h2 id="2-索引有哪些优缺点？"><a href="#2-索引有哪些优缺点？" class="headerlink" title="2. 索引有哪些优缺点？"></a>2. 索引有哪些优缺点？</h2><p><strong>索引的优点</strong></p>
<ul>
<li>可以大大加快数据的检索速度，这也是创建索引的最主要的原因。</li>
<li>通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。</li>
</ul>
<p><strong>索引的缺点</strong></p>
<ul>
<li>时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增&#x2F;改&#x2F;删的执行效率；</li>
<li>空间方面：索引需要占物理空间。</li>
</ul>
<h2 id="3-MySQL有哪几种索引类型？"><a href="#3-MySQL有哪几种索引类型？" class="headerlink" title="3. MySQL有哪几种索引类型？"></a>3. MySQL有哪几种索引类型？</h2><p>1、从存储结构上来划分：BTree索引（B-Tree或B+Tree索引），Hash索引，full-index全文索引，R-Tree索引。这里所描述的是索引存储时保存的形式，</p>
<p>2、从应用层次来分：普通索引，唯一索引，复合索引。</p>
<ul>
<li><p>普通索引：即一个索引只包含单个列，一个表可以有多个单列索引</p>
</li>
<li><p>唯一索引：索引列的值必须唯一，但允许有空值</p>
</li>
<li><p>复合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并</p>
</li>
<li><p>聚簇索引(聚集索引)：并不是一种单独的索引类型，而是一种数据存储方式。具体细节取决于不同的实现，InnoDB的聚簇索引其实就是在同一个结构中保存了B-Tree索引(技术上来说是B+Tree)和数据行。</p>
</li>
<li><p>非聚簇索引： 不是聚簇索引，就是非聚簇索引</p>
</li>
</ul>
<p>3、根据中数据的物理顺序与键值的逻辑（索引）顺序关系： 聚集索引，非聚集索引。</p>
<h2 id="4-说一说索引的底层实现？"><a href="#4-说一说索引的底层实现？" class="headerlink" title="4. 说一说索引的底层实现？"></a>4. 说一说索引的底层实现？</h2><p><strong>Hash索引</strong> </p>
<p>基于哈希表实现，只有精确匹配索引所有列的查询才有效，对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码（hash code），并且Hash索引将所有的哈希码存储在索引中，同时在索引表中保存指向每个数据行的指针。</p>
<blockquote>
<p>图片来源：<a target="_blank" rel="noopener" href="https://www.javazhiyin.com/40232.html">https://www.javazhiyin.com/40232.html</a></p>
</blockquote>
<p><img src="http://blog-img.coolsen.cn/img/image-20210411215012443.png"></p>
<p><strong>B-Tree索引</strong>（MySQL使用B+Tree）</p>
<p>B-Tree能加快数据的访问速度，因为存储引擎不再需要进行全表扫描来获取数据，数据分布在各个节点之中。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210411215023820.png"></p>
<p><strong>B+Tree索引</strong></p>
<p>是B-Tree的改进版本，同时也是数据库索引索引所采用的存储结构。数据都在叶子节点上，并且增加了顺序访问指针，每个叶子节点都指向相邻的叶子节点的地址。相比B-Tree来说，进行范围查找时只需要查找两个节点，进行遍历即可。而B-Tree需要获取所有节点，相比之下B+Tree效率更高。</p>
<p>B+tree性质：</p>
<ul>
<li><p>n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。</p>
</li>
<li><p>所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。</p>
</li>
<li><p>所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。</p>
</li>
<li><p>B+ 树中，数据对象的插入和删除仅在叶节点上进行。</p>
</li>
<li><p>B+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。</p>
</li>
</ul>
<p><img src="http://blog-img.coolsen.cn/img/image-20210411215044332.png"></p>
<h2 id="5-为什么索引结构默认使用B-Tree，而不是B-Tree，Hash，二叉树，红黑树？"><a href="#5-为什么索引结构默认使用B-Tree，而不是B-Tree，Hash，二叉树，红黑树？" class="headerlink" title="5. 为什么索引结构默认使用B+Tree，而不是B-Tree，Hash，二叉树，红黑树？"></a>5. 为什么索引结构默认使用B+Tree，而不是B-Tree，Hash，二叉树，红黑树？</h2><p>B-tree： 从两个方面来回答</p>
<ul>
<li><p>B+树的磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B(B-)树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对<code>IO读写次数就降低</code>了。</p>
</li>
<li><p>由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在<code>区间查询</code>的情况，所以通常B+树用于数据库索引。</p>
</li>
</ul>
<p>Hash： </p>
<ul>
<li>虽然可以快速定位，但是没有顺序，IO复杂度高；</li>
</ul>
<ul>
<li><p>基于Hash表实现，只有Memory存储引擎显式支持哈希索引 ；</p>
</li>
<li><p>适合<strong>等值查询</strong>，如&#x3D;、in()、&lt;&#x3D;&gt;，不支持范围查询 ；</p>
</li>
<li><p>因为不是按照索引值顺序存储的，就不能像B+Tree索引一样利用索引完成<a href="">排序</a> ；</p>
</li>
<li><p>Hash索引在查询等值时非常快 ；</p>
</li>
<li><p>因为Hash索引始终索引的<strong>所有列的全部内容</strong>，所以不支持部分索引列的匹配查找 ；</p>
</li>
<li><p>如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题 。</p>
</li>
</ul>
<p>二叉树： 树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度），并且IO代价高。</p>
<p>红黑树： 树的高度随着数据量增加而增加，IO代价高。</p>
<h2 id="6-讲一讲聚簇索引与非聚簇索引？"><a href="#6-讲一讲聚簇索引与非聚簇索引？" class="headerlink" title="6. 讲一讲聚簇索引与非聚簇索引？"></a>6. 讲一讲聚簇索引与非聚簇索引？</h2><p>在 InnoDB 里，索引B+ Tree的叶子节点存储了整行数据的是主键索引，也被称之为聚簇索引，即将数据存储与索引放到了一块，找到索引也就找到了数据。</p>
<p>而索引B+ Tree的叶子节点存储了主键的值的是非主键索引，也被称之为非聚簇索引、二级索引。</p>
<p>聚簇索引与非聚簇索引的区别：</p>
<ul>
<li><p>非聚集索引与聚集索引的区别在于非聚集索引的叶子节点不存储表中的数据，而是存储该列对应的主键（行号） </p>
</li>
<li><p>对于InnoDB来说，想要查找数据我们还需要根据主键再去聚集索引中进行查找，这个再根据聚集索引查找数据的过程，我们称为<strong>回表</strong>。第一次索引一般是顺序IO，回表的操作属于随机IO。需要回表的次数越多，即随机IO次数越多，我们就越倾向于使用全表扫描 。</p>
</li>
<li><p>通常情况下， 主键索引（聚簇索引）查询只会查一次，而非主键索引（非聚簇索引）需要回表查询多次。当然，如果是覆盖索引的话，查一次即可 </p>
</li>
<li><p>注意：MyISAM无论主键索引还是二级索引都是非聚簇索引，而InnoDB的主键索引是聚簇索引，二级索引是非聚簇索引。我们自己建的索引基本都是非聚簇索引。</p>
</li>
</ul>
<h2 id="7-非聚簇索引一定会回表查询吗？"><a href="#7-非聚簇索引一定会回表查询吗？" class="headerlink" title="7. 非聚簇索引一定会回表查询吗？"></a>7. 非聚簇索引一定会回表查询吗？</h2><p>不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。一个索引包含（覆盖）所有需要查询字段的值，被称之为”覆盖索引”。</p>
<p>举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行<code>select score from student where score &gt; 90</code>的查询时，在索引的叶子节点上，已经包含了score 信息，不会再次进行回表查询。</p>
<h2 id="8-联合索引是什么？为什么需要注意联合索引中的顺序？"><a href="#8-联合索引是什么？为什么需要注意联合索引中的顺序？" class="headerlink" title="8. 联合索引是什么？为什么需要注意联合索引中的顺序？"></a>8. 联合索引是什么？为什么需要注意联合索引中的顺序？</h2><p>MySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。</p>
<p>具体原因为:</p>
<p>MySQL使用索引时需要索引有序，假设现在建立了”name，age，school”的联合索引，那么索引的排序为: 先按照name排序，如果name相同，则按照age排序，如果age的值也相等，则按照school进行排序。</p>
<p>当进行查询时，此时索引仅仅按照name严格有序，因此必须首先使用name字段进行等值查询，之后对于匹配到的列而言，其按照age字段严格有序，此时可以使用age字段用做索引查找，以此类推。因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。</p>
<h2 id="9-讲一讲MySQL的最左前缀原则"><a href="#9-讲一讲MySQL的最左前缀原则" class="headerlink" title="9. 讲一讲MySQL的最左前缀原则?"></a>9. 讲一讲MySQL的最左前缀原则?</h2><p>最左前缀原则就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。<br>mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a &#x3D; 1 and b &#x3D; 2 and c &gt; 3 and d &#x3D; 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</p>
<p>&#x3D;和in可以乱序，比如a &#x3D; 1 and b &#x3D; 2 and c &#x3D; 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。</p>
<h2 id="10-讲一讲前缀索引？"><a href="#10-讲一讲前缀索引？" class="headerlink" title="10. 讲一讲前缀索引？"></a>10. 讲一讲前缀索引？</h2><p>因为可能我们索引的字段非常长，这既占内存空间，也不利于维护。所以我们就想，如果只把很长字段的前面的公共部分作为一个索引，就会产生超级加倍的效果。但是，我们需要注意，order by不支持前缀索引 。</p>
<p> 流程是： </p>
<p> 先计算完整列的选择性 :<code> select count(distinct col_1)/count(1) from table_1 </code></p>
<p> 再计算不同前缀长度的选择性 :<code>select count(distinct left(col_1,4))/count(1) from table_1 </code></p>
<p> 找到最优长度之后，创建前缀索引 :<code> create index idx_front on table_1 (col_1(4))</code></p>
<h2 id="11-了解索引下推吗？"><a href="#11-了解索引下推吗？" class="headerlink" title="11. 了解索引下推吗？"></a>11. 了解索引下推吗？</h2><p>MySQL 5.6引入了索引下推优化。默认开启，使用SET optimizer_switch &#x3D; ‘index_condition_pushdown&#x3D;off’;可以将其关闭。 </p>
<ul>
<li><p>有了索引下推优化，可以在<strong>减少回表次数</strong> </p>
</li>
<li><p>在InnoDB中只针对二级索引有效</p>
</li>
</ul>
<p>官方文档中给的例子和解释如下：</p>
<p>在 people_table中有一个二级索引(zipcode，lastname，address)，查询是SELECT * FROM people WHERE zipcode&#x3D;’95054′ AND lastname LIKE ‘%etrunia%’ AND address LIKE ‘%Main Street%’; </p>
<ul>
<li><p>如果没有使用索引下推技术，则MySQL会通过zipcode&#x3D;’95054’从存储引擎中查询对应的数据，返回到MySQL服务端，然后MySQL服务端基于lastname LIKE ‘%etrunia%’ and address LIKE ‘%Main Street%’来判断数据是否符合条件 </p>
</li>
<li><p>如果使用了索引下推技术，则MYSQL首先会返回符合zipcode&#x3D;’95054’的索引，然后根据lastname LIKE ‘%etrunia%’ and address LIKE ‘%Main Street%’来判断索引是否符合条件。如果符合条件，则根据该索引来定位对应的数据，如果不符合，则直接reject掉。</p>
</li>
</ul>
<h2 id="12-怎么查看MySQL语句有没有用到索引？"><a href="#12-怎么查看MySQL语句有没有用到索引？" class="headerlink" title="12. 怎么查看MySQL语句有没有用到索引？"></a>12. 怎么查看MySQL语句有没有用到索引？</h2><p>通过explain，如以下例子：</p>
<p><code>EXPLAIN SELECT * FROM employees.titles WHERE emp_no=&#39;10001&#39; AND title=&#39;Senior Engineer&#39; AND from_date=&#39;1986-06-26&#39;;</code></p>
<table>
<thead>
<tr>
<th>id</th>
<th>select_type</th>
<th>table</th>
<th>partitions</th>
<th>type</th>
<th>possible_keys</th>
<th>key</th>
<th>key_len</th>
<th>ref</th>
<th>filtered</th>
<th>rows</th>
<th>Extra</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>SIMPLE</td>
<td>titles</td>
<td>null</td>
<td>const</td>
<td>PRIMARY</td>
<td>PRIMARY</td>
<td>59</td>
<td>const,const,const</td>
<td>10</td>
<td>1</td>
<td></td>
</tr>
</tbody></table>
<ul>
<li><p>id：在⼀个⼤的查询语句中每个<strong>SELECT</strong>关键字都对应⼀个唯⼀的id ，如explain select * from s1 where id &#x3D; (select id from s1 where name &#x3D; ‘egon1’);第一个select的id是1，第二个select的id是2。有时候会出现两个select，但是id却都是1，这是因为优化器把子查询变成了连接查询 。</p>
</li>
<li><p>select_type：select关键字对应的那个查询的类型，如SIMPLE,PRIMARY,SUBQUERY,DEPENDENT,SNION 。</p>
</li>
<li><p>table：每个查询对应的表名 。</p>
</li>
<li><p>type：<code>type</code> 字段比较重要, 它提供了判断查询是否高效的重要依据依据. 通过 <code>type</code> 字段, 我们判断此次查询是 <code>全表扫描</code> 还是 <code>索引扫描</code> 等。如const(主键索引或者唯一二级索引进行等值匹配的情况下),ref(普通的⼆级索引列与常量进⾏等值匹配),index(扫描全表索引的覆盖索引) 。</p>
<p>通常来说, 不同的 type 类型的性能关系如下:<br><code>ALL &lt; index &lt; range ~ index_merge &lt; ref &lt; eq_ref &lt; const &lt; system</code><br><code>ALL</code> 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的.<br>而 <code>index</code> 类型的查询虽然不是全表扫描, 但是它扫描了所有的索引, 因此比 ALL 类型的稍快.</p>
</li>
<li><p>possible_key：查询中可能用到的索引*(可以把用不到的删掉，降低优化器的优化时间)* 。</p>
</li>
<li><p>key：此字段是 MySQL 在当前查询时所真正使用到的索引。</p>
</li>
<li><p>filtered：查询器预测满足下一次查询条件的百分比 。</p>
</li>
<li><p>rows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数.<br>这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好。</p>
</li>
<li><p>extra：表示额外信息，如Using where,Start temporary,End temporary,Using temporary等。</p>
</li>
</ul>
<h2 id="13-为什么官方建议使用自增长主键作为索引？"><a href="#13-为什么官方建议使用自增长主键作为索引？" class="headerlink" title="13. 为什么官方建议使用自增长主键作为索引？"></a>13. 为什么官方建议使用自增长主键作为索引？</h2><p>结合B+Tree的特点，自增主键是连续的，在插入过程中尽量减少页分裂，即使要进行页分裂，也只会分裂很少一部分。并且能减少数据的移动，每次插入都是插入到最后。总之就是减少分裂和移动的频率。</p>
<p>插入连续的数据：</p>
<blockquote>
<p>图片来自：<a target="_blank" rel="noopener" href="https://www.javazhiyin.com/40232.html">https://www.javazhiyin.com/40232.html</a></p>
</blockquote>
<p><img src="http://blog-img.coolsen.cn/img/java10-1562726251.gif"></p>
<p>插入非连续的数据：</p>
<p><img src="http://blog-img.coolsen.cn/img/java8-1562726251.gif"></p>
<h2 id="14-如何创建索引？"><a href="#14-如何创建索引？" class="headerlink" title="14. 如何创建索引？"></a>14. 如何创建索引？</h2><p>创建索引有三种方式。</p>
<p>1、 在执行CREATE TABLE时创建索引</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> user_index2 (</span><br><span class="line">	id <span class="type">INT</span> auto_increment <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">	first_name <span class="type">VARCHAR</span> (<span class="number">16</span>),</span><br><span class="line">	last_name <span class="type">VARCHAR</span> (<span class="number">16</span>),</span><br><span class="line">	id_card <span class="type">VARCHAR</span> (<span class="number">18</span>),</span><br><span class="line">	information text,</span><br><span class="line">	KEY name (first_name, last_name),</span><br><span class="line">	FULLTEXT KEY (information),</span><br><span class="line">	<span class="keyword">UNIQUE</span> KEY (id_card)</span><br><span class="line">);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2、 使用ALTER TABLE命令去增加索引。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span> INDEX index_name (column_list);</span><br></pre></td></tr></table></figure>

<p>ALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引。</p>
<p>其中table_name是要增加索引的表名，column_list指出对哪些列进行索引，多列时各列之间用逗号分隔。</p>
<p>索引名index_name可自己命名，缺省时，MySQL将根据第一个索引列赋一个名称。另外，ALTER TABLE允许在单个语句中更改多个表，因此可以在同时创建多个索引。<br>3、 使用CREATE INDEX命令创建。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> INDEX index_name <span class="keyword">ON</span> table_name (column_list);</span><br></pre></td></tr></table></figure>

<h2 id="15-创建索引时需要注意什么？"><a href="#15-创建索引时需要注意什么？" class="headerlink" title="15. 创建索引时需要注意什么？"></a>15. 创建索引时需要注意什么？</h2><ul>
<li>非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；</li>
<li>取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；</li>
<li>索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。</li>
</ul>
<h2 id="16-建索引的原则有哪些？"><a href="#16-建索引的原则有哪些？" class="headerlink" title="16. 建索引的原则有哪些？"></a>16. 建索引的原则有哪些？</h2><p>1、最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a &#x3D; 1 and b &#x3D; 2 and c &gt; 3 and d &#x3D; 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</p>
<p>2、&#x3D;和in可以乱序，比如a &#x3D; 1 and b &#x3D; 2 and c &#x3D; 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。</p>
<p>3、尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)&#x2F;count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。</p>
<p>4、索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) &#x3D; ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time &#x3D; unix_timestamp(’2014-05-29’)。</p>
<p>5、尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。</p>
<h2 id="17-使用索引查询一定能提高查询的性能吗？"><a href="#17-使用索引查询一定能提高查询的性能吗？" class="headerlink" title="17. 使用索引查询一定能提高查询的性能吗？"></a>17. 使用索引查询一定能提高查询的性能吗？</h2><p>通常通过索引查询数据比全表扫描要快。但是我们也必须注意到它的代价。</p>
<p>索引需要空间来存储，也需要定期维护， 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的I* NSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I&#x2F;O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询(INDEX RANGE SCAN)适用于两种情况:</p>
<ul>
<li>基于一个范围的检索，一般查询返回结果集小于表中记录数的30%。</li>
<li>基于非唯一性索引的检索。</li>
</ul>
<h2 id="18-什么情况下不走索引（索引失效）？"><a href="#18-什么情况下不走索引（索引失效）？" class="headerlink" title="18. 什么情况下不走索引（索引失效）？"></a>18. 什么情况下不走索引（索引失效）？</h2><h5 id="1、使用-x3D-或者-lt-gt-导致索引失效"><a href="#1、使用-x3D-或者-lt-gt-导致索引失效" class="headerlink" title="1、使用!&#x3D; 或者 &lt;&gt; 导致索引失效"></a>1、使用!&#x3D; 或者 &lt;&gt; 导致索引失效</h5><h5 id="2、类型不一致导致的索引失效"><a href="#2、类型不一致导致的索引失效" class="headerlink" title="2、类型不一致导致的索引失效"></a>2、类型不一致导致的索引失效</h5><h5 id="3、函数导致的索引失效"><a href="#3、函数导致的索引失效" class="headerlink" title="3、函数导致的索引失效"></a>3、函数导致的索引失效</h5><p>如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM `user` WHERE DATE(create_time) = &#x27;2020-09-03&#x27;;</span><br></pre></td></tr></table></figure>

<p>如果使用函数在索引列，这是不走索引的。</p>
<h5 id="4、运算符导致的索引失效"><a href="#4、运算符导致的索引失效" class="headerlink" title="4、运算符导致的索引失效"></a>4、运算符导致的索引失效</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM `user` WHERE age - 1 = 20;</span><br></pre></td></tr></table></figure>

<p>如果你对列进行了（+，-，*，&#x2F;，!）, 那么都将不会走索引。</p>
<h5 id="5、OR引起的索引失效"><a href="#5、OR引起的索引失效" class="headerlink" title="5、OR引起的索引失效"></a>5、OR引起的索引失效</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM `user` WHERE `name` = &#x27;张三&#x27; OR height = &#x27;175&#x27;;</span><br></pre></td></tr></table></figure>

<p>OR导致索引是在特定情况下的，并不是所有的OR都是使索引失效，如果OR连接的是同一个字段，那么索引不会失效，反之索引失效。</p>
<h5 id="6、模糊搜索导致的索引失效"><a href="#6、模糊搜索导致的索引失效" class="headerlink" title="6、模糊搜索导致的索引失效"></a>6、模糊搜索导致的索引失效</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM `user` WHERE `name` LIKE &#x27;%冰&#x27;;</span><br></pre></td></tr></table></figure>

<p>当<code>%</code>放在匹配字段前是不走索引的，放在后面才会走索引。</p>
<h5 id="7、NOT-IN、NOT-EXISTS导致索引失效"><a href="#7、NOT-IN、NOT-EXISTS导致索引失效" class="headerlink" title="7、NOT IN、NOT EXISTS导致索引失效"></a>7、NOT IN、NOT EXISTS导致索引失效</h5>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/02/MySQL%E7%B4%A2%E5%BC%95%E8%BF%9E%E7%8E%AF18%E9%97%AE%EF%BC%81/" data-id="cl3wpiofy000fo0r45jz6d4o4" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-MySQL基础、锁、事务、分库分表、优化" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/02/MySQL%E5%9F%BA%E7%A1%80%E3%80%81%E9%94%81%E3%80%81%E4%BA%8B%E5%8A%A1%E3%80%81%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E3%80%81%E4%BC%98%E5%8C%96/" class="article-date">
  <time class="dt-published" datetime="2022-06-02T07:37:48.640Z" itemprop="datePublished">2022-06-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><p><img src="http://blog-img.coolsen.cn/img/image-20210822210317322.png" alt="image-20210822210317322"></p>
<h2 id="1-数据库的三范式是什么？"><a href="#1-数据库的三范式是什么？" class="headerlink" title="1. 数据库的三范式是什么？"></a>1. 数据库的三范式是什么？</h2><ul>
<li>第一范式：强调的是列的原子性，即数据库表的每一列都是不可分割的原子数据项。</li>
<li>第二范式：要求实体的属性完全依赖于主关键字。所谓完全 依赖是指不能存在仅依赖主关键字一部分的属性。</li>
<li>第三范式：任何非主属性不依赖于其它非主属性。</li>
</ul>
<h2 id="2-MySQL-支持哪些存储引擎"><a href="#2-MySQL-支持哪些存储引擎" class="headerlink" title="2. MySQL 支持哪些存储引擎?"></a>2. MySQL 支持哪些存储引擎?</h2><p>MySQL 支持多种存储引擎,比如 InnoDB,MyISAM,Memory,Archive 等等.在大多数的情况下,直接选择使用 InnoDB 引擎都是最合适的,InnoDB 也是 MySQL 的默认存储引擎。</p>
<p>MyISAM 和 InnoDB 的区别有哪些：</p>
<ul>
<li>InnoDB 支持事务，MyISAM 不支持</li>
<li>InnoDB 支持外键，而 MyISAM 不支持</li>
<li>InnoDB 是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高；MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的。</li>
<li>Innodb 不支持全文索引，而 MyISAM 支持全文索引，查询效率上 MyISAM 要高；</li>
<li>InnoDB 不保存表的具体行数，MyISAM 用一个变量保存了整个表的行数。</li>
<li>MyISAM 采用表级锁(table-level locking)；InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。</li>
</ul>
<h2 id="3-超键、候选键、主键、外键分别是什么？"><a href="#3-超键、候选键、主键、外键分别是什么？" class="headerlink" title="3. 超键、候选键、主键、外键分别是什么？"></a>3. 超键、候选键、主键、外键分别是什么？</h2><ul>
<li>超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。</li>
<li>候选键：是最小超键，即没有冗余元素的超键。</li>
<li>主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。</li>
<li>外键：在一个表中存在的另一个表的主键称此表的外键。</li>
</ul>
<h2 id="4-SQL-约束有哪几种？"><a href="#4-SQL-约束有哪几种？" class="headerlink" title="4. SQL 约束有哪几种？"></a>4. SQL 约束有哪几种？</h2><ul>
<li>NOT NULL: 用于控制字段的内容一定不能为空（NULL）。</li>
<li>UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。</li>
<li>PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。</li>
<li>FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。</li>
<li>CHECK: 用于控制字段的值范围。</li>
</ul>
<h2 id="5-MySQL-中的-varchar-和-char-有什么区别？"><a href="#5-MySQL-中的-varchar-和-char-有什么区别？" class="headerlink" title="5. MySQL 中的 varchar 和 char 有什么区别？"></a>5. MySQL 中的 varchar 和 char 有什么区别？</h2><p>char 是一个定长字段,假如申请了<code>char(10)</code>的空间,那么无论实际存储多少内容.该字段都占用 10 个字符,而 varchar 是变长的,也就是说申请的只是最大长度,占用的空间为实际字符长度+1,最后一个字符存储使用了多长的空间.</p>
<p>在检索效率上来讲,char &gt; varchar,因此在使用中,如果确定某个字段的值的长度,可以使用 char,否则应该尽量使用 varchar.例如存储用户 MD5 加密后的密码,则应该使用 char。</p>
<h2 id="6-MySQL中-in-和-exists-区别"><a href="#6-MySQL中-in-和-exists-区别" class="headerlink" title="6. MySQL中 in 和 exists 区别"></a>6. MySQL中 in 和 exists 区别</h2><p>MySQL中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。</p>
<p>如果查询的两个表大小相当，那么用in和exists差别不大。<br>如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in。<br>not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。</p>
<h2 id="7-drop、delete与truncate的区别"><a href="#7-drop、delete与truncate的区别" class="headerlink" title="7. drop、delete与truncate的区别"></a>7. drop、delete与truncate的区别</h2><p>三者都表示删除，但是三者有一些差别：</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210822203927822.png" alt="image-20210822203927822"></p>
<h2 id="8-什么是存储过程？有哪些优缺点？"><a href="#8-什么是存储过程？有哪些优缺点？" class="headerlink" title="8. 什么是存储过程？有哪些优缺点？"></a>8. 什么是存储过程？有哪些优缺点？</h2><p>存储过程是一些预编译的 SQL 语句。</p>
<p>1、更加直白的理解：存储过程可以说是一个记录集，它是由一些 T-SQL 语句组成的代码块，这些 T-SQL 语句代码像一个方法一样实现一些功能（对单表或多表的增删改查），然后再给这个代码块取一个名字，在用到这个功能的时候调用他就行了。 </p>
<p>2、存储过程是一个预编译的代码块，执行效率比较高,一个存储过程替代大量 T_SQL 语句 ，可以降低网络通信量，提高通信速率,可以一定程度上确保数据安全</p>
<p>但是,在互联网项目中,其实是不太推荐存储过程的,比较出名的就是阿里的《Java 开发手册》中禁止使用存储过程,我个人的理解是,在互联网项目中,迭代太快,项目的生命周期也比较短,人员流动相比于传统的项目也更加频繁,在这样的情况下,存储过程的管理确实是没有那么方便,同时,复用性也没有写在服务层那么好。</p>
<h2 id="9-MySQL-执行查询的过程"><a href="#9-MySQL-执行查询的过程" class="headerlink" title="9. MySQL 执行查询的过程"></a>9. MySQL 执行查询的过程</h2><ol>
<li>客户端通过 TCP 连接发送连接请求到 MySQL 连接器，连接器会对该请求进行权限验证及连接资源分配</li>
<li>查缓存。（当判断缓存是否命中时，MySQL 不会进行解析查询语句，而是直接使用 SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。）</li>
<li>语法分析（SQL 语法是否写错了）。 如何把语句给到预处理器，检查数据表和数据列是否存在，解析别名看是否存在歧义。</li>
<li>优化。是否使用索引，生成执行计划。</li>
<li>交给执行器，将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。</li>
</ol>
<p><img src="https://static001.geekbang.org/infoq/41/4102b7d60fa20a0caabb127ecbb4d2f3.jpeg?x-oss-process=image/resize,p_80/auto-orient,1" alt="img"></p>
<p>更新语句执行会复杂一点。需要检查表是否有排它锁，写 binlog，刷盘，是否执行 commit。</p>
<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><h2 id="1-什么是数据库事务？"><a href="#1-什么是数据库事务？" class="headerlink" title="1. 什么是数据库事务？"></a>1. 什么是数据库事务？</h2><p>事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。</p>
<p>事务最经典也经常被拿出来说例子就是转账了。</p>
<p>假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。</p>
<h2 id="2-介绍一下事务具有的四个特征"><a href="#2-介绍一下事务具有的四个特征" class="headerlink" title="2. 介绍一下事务具有的四个特征"></a>2. 介绍一下事务具有的四个特征</h2><p>事务就是一组原子性的操作，这些操作要么全部发生，要么全部不发生。事务把数据库从一种一致性状态转换成另一种一致性状态。</p>
<ul>
<li>原子性。事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做</li>
<li>一致性。事 务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统 运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是 不一致的状态。</li>
<li>隔离性。一个事务的执行不能其它事务干扰。即一个事务内部的&#x2F;&#x2F;操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。</li>
<li>持续性。也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。</li>
</ul>
<h2 id="3-说一下MySQL-的四种隔离级别"><a href="#3-说一下MySQL-的四种隔离级别" class="headerlink" title="3. 说一下MySQL 的四种隔离级别"></a>3. 说一下MySQL 的四种隔离级别</h2><ul>
<li>Read Uncommitted（读取未提交内容）</li>
</ul>
<p>在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。</p>
<ul>
<li>Read Committed（读取提交内容）</li>
</ul>
<p>这是大多数数据库系统的默认隔离级别（但不是 MySQL 默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓 的 不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的 commit，所以同一 select 可能返回不同结果。</p>
<ul>
<li>Repeatable Read（可重读）</li>
</ul>
<p>这是 MySQL 的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。</p>
<ul>
<li>Serializable（可串行化）</li>
</ul>
<p>通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210822180308501.png" alt="image-20210822180308501"></p>
<p>MySQL 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别</p>
<p>事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVVC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。</p>
<p>因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是READ-COMMITTED(读取提交内容):，但是你要知道的是InnoDB 存储引擎默认使用 <strong>REPEATABLE-READ（可重读）</strong>并不会有任何性能损失。</p>
<p>InnoDB 存储引擎在 分布式事务 的情况下一般会用到**SERIALIZABLE(可串行化)**隔离级别。</p>
<h2 id="4-什么是脏读？幻读？不可重复读？"><a href="#4-什么是脏读？幻读？不可重复读？" class="headerlink" title="4. 什么是脏读？幻读？不可重复读？"></a>4. 什么是脏读？幻读？不可重复读？</h2><p>1、脏读：事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据</p>
<p>2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果 不一致。</p>
<p>3、幻读：系统管理员 A 将数据库中所有学生的成绩从具体分数改为 ABCDE 等级，但是系统管理员 B 就在这个时候插入了一条具体分数的记录，当系统管理员 A 改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。</p>
<p>不可重复读侧重于修改，幻读侧重于新增或删除（多了或少量行），脏读是一个事务回滚影响另外一个事务。</p>
<h2 id="5-事务的实现原理"><a href="#5-事务的实现原理" class="headerlink" title="5. 事务的实现原理"></a>5. 事务的实现原理</h2><p>事务是基于重做日志文件(redo log)和回滚日志(undo log)实现的。</p>
<p>每提交一个事务必须先将该事务的所有日志写入到重做日志文件进行持久化，数据库就可以通过重做日志来保证事务的原子性和持久性。</p>
<p>每当有修改事务时，还会产生 undo log，如果需要回滚，则根据 undo log 的反向语句进行逻辑操作，比如 insert 一条记录就 delete 一条记录。undo log 主要实现数据库的一致性。</p>
<h2 id="6-MySQL事务日志介绍下？"><a href="#6-MySQL事务日志介绍下？" class="headerlink" title="6. MySQL事务日志介绍下？"></a>6. MySQL事务日志介绍下？</h2><p>innodb 事务日志包括 redo log 和 undo log。</p>
<p>undo log 指事务开始之前，在操作任何数据之前，首先将需操作的数据备份到一个地方。redo log 指事务中操作的任何数据，将最新的数据备份到一个地方。</p>
<p>事务日志的目的：实例或者介质失败，事务日志文件就能派上用场。</p>
<h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><p>redo log 不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入 redo 中。具体的落盘策略可以进行配置 。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启 MySQL 服务的时候，根据 redo log 进行重做，从而达到事务的未入磁盘数据进行持久化这一特性。RedoLog 是为了实现事务的持久性而出现的产物。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210822181340692.png" alt="image-20210822181340692"></p>
<h3 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h3><p>undo log 用来回滚行记录到某个版本。事务未提交之前，Undo 保存了未提交之前的版本数据，Undo 中的数据可作为数据旧版本快照供其他并发事务进行快照读。是为了实现事务的原子性而出现的产物,在 MySQL innodb 存储引擎中用来实现多版本并发控制。</p>
<p><img src="http://blog-img.coolsen.cn/img/image-20210822181416382.png" alt="image-20210822181416382"></p>
<h2 id="7-什么是MySQL的-binlog？"><a href="#7-什么是MySQL的-binlog？" class="headerlink" title="7. 什么是MySQL的 binlog？"></a>7. 什么是MySQL的 binlog？</h2><p>MySQL的 binlog 是记录所有数据库表结构变更（例如 CREATE、ALTER TABLE）以及表数据修改（INSERT、UPDATE、DELETE）的二进制日志。binlog 不会记录 SELECT 和 SHOW 这类操作，因为这类操作对数据本身并没有修改，但你可以通过查询通用日志来查看 MySQL 执行过的所有语句。</p>
<p>MySQL binlog 以事件形式记录，还包含语句所执行的消耗的时间，MySQL 的二进制日志是事务安全型的。binlog 的主要目的是复制和恢复。</p>
<p>binlog 有三种格式，各有优缺点：</p>
<ul>
<li><p><strong>statement：</strong> 基于 SQL 语句的模式，某些语句和函数如 UUID, LOAD DATA INFILE 等在复制过程可能导致数据不一致甚至出错。</p>
</li>
<li><p><strong>row：</strong> 基于行的模式，记录的是行的变化，很安全。但是 binlog 会比其他两种模式大很多，在一些大表中清除大量数据时在 binlog 中会生成很多条语句，可能导致从库延迟变大。</p>
</li>
<li><p><strong>mixed：</strong> 混合模式，根据语句来选用是 statement 还是 row 模式。</p>
</li>
</ul>
<h2 id="8-在事务中可以混合使用存储引擎吗？"><a href="#8-在事务中可以混合使用存储引擎吗？" class="headerlink" title="8. 在事务中可以混合使用存储引擎吗？"></a><strong>8. 在事务中可以混合使用存储引擎吗？</strong></h2><p>尽量不要在同一个事务中使用多种存储引擎，MySQL服务器层不管理事务，事务是由下层的存储引擎实现的。</p>
<p>如果在事务中混合使用了事务型和非事务型的表（例如InnoDB和MyISAM表）,在正常提交的情况下不会有什么问题。</p>
<p>但如果该事务需要回滚，非事务型的表上的变更就无法撤销，这会导致数据库处于不一致的状态，这种情况很难修复，事务的最终结果将无法确定。所以，为每张表选择合适的存储引擎非常重要。</p>
<h2 id="9-MySQL中是如何实现事务隔离的"><a href="#9-MySQL中是如何实现事务隔离的" class="headerlink" title="9. MySQL中是如何实现事务隔离的?"></a>9. MySQL中是如何实现事务隔离的?</h2><p>读未提交和串行化基本上是不需要考虑的隔离级别，前者不加锁限制，后者相当于单线程执行，效率太差。</p>
<p>MySQL 在可重复读级别解决了幻读问题，是通过行锁和间隙锁的组合 Next-Key 锁实现的。</p>
<p>详细原理看这篇文章：<a target="_blank" rel="noopener" href="https://haicoder.net/note/MySQL-interview/MySQL-interview-MySQL-trans-level.html">https://haicoder.net/note/MySQL-interview/MySQL-interview-MySQL-trans-level.html</a></p>
<h2 id="10-什么是-MVCC？"><a href="#10-什么是-MVCC？" class="headerlink" title="10. 什么是 MVCC？"></a>10. 什么是 MVCC？</h2><p>MVCC， 即多版本并发控制。MVCC 的实现，是通过保存数据在某个时间点的快照来实现的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。</p>
<h2 id="11-MVCC-的实现原理"><a href="#11-MVCC-的实现原理" class="headerlink" title="11. MVCC 的实现原理"></a>11. MVCC 的实现原理</h2><p>对于 InnoDB ，聚簇索引记录中包含 3 个隐藏的列：</p>
<ul>
<li>ROW ID：隐藏的自增 ID，如果表没有主键，InnoDB 会自动按 ROW ID 产生一个聚集索引树。</li>
<li>事务 ID：记录最后一次修改该记录的事务 ID。</li>
<li>回滚指针：指向这条记录的上一个版本。</li>
</ul>
<p>我们拿上面的例子，对应解释下 MVCC 的实现原理，如下图：</p>
<p><img src="http://blog-img.coolsen.cn/img/modb_95751916-225c-11eb-b0bb-5254001c05fe.png" alt="img"></p>
<p>如图，首先 insert 语句向表 t1 中插入了一条数据，a 字段为 1，b 字段为 1， ROW ID 也为 1 ，事务 ID 假设为 1，回滚指针假设为 null。当执行 update t1 set b&#x3D;666 where a&#x3D;1 时，大致步骤如下：</p>
<ul>
<li>数据库会先对满足 a&#x3D;1 的行加排他锁；</li>
<li>然后将原记录复制到 undo 表空间中；</li>
<li>修改 b 字段的值为 666，修改事务 ID 为 2；</li>
<li>并通过隐藏的回滚指针指向 undo log 中的历史记录；</li>
<li>事务提交，释放前面对满足 a&#x3D;1 的行所加的排他锁。</li>
</ul>
<p>在前面实验的第 6 步中，session2 查询的结果是 session1 修改之前的记录，这个记录就是<strong>来自 undolog</strong> 中。</p>
<p>因此可以总结出 MVCC 实现的原理大致是：</p>
<p>InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本，这个历史版本存放在 undo log 中。如果要执行更新操作，会将原记录放入 undo log 中，并通过隐藏的回滚指针指向 undo log 中的原记录。其它事务此时需要查询时，就是查询 undo log 中这行数据的最后一个历史版本。</p>
<p>MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。通过 MVCC，保证了事务 ACID 中的 I（隔离性）特性。</p>
<h1 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h1><h2 id="1-为什么要加锁"><a href="#1-为什么要加锁" class="headerlink" title="1. 为什么要加锁?"></a>1. 为什么要加锁?</h2><p>当多个用户并发地存取数据时，在<a target="_blank" rel="noopener" href="https://cloud.tencent.com/solution/database?from=10680">数据库</a>中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。</p>
<p>保证多用户环境下保证数据库完整性和一致性。</p>
<h2 id="2-按照锁的粒度分数据库锁有哪些？"><a href="#2-按照锁的粒度分数据库锁有哪些？" class="headerlink" title="2. 按照锁的粒度分数据库锁有哪些？"></a>2. 按照锁的粒度分数据库锁有哪些？</h2><p>在关系型数据库中，可以<strong>按照锁的粒度把数据库锁分</strong>为行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )。</p>
<p>行级锁</p>
<ul>
<li>行级锁是<a target="_blank" rel="noopener" href="https://cloud.tencent.com/product/cdb?from=10680">MySQL</a>中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。</li>
<li>开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</li>
</ul>
<p>表级锁</p>
<ul>
<li>表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。</li>
<li>开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。</li>
</ul>
<p>页级锁</p>
<ul>
<li>页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁</li>
<li>开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般</li>
</ul>
<p><strong>MyISAM和InnoDB存储引擎使用的锁：</strong></p>
<ul>
<li>MyISAM采用表级锁(table-level locking)。</li>
<li>InnoDB支持行级锁(row-level locking)和表级锁，默认为行级锁</li>
</ul>
<h2 id="3-从锁的类别上分MySQL都有哪些锁呢？"><a href="#3-从锁的类别上分MySQL都有哪些锁呢？" class="headerlink" title="3. 从锁的类别上分MySQL都有哪些锁呢？"></a>3. 从锁的类别上分MySQL都有哪些锁呢？</h2><p>从锁的类别上来讲，有共享锁和排他锁。</p>
<ul>
<li><p>共享锁: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。</p>
</li>
<li><p>排他锁: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。</p>
</li>
</ul>
<p>用上面的例子来说就是用户的行为有两种，一种是来看房，多个用户一起看房是可以接受的。 一种是真正的入住一晚，在这期间，无论是想入住的还是想看房的都不可以。</p>
<p>锁的粒度取决于具体的存储引擎，InnoDB实现了行级锁，页级锁，表级锁。</p>
<p>他们的加锁开销从大到小，并发能力也是从大到小。</p>
<h2 id="4-数据库的乐观锁和悲观锁是什么？怎么实现的？"><a href="#4-数据库的乐观锁和悲观锁是什么？怎么实现的？" class="headerlink" title="4. 数据库的乐观锁和悲观锁是什么？怎么实现的？"></a>4. 数据库的乐观锁和悲观锁是什么？怎么实现的？</h2><p>数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观并发控制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。</p>
<ul>
<li><p>悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制</p>
</li>
<li><p>乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：乐一般会使用版本号机制或CAS算法实现。</p>
</li>
</ul>
<p><strong>两种锁的使用场景</strong></p>
<p>从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。</p>
<p>但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。</p>
<h2 id="5-InnoDB引擎的行锁是怎么实现的？"><a href="#5-InnoDB引擎的行锁是怎么实现的？" class="headerlink" title="5. InnoDB引擎的行锁是怎么实现的？"></a>5. InnoDB引擎的行锁是怎么实现的？</h2><p>InnoDB是基于索引来完成行锁</p>
<p>例: select * from tab_with_index where id &#x3D; 1 for update;</p>
<p>for update 可以根据条件来完成行锁锁定，并且 id 是有索引键的列，如果 id 不是索引键那么InnoDB将完成表锁，并发将无从谈起</p>
<h2 id="6-什么是死锁？怎么解决？"><a href="#6-什么是死锁？怎么解决？" class="headerlink" title="6. 什么是死锁？怎么解决？"></a>6. 什么是死锁？怎么解决？</h2><p>死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。</p>
<p>常见的解决死锁的方法</p>
<p>1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。</p>
<p>2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；</p>
<p>3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；</p>
<p>如果业务处理不好可以用分布式事务锁或者使用乐观锁</p>
<h2 id="7-隔离级别与锁的关系"><a href="#7-隔离级别与锁的关系" class="headerlink" title="7. 隔离级别与锁的关系"></a>7. 隔离级别与锁的关系</h2><p>在Read Uncommitted级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突</p>
<p>在Read Committed级别下，读操作需要加共享锁，但是在语句执行完以后释放共享锁；</p>
<p>在Repeatable Read级别下，读操作需要加共享锁，但是在事务提交之前并不释放共享锁，也就是必须等待事务执行完毕以后才释放共享锁。</p>
<p>SERIALIZABLE 是限制性最强的隔离级别，因为该级别锁定整个范围的键，并一直持有锁，直到事务完成。</p>
<h2 id="8-优化锁方面的意见？"><a href="#8-优化锁方面的意见？" class="headerlink" title="8. 优化锁方面的意见？"></a>8. 优化锁方面的意见？</h2><ul>
<li>使用较低的隔离级别</li>
<li>设计索引，尽量使用索引去访问数据，加锁更加精确，从而减少锁冲突</li>
<li>选择合理的事务大小，给记录显示加锁时，最好一次性请求足够级别的锁。列如，修改数据的话，最好申请排他锁，而不是先申请共享锁，修改时在申请排他锁，这样会导致死锁</li>
<li>不同的程序访问一组表的时候，应尽量约定一个相同的顺序访问各表，对于一个表而言，尽可能的固定顺序的获取表中的行。这样大大的减少死锁的机会。</li>
<li>尽量使用相等条件访问数据，这样可以避免间隙锁对并发插入的影响</li>
<li>不要申请超过实际需要的锁级别</li>
<li>数据查询的时候不是必要，不要使用加锁。MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能：MVCC只在committed read（读提交）和 repeatable read （可重复读）两种隔离级别</li>
<li>对于特定的事务，可以使用表锁来提高处理速度活着减少死锁的可能。</li>
</ul>
<h1 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h1><h2 id="1-为什么要分库分表？"><a href="#1-为什么要分库分表？" class="headerlink" title="1. 为什么要分库分表？"></a>1. 为什么要分库分表？</h2><p><strong>分表</strong></p>
<p>比如你单表都几千万数据了，你确定你能扛住么？绝对不行，单表数据量太大，会极大影响你的 sql执行的性能，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。</p>
<p>分表就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。</p>
<p><strong>分库</strong></p>
<p>分库就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。</p>
<p>这就是所谓的分库分表。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/14266602-ae74054f45f44e3d?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="img"></p>
<h2 id="2-用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？"><a href="#2-用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？" class="headerlink" title="2. 用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？"></a>2. 用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？</h2><p>这个其实就是看看你了解哪些分库分表的中间件，各个中间件的优缺点是啥？然后你用过哪些分库分表的中间件。</p>
<p>比较常见的包括：</p>
<ul>
<li>cobar</li>
<li>TDDL</li>
<li>atlas</li>
<li>sharding-jdbc</li>
<li>mycat</li>
</ul>
<h4 id="cobar"><a href="#cobar" class="headerlink" title="cobar"></a>cobar</h4><p>阿里 b2b 团队开发和开源的，属于 proxy 层方案。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。</p>
<h4 id="TDDL"><a href="#TDDL" class="headerlink" title="TDDL"></a>TDDL</h4><p>淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配置管理系统。</p>
<h4 id="atlas"><a href="#atlas" class="headerlink" title="atlas"></a>atlas</h4><p>360 开源的，属于 proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。</p>
<h4 id="sharding-jdbc"><a href="#sharding-jdbc" class="headerlink" title="sharding-jdbc"></a>sharding-jdbc</h4><p>当当开源的，属于 client 层方案。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且目前推出到了 2.0 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017 年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也<strong>可以选择的方案</strong>。</p>
<h4 id="mycat"><a href="#mycat" class="headerlink" title="mycat"></a>mycat</h4><p>基于 cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 sharding jdbc 来说，年轻一些，经历的锤炼少一些。</p>
<h2 id="3-如何对数据库如何进行垂直拆分或水平拆分的？"><a href="#3-如何对数据库如何进行垂直拆分或水平拆分的？" class="headerlink" title="3. 如何对数据库如何进行垂直拆分或水平拆分的？"></a>3. 如何对数据库如何进行垂直拆分或水平拆分的？</h2><p><strong>水平拆分</strong>的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来抗更高的并发，还有就是用多个库的存储容量来进行扩容。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/10089464-0e01dfe246b5c7ac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/474/format/webp" alt="img"></p>
<p><strong>垂直拆分</strong>的意思，就是<strong>把一个有很多字段的表给拆分成多个表</strong>，<strong>或者是多个库上去</strong>。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会<strong>将较少的访问频率很高的字段放到一个表里去</strong>，然后<strong>将较多的访问频率很低的字段放到另外一个表里去</strong>。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/10089464-ab3069913c0f097c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/320/format/webp" alt="img"></p>
<p>两种<strong>分库分表的方式</strong>：</p>
<ul>
<li>一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如<strong>时间范围</strong>来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。</li>
<li>或者是按照某个字段hash一下均匀分散，这个较为常用。</li>
</ul>
<p>range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。</p>
<p>hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表</p>
<h1 id="读写分离、主从同步（复制）"><a href="#读写分离、主从同步（复制）" class="headerlink" title="读写分离、主从同步（复制）"></a>读写分离、主从同步（复制）</h1><h2 id="1-什么是MySQL主从同步？"><a href="#1-什么是MySQL主从同步？" class="headerlink" title="1. 什么是MySQL主从同步？"></a>1. 什么是MySQL主从同步？</h2><p>主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器（master），其余的服务器充当从服务器（slave）。</p>
<p>因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的数据库，某个数据库，甚至是某个数据库上的某个表。</p>
<h2 id="2-MySQL主从同步的目的？为什么要做主从同步？"><a href="#2-MySQL主从同步的目的？为什么要做主从同步？" class="headerlink" title="2. MySQL主从同步的目的？为什么要做主从同步？"></a>2. MySQL主从同步的目的？为什么要做主从同步？</h2><ol>
<li>通过增加从服务器来提高数据库的性能，在主服务器上执行写入和更新，在从服务器上向外提供读功能，可以动态地调整从服务器的数量，从而调整整个数据库的性能。</li>
<li>提高数据安全-因为数据已复制到从服务器，从服务器可以终止复制进程，所以，可以在从服务器上备份而不破坏主服务器相应数据</li>
<li>在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器的性能</li>
<li>数据备份。一般我们都会做数据备份，可能是写定时任务，一些特殊行业可能还需要手动备份，有些行业要求备份和原数据不能在同一个地方，所以主从就能很好的解决这个问题，不仅备份及时，而且还可以多地备份，保证数据的安全</li>
</ol>
<h2 id="3-如何实现MySQL的读写分离？"><a href="#3-如何实现MySQL的读写分离？" class="headerlink" title="3. 如何实现MySQL的读写分离？"></a>3. 如何实现MySQL的读写分离？</h2><p>其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。</p>
<h2 id="4-MySQL主从复制流程和原理？"><a href="#4-MySQL主从复制流程和原理？" class="headerlink" title="4. MySQL主从复制流程和原理？"></a>4. MySQL主从复制流程和原理？</h2><p>基本原理流程，是3个线程以及之间的关联</p>
<p>主：binlog线程——记录下所有改变了数据库数据的语句，放进master上的binlog中；</p>
<p>从：io线程——在使用start slave 之后，负责从master上拉取 binlog 内容，放进自己的relay log中；</p>
<p>从：sql执行线程——执行relay log中的语句；</p>
<p><strong>复制过程如下</strong>：</p>
<p><img src="http://blog-img.coolsen.cn/img/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC85LzIxLzE2NWZiNjgzMjIyMDViMmU" alt="img"></p>
<p>Binary log：主数据库的二进制日志</p>
<p>Relay log：从服务器的中继日志</p>
<p>第一步：master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中。</p>
<p>第二步：salve开启一个I&#x2F;O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I&#x2F;O线程最终的目的是将这些事件写入到中继日志中。</p>
<p>第三步：SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。</p>
<h2 id="5-MySQL主从同步延时问题如何解决？"><a href="#5-MySQL主从同步延时问题如何解决？" class="headerlink" title="5. MySQL主从同步延时问题如何解决？"></a>5. MySQL主从同步延时问题如何解决？</h2><p>MySQL 实际上在有两个同步机制，一个是半同步复制，用来 解决主库数据丢失问题；一个是并行复制，用来 解决主从同步延时问题。</p>
<ul>
<li>半同步复制，也叫 semi-sync 复制，指的就是主库写入 binlog 日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写操作完成了。</li>
<li>并行复制，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。</li>
</ul>
<h1 id="MySQL优化"><a href="#MySQL优化" class="headerlink" title="MySQL优化"></a>MySQL优化</h1><h2 id="1-如何定位及优化SQL语句的性能问题？"><a href="#1-如何定位及优化SQL语句的性能问题？" class="headerlink" title="1. 如何定位及优化SQL语句的性能问题？"></a>1. 如何定位及优化SQL语句的性能问题？</h2><p>对于低性能的SQL语句的定位，最重要也是最有效的方法就是使用执行计划，MySQL提供了explain命令来查看语句的执行计划。 我们知道，不管是哪种数据库，或者是哪种数据库引擎，在对一条SQL语句进行执行的过程中都会做很多相关的优化，对于查询语句，最重要的优化方式就是使用索引。</p>
<p> 而执行计划，就是显示数据库引擎对于SQL语句的执行的详细情况，其中包含了是否使用索引，使用什么索引，使用的索引的相关信息等。<br><img src="http://blog-img.coolsen.cn/img/image-20210822204026552.png" alt="image-20210822204026552"></p>
<h2 id="2-大表数据查询，怎么优化"><a href="#2-大表数据查询，怎么优化" class="headerlink" title="2. 大表数据查询，怎么优化"></a>2. 大表数据查询，怎么优化</h2><ul>
<li>优化shema、sql语句+索引；</li>
<li>第二加缓存，memcached, redis；</li>
<li>主从复制，读写分离；</li>
<li>垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；</li>
<li>水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；</li>
</ul>
<h2 id="3-超大分页怎么处理"><a href="#3-超大分页怎么处理" class="headerlink" title="3. 超大分页怎么处理?"></a>3. 超大分页怎么处理?</h2><p>数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于<code>select * from table where age &gt; 20 limit 1000000</code>,10 这种查询其实也是有可以优化的余地的. 这条语句需要 load1000000 数据然后基本上全部丢弃,只取 10 条当然比较慢. 当时我们可以修改为<code>select * from table where id in (select id from table where age &gt; 20 limit 1000000,10)</code>.这样虽然也 load 了一百万的数据,但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快。</p>
<p>解决超大分页,其实主要是靠缓存,可预测性的提前查到内容,缓存至redis等k-V数据库中,直接返回即可.</p>
<p>在阿里巴巴《Java开发手册》中,对超大分页的解决办法是类似于上面提到的第一种.</p>
<blockquote>
<p>【推荐】利用延迟关联或者子查询优化超多分页场景。 </p>
<p>说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL改写。 </p>
<p>正例：先快速定位需要获取的id段，然后再关联： </p>
<p>SELECT a.* FROM 表1 a, (select id from 表1 where 条件 LIMIT 100000,20 ) b where a.id&#x3D;b.id</p>
</blockquote>
<h2 id="4-统计过慢查询吗？对慢查询都怎么优化过？"><a href="#4-统计过慢查询吗？对慢查询都怎么优化过？" class="headerlink" title="4. 统计过慢查询吗？对慢查询都怎么优化过？"></a>4. 统计过慢查询吗？对慢查询都怎么优化过？</h2><p>在业务系统中，除了使用主键进行的查询，其他的我都会在测试库上测试其耗时，慢查询的统计主要由运维在做，会定期将业务中的慢查询反馈给我们。</p>
<p>慢查询的优化首先要搞明白慢的原因是什么？ 是查询条件没有命中索引？是load了不需要的数据列？还是数据量太大？</p>
<p>所以优化也是针对这三个方向来的，</p>
<ul>
<li>首先分析语句，看看是否load了额外的数据，可能是查询了多余的行并且抛弃掉了，可能是加载了许多结果中并不需要的列，对语句进行分析以及重写。</li>
<li>分析语句的执行计划，然后获得其使用索引的情况，之后修改语句或者修改索引，使得语句可以尽可能的命中索引。</li>
<li>如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行横向或者纵向的分表。</li>
</ul>
<h2 id="5-如何优化查询过程中的数据访问"><a href="#5-如何优化查询过程中的数据访问" class="headerlink" title="5. 如何优化查询过程中的数据访问"></a>5. 如何优化查询过程中的数据访问</h2><ul>
<li>访问数据太多导致查询性能下降</li>
<li>确定应用程序是否在检索大量超过需要的数据，可能是太多行或列</li>
<li>确认MySQL服务器是否在分析大量不必要的数据行</li>
<li>查询不需要的数据。解决办法：使用limit解决</li>
<li>多表关联返回全部列。解决办法：指定列名</li>
<li>总是返回全部列。解决办法：避免使用SELECT *</li>
<li>重复查询相同的数据。解决办法：可以缓存数据，下次直接读取缓存</li>
<li>是否在扫描额外的记录。解决办法：<br>使用explain进行分析，如果发现查询需要扫描大量的数据，但只返回少数的行，可以通过如下技巧去优化：<br>使用索引覆盖扫描，把所有的列都放到索引中，这样存储引擎不需要回表获取对应行就可以返回结果。</li>
<li>改变数据库和表的结构，修改数据表范式</li>
<li>重写SQL语句，让优化器可以以更优的方式执行查询。</li>
</ul>
<h2 id="6-如何优化关联查询"><a href="#6-如何优化关联查询" class="headerlink" title="6. 如何优化关联查询"></a>6. 如何优化关联查询</h2><ul>
<li>确定ON或者USING子句中是否有索引。</li>
<li>确保GROUP BY和ORDER BY只有一个表中的列，这样MySQL才有可能使用索引。</li>
</ul>
<h2 id="7-数据库结构优化"><a href="#7-数据库结构优化" class="headerlink" title="7. 数据库结构优化"></a>7. 数据库结构优化</h2><p>一个好的数据库设计方案对于数据库的性能往往会起到事半功倍的效果。</p>
<p>需要考虑数据冗余、查询和更新的速度、字段的数据类型是否合理等多方面的内容。</p>
<ol>
<li><strong>将字段很多的表分解成多个表</strong></li>
</ol>
<p>对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。</p>
<p>因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。</p>
<ol start="2">
<li><strong>增加中间表</strong></li>
</ol>
<p>对于需要经常联合查询的表，可以建立中间表以提高查询效率。</p>
<p>通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询。</p>
<ol start="3">
<li><strong>增加冗余字段</strong></li>
</ol>
<p>设计数据表时应尽量遵循范式理论的规约，尽可能的减少冗余字段，让数据库设计看起来精致、优雅。但是，合理的加入冗余字段可以提高查询速度。</p>
<p>表的规范化程度越高，表和表之间的关系越多，需要连接查询的情况也就越多，性能也就越差。</p>
<p>注意：</p>
<p>冗余字段的值在一个表中修改了，就要想办法在其他表中更新，否则就会导致数据不一致的问题。</p>
<h2 id="8-MySQL数据库cpu飙升到500-的话他怎么处理？"><a href="#8-MySQL数据库cpu飙升到500-的话他怎么处理？" class="headerlink" title="8. MySQL数据库cpu飙升到500%的话他怎么处理？"></a>8. MySQL数据库cpu飙升到500%的话他怎么处理？</h2><p>当 cpu 飙升到 500%时，先用操作系统命令 top 命令观察是不是 MySQLd 占用导致的，如果不是，找出占用高的进程，并进行相关处理。</p>
<p>如果是 MySQLd 造成的， show processlist，看看里面跑的 session 情况，是不是有消耗资源的 sql 在运行。找出消耗高的 sql，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。</p>
<p>一般来说，肯定要 kill 掉这些线程(同时观察 cpu 使用率是否下降)，等进行相应的调整(比如说加索引、改 sql、改内存参数)之后，再重新跑这些 SQL。</p>
<p>也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等。</p>
<h2 id="9-大表怎么优化？"><a href="#9-大表怎么优化？" class="headerlink" title="9. 大表怎么优化？"></a>9. 大表怎么优化？</h2><p>类似的问题：某个表有近千万数据，CRUD比较慢，如何优化？分库分表了是怎么做的？分表分库了有什么问题？有用到中间件么？他们的原理知道么？</p>
<p>当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下：</p>
<ul>
<li>限定数据的范围： 务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内；</li>
<li>读&#x2F;写分离： 经典的数据库拆分方案，主库负责写，从库负责读；</li>
<li>缓存： 使用MySQL的缓存，另外对重量级、更新少的数据可以考虑；</li>
<li>通过分库分表的方式进行优化，主要有垂直分表和水平分表。</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ThinkWon/article/details/104778621">https://blog.csdn.net/ThinkWon/article/details/104778621</a></p>
<p><a target="_blank" rel="noopener" href="https://haicoder.net/note/mysql-interview/mysql-interview-mysql-binlog.html">https://haicoder.net/note/mysql-interview/mysql-interview-mysql-binlog.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.modb.pro/db/40241">https://www.modb.pro/db/40241</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/05da0fc0950e">https://www.jianshu.com/p/05da0fc0950e</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ThinkWon/article/details/104778621">https://blog.csdn.net/ThinkWon/article/details/104778621</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/02/MySQL%E5%9F%BA%E7%A1%80%E3%80%81%E9%94%81%E3%80%81%E4%BA%8B%E5%8A%A1%E3%80%81%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E3%80%81%E4%BC%98%E5%8C%96/" data-id="cl3wpiog3000ko0r47sgbbogf" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-MySQL" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/02/MySQL/" class="article-date">
  <time class="dt-published" datetime="2022-06-02T07:37:48.633Z" itemprop="datePublished">2022-06-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-MySQL中myisam与innodb的区别"><a href="#1-MySQL中myisam与innodb的区别" class="headerlink" title="1.  MySQL中myisam与innodb的区别?"></a>1.  MySQL中myisam与innodb的区别?</h2><ul>
<li>InnoDB支持事物，而MyISAM不支持事物</li>
<li>InnoDB支持行级锁，而MyISAM支持表级锁</li>
<li>InnoDB支持MVCC, 而MyISAM不支持</li>
<li>InnoDB支持外键，而MyISAM不支持</li>
<li>InnoDB不支持全文索引，而MyISAM支持。</li>
</ul>
<h2 id="2-事务的特性"><a href="#2-事务的特性" class="headerlink" title="2. 事务的特性"></a>2. 事务的特性</h2><ul>
<li>原子性：是指事务包含所有操作要么全部成功，要么全部失败回滚。</li>
<li>一致性：指事务必须使数据库从一个一致性状态变换成另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。<br>拿转账来说，假设用户 A 和用户 B 两者的钱加起来一共是 5000，那么不管 A 和 B 之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是 5000，这就是事务的一致性。</li>
<li>隔离性：是当多个用户并发访问数据库时，比如操作同一张表时，数据表为每个用户开启的事务，不能被其他事务所干扰，多个并发事务之间要相互隔离。</li>
<li>持久性：持久性是指一个事务一旦被提交，那么对数据库中的数据的改变就是永久的，即便是在数据库系统遇到故障的性况下也不会丢失提交事务的操作。</li>
</ul>
<h2 id="3-并发操作问题"><a href="#3-并发操作问题" class="headerlink" title="3. 并发操作问题"></a>3. 并发操作问题</h2><ul>
<li>脏读：脏读是指在一个事务处理过程中读取到了另外一个未提交事务中的数据。</li>
<li>不可重复读：不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。</li>
<li>虚读(幻读)：幻读发生在当两个完全相同的查询执行时，第二次查询所返回的结果集跟第一个查询不相同。<br>比如两个事务操作，A 事务查询状态为 1 的记录时，这时 B 事务插入了一条状态为 1 的记录，A 事务再次查询返回的结果不一样。</li>
</ul>
<h2 id="4-事务的隔离级别"><a href="#4-事务的隔离级别" class="headerlink" title="4. 事务的隔离级别"></a>4. 事务的隔离级别</h2><ul>
<li>Serializable(串行化)：可避免脏读、不可重复读、幻读。（就是串行化读数据）</li>
<li>Repeatable read(可重复读)：可避免脏读、不可重复读的发生。</li>
<li>Read committed(读已提交)：可避免脏读的发生。</li>
<li>Read uncommitted(读未提交)：最低级别，任何情况都无法保证。</li>
</ul>
<p>在 MySQL 数据库中，支持上面四种隔离级别，默认的为 Repeatable read (可重复读)；而在 Oracle 数据库中，只支持 Serializable (串行化)级别和 Read committed (读已提交)这两种级别，其中默认的为 Read committed 级别。##</p>
<h2 id="5-索引是什么？"><a href="#5-索引是什么？" class="headerlink" title="5. 索引是什么？"></a>5. 索引是什么？</h2><p>索引是表的目录，在查找内容之前可以先在目录中查找索引位置，以此快速定位查询数据。对于索引，会保存在额外的文件中。</p>
<p>索引是帮助MySQL高效获取数据的数据结构。</p>
<h2 id="6-索引能干什么-有什么好处？"><a href="#6-索引能干什么-有什么好处？" class="headerlink" title="6. 索引能干什么?有什么好处？"></a>6. 索引能干什么?有什么好处？</h2><p>当表中的数据量越来越大时，索引对于性能的影响愈发重要。索引能够轻易将查询性能提高好几个数量级，总的来说就是可以明显的提高查询效率。</p>
<h2 id="7-索引的种类有哪些？"><a href="#7-索引的种类有哪些？" class="headerlink" title="7.  索引的种类有哪些？"></a>7.  索引的种类有哪些？</h2><p>1、从存储结构上来划分：BTree索引（B-Tree或B+Tree索引），Hash索引，full-index全文索引，R-Tree索引。这里所描述的是索引存储时保存的形式，</p>
<p>2、从应用层次来分：普通索引，唯一索引，复合索引</p>
<p>3、根据中数据的物理顺序与键值的逻辑（索引）顺序关系：聚集索引，非聚集索引。</p>
<p>平时讲的索引类型一般是指在应用层次的划分。</p>
<ul>
<li>普通索引：即一个索引只包含单个列，一个表可以有多个单列索引 </li>
<li>复合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并 </li>
<li>唯一索引：索引列的值必须唯一，但允许有空值</li>
</ul>
<h2 id="8-为什么-MySQL-的索引要使用-B-树而不是其它树形结构-比如-B-树？"><a href="#8-为什么-MySQL-的索引要使用-B-树而不是其它树形结构-比如-B-树？" class="headerlink" title="8. 为什么 MySQL 的索引要使用 B+树而不是其它树形结构?比如 B 树？"></a>8. 为什么 MySQL 的索引要使用 B+树而不是其它树形结构?比如 B 树？</h2><p>B-tree：因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少（有些资料也称为扇出），指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低；</p>
<p>Hash：虽然可以快速定位，但是没有顺序，IO复杂度高。</p>
<p>二叉树：树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度），并且IO代价高。</p>
<p>红黑树：树的高度随着数据量增加而增加，IO代价高。</p>
<p><strong>不使用平衡二叉树的原因如下</strong>：</p>
<p>最大原因：深度太大(因为一个节点最多只有2个子节点)，一次查询需要的I&#x2F;O复杂度为O(lgN),而b+tree只需要O(log_mN),而其出度m非常大，其深度一般不会超过4<br>平衡二叉树逻辑上很近的父子节点，物理上可能很远，无法充分发挥磁盘顺序读和预读的高效特性。</p>
<h2 id="9-MyISAM和InnoDB实现BTree索引方式的区别"><a href="#9-MyISAM和InnoDB实现BTree索引方式的区别" class="headerlink" title="9. MyISAM和InnoDB实现BTree索引方式的区别"></a>9. MyISAM和InnoDB实现BTree索引方式的区别</h2><h3 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h3><p>B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。<br>索引文件和数据文件是分离的</p>
<h3 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h3><ul>
<li>InnoDB 的 B+Tree 索引分为主索引（聚集索引）和辅助索引(非聚集索引)。一张表一定包含一个聚集索引构成的 B+ 树以及若干辅助索引的构成的 B+ 树。</li>
<li>辅助索引的存在并不会影响聚集索引，因为聚集索引构成的 B+ 树是数据实际存储的形式，而辅助索引只用于加速数据的查找，所以一张表上往往有多个辅助索引以此来提升数据库的性能。</li>
<li>就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。</li>
</ul>
<h2 id="10-什么是最左匹配原则？"><a href="#10-什么是最左匹配原则？" class="headerlink" title="10. 什么是最左匹配原则？"></a>10. 什么是最左匹配原则？</h2><p>最左优先，以最左边的为起点任何连续的索引都能匹配上。同时遇到范围查询(&gt;、&lt;、between、like)就会停止匹配。<br>例如：b &#x3D; 2 如果建立(a,b)顺序的索引，是匹配不到(a,b)索引的；但是如果查询条件是a &#x3D; 1 and b &#x3D; 2,就可以，因为**优化器会自动调整a,b的顺序**。再比如a &#x3D; 1 and b &#x3D; 2 and c &gt; 3 and d &#x3D; 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，因为c字段是一个范围查询，它之后的字段会停止匹配。</p>
<p><strong>最左匹配原则的原理</strong></p>
<p>MySQL中的索引可以以一定顺序引用多列，这种索引叫作联合索引.最左匹配原则都是针对联合索引来说的</p>
<ul>
<li>我们都知道索引的底层是一颗B+树，那么联合索引当然还是一颗B+树，只不过联合索引的健值数量不是一个，而是多个。构建一颗B+树只能根据一个值来构建，因此数据库依据联合索引最左的字段来构建B+树。<br>例子：假如创建一个（a,b)的联合索引，那么它的索引树是这样的可以看到a的值是有顺序的，1，1，2，2，3，3，而b的值是没有顺序的1，2，1，4，1，2。所以b &#x3D; 2这种查询条件没有办法利用索引，因为联合索引首先是按a排序的，b是无序的。</li>
</ul>
<p>同时我们还可以发现在a值相等的情况下，b值又是按顺序排列的，但是这种顺序是相对的。所以最左匹配原则遇上范围查询就会停止，剩下的字段都无法使用索引。例如a &#x3D; 1 and b &#x3D; 2 a,b字段都可以使用索引，因为在a值确定的情况下b是相对有序的，而a&gt;1and b&#x3D;2，a字段可以匹配上索引，但b值不可以，因为a的值是一个范围，在这个范围中b是无序的。</p>
<p>优点：最左前缀原则的利用也可以显著提高查询效率，是常见的MySQL性能优化手段。</p>
<h2 id="11-哪些列上适合创建索引？创建索引有哪些开销？"><a href="#11-哪些列上适合创建索引？创建索引有哪些开销？" class="headerlink" title="11. 哪些列上适合创建索引？创建索引有哪些开销？"></a>11. 哪些列上适合创建索引？创建索引有哪些开销？</h2><p>经常需要作为条件查询的列上适合创建索引，并且该列上也必须有一定的区分度。创建索引需要维护，在插入数据的时候会重新维护各个索引树（数据页的分裂与合并），对性能造成影响</p>
<h2 id="12-索引这么多优点，为什么不对表中的每一个列创建一个索引呢？"><a href="#12-索引这么多优点，为什么不对表中的每一个列创建一个索引呢？" class="headerlink" title="12. 索引这么多优点，为什么不对表中的每一个列创建一个索引呢？"></a>12. 索引这么多优点，为什么不对表中的每一个列创建一个索引呢？</h2><ol>
<li>当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。</li>
<li>索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。</li>
<li>创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。</li>
</ol>
<h2 id="13-MySQL建表的约束条件有哪些？"><a href="#13-MySQL建表的约束条件有哪些？" class="headerlink" title="13. MySQL建表的约束条件有哪些？"></a>13. <strong>MySQL建表的约束条件有哪些</strong>？</h2><ul>
<li>主键约束（Primay Key Coustraint） 唯一性，非空性</li>
<li>唯一约束 （Unique Counstraint）唯一性，可以空，但只能有一个</li>
<li>检查约束 (Check Counstraint) 对该列数据的范围、格式的限制</li>
<li>默认约束 (Default Counstraint) 该数据的默认值</li>
<li>外键约束 (Foreign Key Counstraint) 需要建立两表间的关系并引用主表的列</li>
</ul>
<h2 id="14-MySQL执行查询的过程？"><a href="#14-MySQL执行查询的过程？" class="headerlink" title="14. MySQL执行查询的过程？"></a>14. MySQL执行查询的过程？</h2><ol>
<li>客户端通过TCP连接发送连接请求到mysql连接器，连接器会对该请求进行权限验证及连接资源分配</li>
<li>查缓存。（当判断缓存是否命中时，MySQL不会进行解析查询语句，而是直接使用SQL语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。）</li>
<li>语法分析（SQL语法是否写错了）。 如何把语句给到预处理器，检查数据表和数据列是否存在，解析别名看是否存在歧义。</li>
<li>优化。是否使用索引，生成执行计划。</li>
<li>交给执行器，将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。</li>
</ol>
<p><img src="http://blog-img.coolsen.cn/img/image-20210220120155334.png"></p>
<h2 id="15-MySQL的binlog有有几种录入格式-分别有什么区别"><a href="#15-MySQL的binlog有有几种录入格式-分别有什么区别" class="headerlink" title="15. MySQL的binlog有有几种录入格式?分别有什么区别?"></a>15. MySQL的binlog有有几种录入格式?分别有什么区别?</h2><p>有三种格式,statement,row和mixed.</p>
<ul>
<li>statement模式下,记录单元为语句.即每一个sql造成的影响会记录.由于sql的执行是有上下文的,因此在保存的时候需要保存相关的信息,同时还有一些使用了函数之类的语句无法被记录复制.</li>
<li>row级别下,记录单元为每一行的改动,基本是可以全部记下来但是由于很多操作,会导致大量行的改动(比如alter table),因此这种模式的文件保存的信息太多,日志量太大。</li>
<li>mixed. 一种折中的方案,普通操作使用statement记录,当无法使用statement的时候使用row. 此外,新版的MySQL中对row级别也做了一些优化,当表结构发生变化的时候,会记录语句而不是逐行记录.</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/06/02/MySQL/" data-id="cl3wpioen0003o0r45x2edx4r" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/06/">June 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">May 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/06/02/Netty/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/06/02/Java%E9%9B%86%E5%90%88%E9%AB%98%E9%A2%91%E9%9D%A2%E8%AF%95%E9%A2%98/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/06/02/HashMap%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/06/02/HashMap/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/06/02/ConcurrentHashMap/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>